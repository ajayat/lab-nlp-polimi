{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giKsby3Lpdlp"
   },
   "source": [
    "# Sequence Labelling and Classification\n",
    "\n",
    "In this session we will first investigate Part-of-Speech (POS) tagging and Named-entity recognition (NER).\n",
    "- For this we will make use of the spaCy natural langauge processing API: https://spacy.io/\n",
    "- spaCy is an opensource API that provides state-of-the-art performance on sequence labeling tasks such as POS tagging and NER.\n",
    "- Parts of this tutorial are based on code from: https://medium.com/data-science/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OgRPEb6pdlv"
   },
   "source": [
    "## Installing spaCy and downloading models\n",
    "\n",
    "First we need to check whether the spaCy library is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4187,
     "status": "ok",
     "timestamp": 1743369809810,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "3083U81cpdlv",
    "outputId": "43e24189-1f18-4b5d-dd4e-c93358cd4ffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJ1xLIcHpdlw"
   },
   "source": [
    "Then we need to download pretrained models for use with spaCy. We will load models for both English and Italian:\n",
    "- The models are called 'en_core_web_sm' and 'it_core_news_sm', where the 'web'/'news' indicates what type of collection the model was trained on and the 'sm' at the end indicates that we are using the 'small' version of the models\n",
    "- Other models are available here: https://spacy.io/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v05LKyQWZEuo"
   },
   "source": [
    "If the model is not download automatically, uncomment the following code. It calls the python executable instructing it to run the module 'spacy', which in turn download the models. See discussion here: https://stackoverflow.com/questions/46148033/unable-to-load-en-from-spacy-in-jupyter-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47840,
     "status": "ok",
     "timestamp": 1743369857649,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "dyv-NpFbpdlw",
    "outputId": "b899bf46-7291-4916-b63d-8404bff2ebca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting it-core-news-sm==3.8.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.8.0/it_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('it_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download it_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYRlbtvspdlx"
   },
   "source": [
    "We are now ready to import spacy and load a model. Let's start with the English model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 11216,
     "status": "ok",
     "timestamp": 1743369868868,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "4KHrsza0pdlx"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp_model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jy4K8dRApdlx"
   },
   "source": [
    "Consider the following piece of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743369868872,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "3MGjLJU0pdlx",
    "outputId": "68a7817c-5ada-429c-a243-8a4d626f5650"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melbourne is to re-enter Stage 3 lockdown after a record increase in cases. Victorian state premier Daniel Andrews said there was “simply no alternative” to reimposing stay at home restrictions in Australia’s second-biggest city.\n"
     ]
    }
   ],
   "source": [
    "text = 'Melbourne is to re-enter Stage 3 lockdown after a record increase in cases. Victorian state premier Daniel Andrews said there was “simply no alternative” to reimposing stay at home restrictions in Australia’s second-biggest city.'\n",
    "# text = \"Good evening, London. Allow me first to apologize for this interruption. I do, like many of you, appreciate the comforts of everyday routine, the security of the familiar, the tranquillity of repetition. I enjoy them as much as any bloke. But in the spirit of commemoration, whereby those important events of the past, usually associated with someone's death or the end of some awful bloody struggle, are celebrated with a nice holiday, I thought we could mark this November the fifth, a day that is sadly no longer remembered, by taking some time out of our daily lives to sit down and have a little chat.\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_rCI0Hbpdly"
   },
   "source": [
    "Parse the text using the NLP engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1743369868917,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "xmpvXvjapdly",
    "outputId": "4cb95694-b986-4551-f155-35584a97d018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melbourne is to re-enter Stage 3 lockdown after a record increase in cases. Victorian state premier Daniel Andrews said there was “simply no alternative” to reimposing stay at home restrictions in Australia’s second-biggest city.\n"
     ]
    }
   ],
   "source": [
    "parsed_text = nlp_model(text)\n",
    "print(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnXyGOx0pdlz"
   },
   "source": [
    "Did it do something? It looks like it has just output the same text.\n",
    "- Actually, yes. It has parsed the input and built its internal datastructure from it.\n",
    "- Note that the length of the parsed object is in words, not characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1743369868923,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "fbAOI2Mnpdlz",
    "outputId": "87905275-dc1b-42b5-9b61-7b4757f47561"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the original text is 229 chacacters\n",
      "The length of the parsed text is 43 words\n"
     ]
    }
   ],
   "source": [
    "print(f'The length of the original text is {len(text)} chacacters')\n",
    "print(f'The length of the parsed text is {len(parsed_text)} words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agx17FP4dQth"
   },
   "source": [
    "Also, the parsed object is not a simple string. It is actually a Spacy **Document** object which implements a to_string() method. If requested access to the object, like in the case of just printing its value, Python automatically look for a to_string method, that's why if we just print the parsed object we get a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1743369869074,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "vkOCiD3PdP8i",
    "outputId": "e2a8e1b9-c29f-45d7-e2fc-1ef790b08cc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xImJ-i_Lpdlz"
   },
   "source": [
    "## Part-of-Speech Tagging\n",
    "\n",
    "While parsing the text, spaCy performs part-of-speech (POS) tagging.\n",
    "- We can see the POS tag for each token as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1743369869075,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "Ho4HEJTLpdlz",
    "outputId": "a79aac5b-f434-486b-f513-bf3c8fdf49ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Melbourne, 'PROPN'),\n",
       " (is, 'AUX'),\n",
       " (to, 'PART'),\n",
       " (re, 'VERB'),\n",
       " (-, 'VERB'),\n",
       " (enter, 'VERB'),\n",
       " (Stage, 'PROPN'),\n",
       " (3, 'NUM'),\n",
       " (lockdown, 'NOUN'),\n",
       " (after, 'ADP'),\n",
       " (a, 'DET'),\n",
       " (record, 'ADJ'),\n",
       " (increase, 'NOUN'),\n",
       " (in, 'ADP'),\n",
       " (cases, 'NOUN'),\n",
       " (., 'PUNCT'),\n",
       " (Victorian, 'ADJ'),\n",
       " (state, 'NOUN'),\n",
       " (premier, 'NOUN'),\n",
       " (Daniel, 'PROPN'),\n",
       " (Andrews, 'PROPN'),\n",
       " (said, 'VERB'),\n",
       " (there, 'PRON'),\n",
       " (was, 'VERB'),\n",
       " (“, 'PUNCT'),\n",
       " (simply, 'ADV'),\n",
       " (no, 'DET'),\n",
       " (alternative, 'NOUN'),\n",
       " (”, 'PUNCT'),\n",
       " (to, 'ADP'),\n",
       " (reimposing, 'VERB'),\n",
       " (stay, 'NOUN'),\n",
       " (at, 'ADP'),\n",
       " (home, 'NOUN'),\n",
       " (restrictions, 'NOUN'),\n",
       " (in, 'ADP'),\n",
       " (Australia, 'PROPN'),\n",
       " (’s, 'PART'),\n",
       " (second, 'ADV'),\n",
       " (-, 'PUNCT'),\n",
       " (biggest, 'ADJ'),\n",
       " (city, 'NOUN'),\n",
       " (., 'PUNCT')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(w,w.pos_) for w in parsed_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFEzvleepdlz"
   },
   "source": [
    "Who remembers their grammar from high school? What do all those POS symbols mean?\n",
    "- You can find an explanation of the POS tags on this website https://spacy.io/api/annotation in the section \"Universal Part-of-speech Tags\"\n",
    "\n",
    "What can we do with POS tags?\n",
    "- Well, we could select all terms that have a certain tag, such as all adjectives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743369869075,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "6Kcjc28lpdl0",
    "outputId": "63c697cb-6545-4f0a-dcaf-0f32b427f113"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{record, Victorian, biggest}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(w for w in parsed_text if w.pos_=='ADJ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftw5HEYEpdl0"
   },
   "source": [
    "That was a little underwhelming.\n",
    "- Let's try it on Alice in Wonderland chapter 1 text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1743369869972,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "tGRt3HF8pdl0",
    "outputId": "f3455e76-018d-4159-c350-745936ebf498"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afraid', 'best', 'brave', 'bright', 'certain', 'close', 'common', 'cool', 'curious', 'dark', 'deep', 'dreamy', 'dry', 'dull', 'empty', 'enough', 'fancy', 'few', 'first', 'fond', 'funny', 'glad', 'golden', 'good', 'grand', 'great', 'high', 'hot', 'hurt', 'ignorant', 'impossible', 'large', 'larger', 'late', 'legged', 'likely', 'little', 'long', 'loveliest', 'lovely', 'low', 'many', 'mixed', 'much', 'natural', 'nervous', 'nice', 'other', 'out', 'own', 'pine', 'pink', 'poor', 'red', 'remarkable', 'respectable', 'right', 'same', 'second', 'several', 'simple', 'sleepy', 'slippery', 'small', 'smaller', 'solid', 'stupid', 'such', 'sure', 'surprised', 'tart', 'tiny', 'tired', 'true', 'unpleasant', 'wild', 'wise', 'worth']\n"
     ]
    }
   ],
   "source": [
    "adjectives = sorted(set(w.text for w in nlp_model(open(\"docs/Alice_Chapter1.txt\", \"r\").read()) if w.pos_=='ADJ'))\n",
    "print(adjectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pct1jNdEpdl0"
   },
   "source": [
    "You can see how descriptive a writer Lewis Carroll was!\n",
    "\n",
    "This leads us to one explanation as to why we might want to extract POS tags from text:\n",
    "- They can sometimes be useful for **extracting features** (often handcrafted ones) for certain text classification tasks (such as authorship identification).\n",
    "- This is particularly the case if only a small amount of training data is available.  \n",
    "- For example, in this article (https://medium.com/data-science/automatically-detect-covid-19-misinformation-f7ceca1dc1c7) hand-crafted features are extracted for classifying covid misinformation.\n",
    "\n",
    "Another reason why we might consider POS tagging is to **reduce ambiguity** in our bag-of-words representation by appending POS tags to word occurrences.\n",
    "- Consider the following two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1743369869978,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "2iO992Q-pdl0",
    "outputId": "8ac28877-eae0-4688-81a8-6d96bef73fdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I catch the train to and from work.      <-- 'train' is a NOUN\n",
      "I like to train at least 6 times a week. <-- 'train' is a VERB\n"
     ]
    }
   ],
   "source": [
    "ex1 = 'I catch the train to and from work.'       # This is Prof. Mark Carman speaking\n",
    "ex2 = 'I like to train at least 6 times a week.'  # This is Prof. Jacked Carman speaking\n",
    "\n",
    "print(ex1, '     <-- \\'train\\' is a', nlp_model(ex1)[3].pos_)\n",
    "print(ex2, '<-- \\'train\\' is a', nlp_model(ex2)[3].pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHlqof06pdl1"
   },
   "source": [
    "The second sentence has nothing to do with trains, despite containing the word 'train'!\n",
    "- We could deal with this issue by appending the POS tag to the observed literal to form vocabulary elements: train_NOUN, train_VERB\n",
    "\n",
    "A final reason why we might think about running POS tagging would be to extract proper nouns from the text, since they refer to real entities that are being discussed in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1743369869994,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "kW4TbHffpdl1",
    "outputId": "c9985b8a-c9c2-4003-c759-79ee167b5b2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Melbourne', 'Stage', 'Daniel', 'Andrews', 'Australia']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.text for w in parsed_text if w.pos_=='PROPN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDl1pPoSpdl1"
   },
   "source": [
    "Shortly though, we will talk about Entity-extraction, which is the task of identifying and categorising the entities discussed in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDh0iS65pdl1"
   },
   "source": [
    "## Lemmatization\n",
    "\n",
    "While parsing, spaCy also performs lemmatization.\n",
    "- Lemmatization is the process of extracting the 'lemma' for each token, which is the canonical form of the word that would be found in the dictionary, (see https://en.wikipedia.org/wiki/Lemma_(morphology))\n",
    "- Basically, verbs converted to their root form, e.g.: **went, going, goes, gone => go**\n",
    "- And nouns are retuned to singular form: **kittens => kitten**\n",
    "- Lemmatization is a more complicated POS-aware process than stemming (https://en.wikipedia.org/wiki/Stemming). Stemmers simply apply a set of language-specific syntax rules to recover the stem of the word. For example, the word \"better\" is lemmatized to \"good\" if it is an adjective, or to \"better\" if it is a noun (i.e. \"Who bets something\"). A simple stemmer makes no distinction between these cases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1743369870027,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "EevBrQRbpdl1",
    "outputId": "3316e073-6926-4dae-9f95-c93e2cc53f70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Melbourne, 'Melbourne'),\n",
       " (is, 'be'),\n",
       " (to, 'to'),\n",
       " (re, 're'),\n",
       " (-, '-'),\n",
       " (enter, 'enter'),\n",
       " (Stage, 'Stage'),\n",
       " (3, '3'),\n",
       " (lockdown, 'lockdown'),\n",
       " (after, 'after'),\n",
       " (a, 'a'),\n",
       " (record, 'record'),\n",
       " (increase, 'increase'),\n",
       " (in, 'in'),\n",
       " (cases, 'case'),\n",
       " (., '.'),\n",
       " (Victorian, 'victorian'),\n",
       " (state, 'state'),\n",
       " (premier, 'premier'),\n",
       " (Daniel, 'Daniel'),\n",
       " (Andrews, 'Andrews'),\n",
       " (said, 'say'),\n",
       " (there, 'there'),\n",
       " (was, 'be'),\n",
       " (“, '\"'),\n",
       " (simply, 'simply'),\n",
       " (no, 'no'),\n",
       " (alternative, 'alternative'),\n",
       " (”, '\"'),\n",
       " (to, 'to'),\n",
       " (reimposing, 'reimpose'),\n",
       " (stay, 'stay'),\n",
       " (at, 'at'),\n",
       " (home, 'home'),\n",
       " (restrictions, 'restriction'),\n",
       " (in, 'in'),\n",
       " (Australia, 'Australia'),\n",
       " (’s, '’s'),\n",
       " (second, 'second'),\n",
       " (-, '-'),\n",
       " (biggest, 'big'),\n",
       " (city, 'city'),\n",
       " (., '.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x, x.lemma_) for x in parsed_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEIoq1RFpdl1"
   },
   "source": [
    "Why would one want to perfom lemmatization? -- Or stemming for that matter?\n",
    "- to **reduce the vocabulary size** and thereby generalise the representation. -- This used to be very important for improving performance of search engine performance (better similarity measures between documents) and also classifiers on small datasets, (before word embeddings came along).\n",
    "- to **look-up information** about the word in a dictionary/ontology, such as WordNet (https://en.wikipedia.org/wiki/WordNet). This used to be an important way to compute semantic similarity between words, but again, word embeddngs probably do a better job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vBQ7f0tpdl2"
   },
   "source": [
    "## Dependency Parsing\n",
    "\n",
    "Tradititonally in Natural Language Processing, text is processed in a pipeline that first tokenizes, then POS tags, lemmatizes and finaly dependency parses a piece of text.\n",
    "- The idea with dependency parsing is to determine what function each of the word instances is fulfilling in the sentence.\n",
    "- What is the subject and object of the sentence?\n",
    "- Which noun is each adjective referring to?\n",
    "\n",
    "So while parsing the text, the spaCy model also generates a **dependency parse tree**, which can be displayed using 'displacy':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1743369870109,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "Dbz57hc5pdl2",
    "outputId": "bec83c49-ab20-4ef8-8e3d-b4734df8184b"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "def displacy_render(*args, displacy_render_=displacy.render, **kwargs):\n",
    "    \"\"\"\n",
    "    Fix displacy.render function (ImportError from IPython.core.display).\n",
    "    \"\"\"\n",
    "    from IPython.display import display, HTML  # Fix here\n",
    "\n",
    "    kwargs[\"jupyter\"] = False\n",
    "    html = displacy_render_(*args, **kwargs)\n",
    "    return display(HTML('<span class=\"tex2jax_ignore\">{}</span>'.format(html)))\n",
    "\n",
    "displacy.render = displacy_render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quwWOjbOpdl3"
   },
   "source": [
    "Such dependency trees are interesting for understanding and visualising language (particularly for linguists) and could possibly be used for some downstream tasks (say checking ambiguity in legal documents).  \n",
    "\n",
    "Consider the sentences:\n",
    "- *The girl saw a man carrying a telescope.*\n",
    "- *The girl saw a man with a telescope.*\n",
    "\n",
    "Who had the telescope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1743369870123,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "_AxJLNswpdl3",
    "outputId": "0211fb54-bbbf-4dfe-9f9c-21caea307d48"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4e549ad78a6b40198c5c5fef4c87c737-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">girl</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">saw</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">man</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">carrying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">telescope.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e549ad78a6b40198c5c5fef4c87c737-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e549ad78a6b40198c5c5fef4c87c737-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e549ad78a6b40198c5c5fef4c87c737-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e549ad78a6b40198c5c5fef4c87c737-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e549ad78a6b40198c5c5fef4c87c737-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e549ad78a6b40198c5c5fef4c87c737-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e549ad78a6b40198c5c5fef4c87c737-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e549ad78a6b40198c5c5fef4c87c737-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e549ad78a6b40198c5c5fef4c87c737-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e549ad78a6b40198c5c5fef4c87c737-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e549ad78a6b40198c5c5fef4c87c737-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e549ad78a6b40198c5c5fef4c87c737-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4e549ad78a6b40198c5c5fef4c87c737-0-6\" stroke-width=\"2px\" d=\"M945,177.0 C945,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4e549ad78a6b40198c5c5fef4c87c737-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp_model('The girl saw a man carrying a telescope.'),jupyter=True,style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1743369870133,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "7abgGOdwpdl3",
    "outputId": "78ec53fb-5820-4c4f-8e37-2d7bc61583a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c2fda3e94ffc4b6d81d94191fa02d927-0\" class=\"displacy\" width=\"1450\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">girl</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">saw</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">man</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">telescope.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c2fda3e94ffc4b6d81d94191fa02d927-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c2fda3e94ffc4b6d81d94191fa02d927-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c2fda3e94ffc4b6d81d94191fa02d927-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c2fda3e94ffc4b6d81d94191fa02d927-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c2fda3e94ffc4b6d81d94191fa02d927-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c2fda3e94ffc4b6d81d94191fa02d927-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c2fda3e94ffc4b6d81d94191fa02d927-0-3\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c2fda3e94ffc4b6d81d94191fa02d927-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M745.0,266.5 L753.0,254.5 737.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c2fda3e94ffc4b6d81d94191fa02d927-0-4\" stroke-width=\"2px\" d=\"M420,264.5 C420,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c2fda3e94ffc4b6d81d94191fa02d927-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,266.5 L933.0,254.5 917.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c2fda3e94ffc4b6d81d94191fa02d927-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c2fda3e94ffc4b6d81d94191fa02d927-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c2fda3e94ffc4b6d81d94191fa02d927-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c2fda3e94ffc4b6d81d94191fa02d927-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp_model('The girl saw a man with a telescope.'),jupyter=True,style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fIZq6zIhPbk"
   },
   "source": [
    "The second sentence is ambiguous: The girl may have made use of her telescope or the man may have been using the girl's telescope...\n",
    "- Language is full of such ambiguities which we as humans naturally deal with using our prior knowledge and abilty to construct mental models of the situations described.\n",
    "- This process is not without its biases:\n",
    "  - *The doctor went over to talk to the nurse. She told him that she had just given the patient 5mg of Vicodin and the child had started convulsing. He listened attentively as she explained what had happened. The doctor was worried that the patient should not be given any more painkillers. The nurse told the doctor not to worry, that the patient was in good hands, and that he would let her know immediately if the child's condition changed.*\n",
    "  - What gender are the doctor and the nurse?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uE1efbqpdl3"
   },
   "source": [
    "## Extracting Entities\n",
    "\n",
    "A more important output than the depency parse, from a text mining perspective, is the list of named-entities present in the text\n",
    "- **named entities** are objects in the real world, e.g. persons, products, organizations, locations, etc.\n",
    "  - see https://en.wikipedia.org/wiki/Named_entity\n",
    "- if spacy has found any named entities while parsing the text, we can access them as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1743369870143,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "irYwH5WVpdl3",
    "outputId": "14967fda-e5dd-42d0-8add-191788c59fa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Melbourne, 3, Victorian, Daniel Andrews, Australia, second)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_text.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rv6krbXmpdl3"
   },
   "source": [
    "Note that the entities are not single word tokens but short sequences of words: 'Stage 3' and 'Daniel Andrews'.\n",
    "\n",
    "Not only does spacy extract the entities, but also categorises them based on their type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743369870144,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "EXA2FRzXpdl4",
    "outputId": "95a323cb-a6d7-4728-dc5c-0e801a3fa54c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Melbourne', 'GPE'), ('3', 'CARDINAL'), ('Victorian', 'NORP'), ('Daniel Andrews', 'PERSON'), ('Australia', 'GPE'), ('second', 'ORDINAL')]\n"
     ]
    }
   ],
   "source": [
    "print([(ent.text, ent.label_) for ent in parsed_text.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyp09Uelpdl4"
   },
   "source": [
    "The city and country locations have been labeled 'GPE' for 'geopolitical entity', while the Premier of Victoria has been correctly identified as a person.\n",
    "- Here is the list of all entity types that spaCy looks for: https://spacy.io/api/annotation#section-named-entities\n",
    "\n",
    "Internally, the output of the Named Entity Recogniser is a sequence annotated with entities using inside-outside-beginning encoding:\n",
    "- see https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)\n",
    "- We can print out this labeling as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1743369870178,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "-E1H-RM6pdl4",
    "outputId": "9b1f59da-6271-4b88-8705-e170f05af8ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Melbourne, 'B', 'GPE'),\n",
       " (is, 'O', ''),\n",
       " (to, 'O', ''),\n",
       " (re, 'O', ''),\n",
       " (-, 'O', ''),\n",
       " (enter, 'O', ''),\n",
       " (Stage, 'O', ''),\n",
       " (3, 'B', 'CARDINAL'),\n",
       " (lockdown, 'O', ''),\n",
       " (after, 'O', ''),\n",
       " (a, 'O', ''),\n",
       " (record, 'O', ''),\n",
       " (increase, 'O', ''),\n",
       " (in, 'O', ''),\n",
       " (cases, 'O', ''),\n",
       " (., 'O', ''),\n",
       " (Victorian, 'B', 'NORP'),\n",
       " (state, 'O', ''),\n",
       " (premier, 'O', ''),\n",
       " (Daniel, 'B', 'PERSON'),\n",
       " (Andrews, 'I', 'PERSON'),\n",
       " (said, 'O', ''),\n",
       " (there, 'O', ''),\n",
       " (was, 'O', ''),\n",
       " (“, 'O', ''),\n",
       " (simply, 'O', ''),\n",
       " (no, 'O', ''),\n",
       " (alternative, 'O', ''),\n",
       " (”, 'O', ''),\n",
       " (to, 'O', ''),\n",
       " (reimposing, 'O', ''),\n",
       " (stay, 'O', ''),\n",
       " (at, 'O', ''),\n",
       " (home, 'O', ''),\n",
       " (restrictions, 'O', ''),\n",
       " (in, 'O', ''),\n",
       " (Australia, 'B', 'GPE'),\n",
       " (’s, 'O', ''),\n",
       " (second, 'B', 'ORDINAL'),\n",
       " (-, 'O', ''),\n",
       " (biggest, 'O', ''),\n",
       " (city, 'O', ''),\n",
       " (., 'O', '')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(X, X.ent_iob_, X.ent_type_) for X in parsed_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10tU8n44pdl4"
   },
   "source": [
    "The above format is a bit hard to read though, so spaCy also provides a far more natural visualisation of the tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1743369870180,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "9PmUl2y5pdl4",
    "outputId": "631929e8-75b3-438a-e99d-2d384aeb971d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Melbourne\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is to re-enter Stage \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " lockdown after a record increase in cases. \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Victorian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " state premier \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Daniel Andrews\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " said there was “simply no alternative” to reimposing stay at home restrictions in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Australia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "’s \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    second\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       "-biggest city.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(parsed_text, jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VS1PK7ifpdl5"
   },
   "source": [
    "## Extracting entities from a web document\n",
    "\n",
    "Now that we know how to perform entity recognition on text, let's apply it to a full document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 1905,
     "status": "ok",
     "timestamp": 1743369872090,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "8pY-nN0Zpdl5"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.bbc.com/news/world-latin-america-53319517'\n",
    "#url = 'https://en.wikipedia.org/wiki/Apple_(disambiguation)'\n",
    "\n",
    "html_doc = requests.get(url).text\n",
    "parsed_doc = BeautifulSoup(html_doc, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRe5AUvCpdl5"
   },
   "source": [
    "Now lets extract the title and paragraph text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1743369872107,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "e5YGoQISpdl5",
    "outputId": "52da45b6-0202-4b4b-9bb9-be82e2dd8228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coronavirus: Brazil's President Bolsonaro tests positive\n",
      "\n",
      "Brazil's President Jair Bolsonaro has tested positive for coronavirus.\n",
      "He took the test, his fourth, on Monday after developing symptoms, including a high temperature.\n",
      "Mr Bolsonaro has repeatedly played down risks of what he has called the \"little flu\", saying he would not be seriously affected. He has opposed lockdowns, which he says hurt the economy.\n",
      "Brazil has the second-highest number of Covid-19 cases and deaths in the world, after the US. \n",
      "He made the announcement in a TV interview on Tuesday, saying the fever he had been experiencing had gone down and that he felt \"very well\".\n",
      "Mr Bolsonaro said that he had started experiencing symptoms on Sunday. He said he had had a high temperature, a cough and had felt unwell. \n",
      "He added that on Monday he had felt worse, which prompted him to take the coronavirus test.\n",
      "Mr Bolsonaro is in a higher-risk group because of his age, 65.\n",
      "He said he was taking hydroxychloroquine - championed by US President Donald Trump - and azithromycin, an antibiotic, to treat the illness. Neither has been proven to be effective against the virus.\n",
      "Contact tracing and tests will be carried out for the people Mr Bolsonaro has met recently.\n",
      "His previous three tests for the virus all came back negative.\n",
      "The executive director of the World Health Organization, Dr Mike Ryan, wished President Bolsonaro \"a speedy and full recovery from this disease\", adding: \"I think the message to us all is: we are vulnerable to this virus.\"\n",
      "Back in April, Mr Bolsonaro said that even if infected, he would \"not have to worry as I wouldn't feel anything, at most it would be like a little flu or a little cold\".\n",
      "The number of Covid-19-related deaths and infections - at that time under 3,000 and 40,000 - has since soared.\n",
      "Despite this, President Bolsonaro has argued that regional lockdowns are having a more damaging effect than the virus itself, and accused the media of spreading panic and paranoia.\n",
      "His other comments on the virus include:\n",
      "He has since continued to rail against measures that he deems \"dictatorial\" such as the closing beaches or requirements to wear face coverings. \n",
      "On Monday, he made further changes to a law that would require Brazilians to wear masks in public.\n",
      "He has attended a number of public events without a mask, even when local rules required him to wear one.\n",
      "On Sunday, Foreign Minister Ernesto Araújo posted a photo on social media showing himself with President Bolsonaro and others attending an Independence Day celebration at the US embassy in Brasilia. \n",
      "None of those in the photo is wearing a mask or observing social distancing.\n",
      "The US embassy said that the ambassador had had lunch with Mr Bolsonaro and others on 4 July. It added that the ambassador had no symptoms but that he would undergo testing.\n",
      "The ambassador had earlier tweeted a picture of himself with President Bolsonaro.\n",
      "For so long, Jair Bolsonaro has tried to brush off this virus - the irony that he has now caught it has not been missed in Brazil. \n",
      "His detractors - of which he has many - have weighed in, calling this karma - that Jair Bolsonaro invited this to happen. \n",
      "There was even a column in one of the biggest newspapers, Folha de São Paulo, entitled \"Why I'm Cheering for Bolsonaro to Die\" - this is how divided, how toxic  the political picture is here in Brazil as the pandemic takes hold. \n",
      "But the fact is, Bolsonaro joins the nearly 1.7 million Brazilians who've contracted Covid-19. They're scary numbers and Brazil is a country in trouble, where coronavirus is spreading fast. \n",
      "Will Jair Bolsonaro get away with mild symptoms and carry on downplaying it? Or change tack now the virus has hit home? Whatever happens, with the man at the top suffering from Covid-19, it symbolises the crisis this country is in. \n",
      "Infections in Brazil and Latin America as a whole took a while to take hold but then started to rise, initially for Brazil in its Amazonas region but then more starkly in Rio de Janeiro and São Paulo.\n",
      "Brazil became only the second country to pass one million cases on 20 June and has continued to rise, passing 1.5 million. Many experts believe deficiencies in testing mean the overall figures for cases and deaths could be considerably higher.\n",
      "Nevertheless lockdowns began to be lifted in many areas even as the cases surged. Both Rio and São Paulo have reopened bars and restaurants in the past week.\n",
      "Two health ministers - both doctors - have left their posts after disagreements with the president.\n",
      "One ray of hope though is Brazil's renowned expertise in vaccines. Two major vaccine tests, in partnership with AstraZeneca and Sinovac, are to begin final phase testing on thousands of Brazilian volunteers.\n",
      "Copyright 2025 BBC. All rights reserved.  The BBC is not responsible for the content of external sites. Read about our approach to external linking.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "title = parsed_doc.find('title').text\n",
    "paragraphs = [p.text for p in parsed_doc.find_all('p')]\n",
    "\n",
    "# Combine the title and paragraphs into a single text:\n",
    "article_text = title + '\\n\\n' + '\\n'.join(paragraphs)\n",
    "print(article_text)\n",
    "\n",
    "#article_text = parsed_doc.get_text()\n",
    "#print(article_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_dqist0pdl5"
   },
   "source": [
    "Parse the article to identify the entities and display them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1743369872566,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "RMTsfAhYpdl6",
    "outputId": "d75d8fc6-9cca-4572-c70a-3291ed00e958"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Coronavirus: \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "'s President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " tests positive<br><br>\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "'s President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jair Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " has tested positive for coronavirus.<br>He took the test, his \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    fourth\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       ", on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Monday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " after developing symptoms, including a high temperature.<br>Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " has repeatedly played down risks of what he has called the &quot;little flu&quot;, saying he would not be seriously affected. He has opposed lockdowns, which he says hurt the economy.<br>\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " has the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    second\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       "-highest number of Covid-19 cases and deaths in the world, after the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". <br>He made the announcement in a TV interview on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tuesday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", saying the fever he had been experiencing had gone down and that he felt &quot;very well&quot;.<br>Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " said that he had started experiencing symptoms on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sunday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". He said he had had a high temperature, a cough and had felt unwell. <br>He added that on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Monday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " he had felt worse, which prompted him to take the coronavirus test.<br>Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is in a higher-risk group because of \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    his age, 65\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".<br>He said he was taking hydroxychloroquine - championed by \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Donald Trump\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " - and azithromycin, an antibiotic, to treat the illness. Neither has been proven to be effective against the virus.<br>Contact tracing and tests will be carried out for the people Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " has met recently.<br>His previous \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " tests for the virus all came back negative.<br>The executive director of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the World Health Organization\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", Dr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mike Ryan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", wished President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " &quot;a speedy and full recovery from this disease&quot;, adding: &quot;I think the message to us all is: we are vulnerable to this virus.&quot;<br>Back in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    April\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " said that even if infected, he would &quot;not have to worry as I wouldn't feel anything, at most it would be like a little flu or a little cold&quot;.<br>The number of Covid-19-related deaths and infections - at that time \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    under 3,000 and 40,000 -\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " has since soared.<br>Despite this, President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " has argued that regional lockdowns are having a more damaging effect than the virus itself, and accused the media of spreading panic and paranoia.<br>His other comments on the virus include:<br>He has since continued to rail against measures that he deems &quot;dictatorial&quot; such as the closing beaches or requirements to wear face coverings. <br>On \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Monday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", he made further changes to a law that would require \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazilians\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " to wear masks in public.<br>He has attended a number of public events without a mask, even when local rules required him to wear one.<br>On \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sunday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", Foreign Minister \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ernesto Araújo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " posted a photo on social media showing himself with President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and others attending an \n",
       "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Independence Day\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
       "</mark>\n",
       " celebration at the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " embassy in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brasilia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". <br>None of those in the photo is wearing a mask or observing social distancing.<br>The \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " embassy said that the ambassador had had lunch with Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and others on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    4 July\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". It added that the ambassador had no symptoms but that he would undergo testing.<br>The ambassador had earlier tweeted a picture of himself with President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".<br>For so long, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jair Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " has tried to brush off this virus - the irony that he has now caught it has not been missed in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". <br>His detractors - of which he has many - have weighed in, calling this karma - that \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jair Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " invited this to happen. <br>There was even a column in one of the biggest newspapers, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Folha de São Paulo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", entitled &quot;Why I'm Cheering for Bolsonaro to Die&quot; - this is how divided, how toxic  the political picture is here in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " as the pandemic takes hold. <br>But the fact is, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " joins the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 1.7 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazilians\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " who've contracted Covid-19. They're scary numbers and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " is a country in trouble, where coronavirus is spreading fast. <br>\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Will Jair Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " get away with mild symptoms and carry on downplaying it? Or change tack now the virus has hit home? Whatever happens, with the man at the top suffering from Covid-19, it symbolises the crisis this country is in. <br>Infections in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Latin America\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " as a whole took a while to take hold but then started to rise, initially for \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " in its \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Amazonas\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " region but then more starkly in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rio de Janeiro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    São Paulo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".<br>\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " became only the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    second\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " country to pass \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " cases on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    20 June\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " and has continued to rise, passing \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1.5 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ". Many experts believe deficiencies in testing mean the overall figures for cases and deaths could be considerably higher.<br>Nevertheless lockdowns began to be lifted in many areas even as the cases surged. Both Rio and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    São Paulo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " have reopened bars and restaurants in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the past week\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".<br>\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " health ministers - both doctors - have left their posts after disagreements with the president.<br>\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    One\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " ray of hope though is \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "'s renowned expertise in vaccines. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " major vaccine tests, in partnership with \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    AstraZeneca and Sinovac\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", are to begin final phase testing on \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    thousands\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazilian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " volunteers.<br>Copyright \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2025\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    BBC\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". All rights reserved.  The \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    BBC\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is not responsible for the content of external sites. Read about our approach to external linking.<br> </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parsed_article = nlp_model(article_text)\n",
    "displacy.render(parsed_article,jupyter=True,style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6I8_zJQrpdl6"
   },
   "source": [
    "What do you think? Did it work?\n",
    "\n",
    "Let's have a bit of a better look at the entities found\n",
    "- List all the distinct entities found in the article, sorted alphabetically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1743369872572,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "SakcaXuypdl6",
    "outputId": "815dc21d-c48f-47bb-ca22-d2d64f16025e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.5 million',\n",
       " '20 June',\n",
       " '2025',\n",
       " '4 July',\n",
       " 'Amazonas',\n",
       " 'April',\n",
       " 'AstraZeneca and Sinovac',\n",
       " 'BBC',\n",
       " 'Bolsonaro',\n",
       " 'Brasilia',\n",
       " 'Brazil',\n",
       " 'Brazilian',\n",
       " 'Brazilians',\n",
       " 'Donald Trump',\n",
       " 'Ernesto Araújo',\n",
       " 'Folha de São Paulo',\n",
       " 'Independence Day',\n",
       " 'Jair Bolsonaro',\n",
       " 'Latin America',\n",
       " 'Mike Ryan',\n",
       " 'Monday',\n",
       " 'One',\n",
       " 'Rio de Janeiro',\n",
       " 'Sunday',\n",
       " 'São Paulo',\n",
       " 'Tuesday',\n",
       " 'Two',\n",
       " 'US',\n",
       " 'Will Jair Bolsonaro',\n",
       " 'fourth',\n",
       " 'his age, 65',\n",
       " 'nearly 1.7 million',\n",
       " 'one million',\n",
       " 'second',\n",
       " 'the World Health Organization',\n",
       " 'the past week',\n",
       " 'thousands',\n",
       " 'three',\n",
       " 'under 3,000 and 40,000 -']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(x.text for x in parsed_article.ents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyGeLXs8pdl6"
   },
   "source": [
    "We can count the number of times each **entity type** occurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1743369872610,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "mcmsbiUkpdl6",
    "outputId": "328b2f89-4408-4f8e-a9f8-c74ef4b3924c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'PERSON': 21,\n",
       "         'GPE': 16,\n",
       "         'DATE': 12,\n",
       "         'CARDINAL': 8,\n",
       "         'ORG': 6,\n",
       "         'ORDINAL': 3,\n",
       "         'NORP': 3,\n",
       "         'QUANTITY': 1,\n",
       "         'EVENT': 1,\n",
       "         'LOC': 1})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "labels = [x.label_ for x in parsed_article.ents]\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tb3g9y5Kpdl6"
   },
   "source": [
    "We can also count the number of times each **entity name** occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1743369872622,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "JPdOsoiApdl6",
    "outputId": "0863959a-d825-4533-b369-a6b5cf0e2f24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bolsonaro', 12),\n",
       " ('Brazil', 10),\n",
       " ('US', 4),\n",
       " ('Jair Bolsonaro', 3),\n",
       " ('Monday', 3),\n",
       " ('second', 2),\n",
       " ('Sunday', 2),\n",
       " ('Brazilians', 2),\n",
       " ('São Paulo', 2),\n",
       " ('Two', 2),\n",
       " ('BBC', 2),\n",
       " ('fourth', 1),\n",
       " ('Tuesday', 1),\n",
       " ('his age, 65', 1),\n",
       " ('Donald Trump', 1),\n",
       " ('three', 1),\n",
       " ('the World Health Organization', 1),\n",
       " ('Mike Ryan', 1),\n",
       " ('April', 1),\n",
       " ('under 3,000 and 40,000 -', 1),\n",
       " ('Ernesto Araújo', 1),\n",
       " ('Independence Day', 1),\n",
       " ('Brasilia', 1),\n",
       " ('4 July', 1),\n",
       " ('Folha de São Paulo', 1),\n",
       " ('nearly 1.7 million', 1),\n",
       " ('Will Jair Bolsonaro', 1),\n",
       " ('Latin America', 1),\n",
       " ('Amazonas', 1),\n",
       " ('Rio de Janeiro', 1),\n",
       " ('one million', 1),\n",
       " ('20 June', 1),\n",
       " ('1.5 million', 1),\n",
       " ('the past week', 1),\n",
       " ('One', 1),\n",
       " ('AstraZeneca and Sinovac', 1),\n",
       " ('thousands', 1),\n",
       " ('Brazilian', 1),\n",
       " ('2025', 1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [x.text for x in parsed_article.ents]\n",
    "Counter(items).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEV2BJCTpdl7"
   },
   "source": [
    "Note that some of the phrases refer to the same entity, e.g. 'Mr Bolsonaro' and just 'Bolsonaro'.\n",
    "- Entity Linking and Reference Resolution are the NLP problems that deal with resolving the different references to the same entity in the text.\n",
    "\n",
    "If we were only interested in what was being said about Bolsonaro,\n",
    "- we could select only sentences refering to him:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1743369872678,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "oNXjt46Jpdl7",
    "outputId": "9b2b9f7c-e8d7-4d38-9bd1-94a2891c4297"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Coronavirus: \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "'s President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " tests positive<br><br>\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "'s President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jair Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " has tested positive for coronavirus.<br></div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " has repeatedly played down risks of what he has called the &quot;little flu&quot;, saying he would not be seriously affected. </div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " said that he had started experiencing symptoms on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sunday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". </div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " is in a higher-risk group because of \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    his age, 65\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".<br></div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Contact tracing and tests will be carried out for the people Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " has met recently.<br></div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The executive director of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the World Health Organization\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", Dr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mike Ryan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", wished President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " &quot;a speedy and full recovery from this disease&quot;, adding: &quot;I think the message to us all is: we are vulnerable to this virus.</div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">&quot;<br>Back in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    April\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " said that even if infected, he would &quot;not have to worry as I wouldn't feel anything, at most it would be like a little flu or a little cold&quot;.<br></div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Despite this, President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " has argued that regional lockdowns are having a more damaging effect than the virus itself, and accused the media of spreading panic and paranoia.<br></div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">On \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sunday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", Foreign Minister \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ernesto Araújo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " posted a photo on social media showing himself with President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and others attending an \n",
       "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Independence Day\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
       "</mark>\n",
       " celebration at the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " embassy in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brasilia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". <br></div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    US\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " embassy said that the ambassador had had lunch with Mr \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and others on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    4 July\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ". </div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The ambassador had earlier tweeted a picture of himself with President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".<br></div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">For so long, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jair Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " has tried to brush off this virus - the irony that he has now caught it has not been missed in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". <br></div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">His detractors - of which he has many - have weighed in, calling this karma - that \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jair Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " invited this to happen. <br></div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">There was even a column in one of the biggest newspapers, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Folha de São Paulo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", entitled &quot;Why I'm Cheering for Bolsonaro to Die&quot; - this is how divided, how toxic  the political picture is here in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " as the pandemic takes hold. <br></div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">But the fact is, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " joins the \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 1.7 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazilians\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " who've contracted Covid-19. </div>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Will Jair Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " get away with mild symptoms and carry on downplaying it? </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences_containing_Bolsonaro = [x for x in parsed_article.sents if 'Bolsonaro' in x.text]\n",
    "displacy.render(sentences_containing_Bolsonaro,jupyter=True,style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkJvASO9pdl7"
   },
   "source": [
    "## Named Entity Extraction in Italian\n",
    "\n",
    "But wait, SpaCy can speak Italian too!\n",
    "- Let's make use of the pretrained italian model that we downloaded earlier: https://spacy.io/models/it\n",
    "- to recognise entities in an article from 'Il Corriere'\n",
    "\n",
    "First download the article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 907,
     "status": "ok",
     "timestamp": 1743369873586,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "BCTkJTsopdl7"
   },
   "outputs": [],
   "source": [
    "url = 'https://www.ansa.it/sito/notizie/mondo/2020/07/07/bolsonaro-ha-i-sintomi-del-coronavirus_40d26967-e377-4455-9b42-83c2756cf5f1.html'\n",
    "html_doc = requests.get(url).text\n",
    "parsed_doc = BeautifulSoup(html_doc, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrnqQcMOpdl7"
   },
   "source": [
    "Now let's extract the title and paragraph text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1743369873589,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "OIyIysghpdl7",
    "outputId": "1fc81485-eab3-40ef-b003-ccab2decd39e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bolsonaro positivo al test del coronavirus - Mondo - ANSA\n",
      "\n",
      "Se hai scelto di non accettare i cookie di  profilazione e tracciamento, puoi aderire all’abbonamento \"Consentless\" a un  costo molto accessibile, oppure scegliere un altro abbonamento per accedere ad ANSA.it.\n",
      "Ti invitiamo a leggere le Condizioni  Generali di Servizio, la Cookie Policy e l'Informativa Privacy. \n",
      "Puoi leggere tutti i titoli di ANSA.it e 10  contenuti ogni 30 giornia €16,99/anno\n",
      "Per accedere senza limiti a tutti i contenuti di ANSA.it\n",
      "Scegli il piano di  abbonamento più adatto alle tue esigenze.\n",
      "Se hai cambiato idea e non ti vuoi abbonare, puoi sempre esprimere il tuo consenso ai cookie di profilazione e tracciamento per leggere tutti i titoli di ANSA.it e 10 contenuti ogni 30 giorni (servizio base):\n",
      "Se accetti tutti i cookie di profilazione pubblicitaria e di tracciamento, noi e terze  parti selezionate utilizzeremo cookie e tecnologie simili per raccogliere ed  elaborare i tuoi dati personali e fornirti annunci e contenuti personalizzati,  valutare l’interazione con annunci e contenuti, effettuare ricerche di mercato,  migliorare i prodotti e i servizi.Per maggiori  informazioni accedi alla Cookie Policy e all'Informativa Privacy. \n",
      "Per maggiori informazioni sui servizi di ANSA.it, puoi consultare le nostre risposte alle domande più frequenti, oppure contattarci inviando una mail a register@ansa.it o telefonando al numero verde 800 938 881. Il servizio di assistenza clienti è attivo dal lunedì al venerdì dalle ore 09.00 alle ore 18:30, il sabato dalle ore 09:00 alle ore 14:00.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Il presidente brasiliano, Jair Bolsonaro, è risultato positivo al test sul Covid-19: lo ha reso noto lui stesso parlando in diretta a Tv Brasil dal Palacio da Alvorada, sua residenza ufficiale a Brasilia.    Ieri Bolsonaro aveva detto di sentirsi \"molto meglio, anche la febbre è scesa\". Bolsonaro - che ha già cancellato tutti gli impegni di lavoro previsti per questa settimana - aveva anche precisato che, non appena si è sentito male, ha iniziato ad assumere compresse di idrossiclorochina, seguendo l'esempio del suo omologo americano, Donald Trump, anche lui favorevole alla cura con il farmaco, spesso indicato per i casi di malaria.    Intanto, si è scatenato scatenato l'odio sul web contro il presidente brasiliano, accusato da più parti di aver sempre minimizzato la pandemia da coronavirus nel suo Paese.    In vetta ai 'trending topic' su Twitter in Brasile c'è infatti l'hashtag \"forca covid\" (forza covid). Una tendenza simile si era registrata anche all'epoca della positività di Boris Johnson, pure lui inizialmente scettico sulla gravità della malattia. Il premier britannico poi guarì dopo essere stato ricoverato in gravi condizioni.    Nel caso di Bolsonaro, il tenore della maggioranza dei tweet è forse ancora più violento, con migliaia di utenti che augurano apertamente la morte al capo di Stato verdeoro.    Prima di sottoporsi al test, Bolsonaro ha effettuato anche un esame dei polmoni. \"Vengo dall'ospedale, ho fatto una risonanza dei polmoni, sono puliti, tra un pò farò anche l'esame per il Covid, ma va tutto bene\", aveva spiegato lunedì sera il presidente della Repubblica a un gruppo di simpatizzanti che lo attendevano davanti al Palacio da Alvorada, la sua residenza ufficiale a Brasilia.   Bolsonaro si era già sottposto a due tamponi, poi risultati negativi, a marzo, dopo una visita negli Stati Uniti, al cui ritorno oltre 20 membri del suo staff erano risultati positivi. La scorsa settimana il presidente aveva detto che potrebbe avere contratto la malattia, pur senza manifestarne i sintomi, ma aveva ribadito la sua contrarietà al lockdown e ad altre misure restrittive imposte dalle autorità sanitarie per contenere la diffusione del coronavirus, difendendo la ripresa dell'economia.\n",
      "11:42\n",
      "10:27\n",
      "09:42\n",
      "06:09\n",
      "06:08\n",
      "06:04\n",
      "04:41\n",
      "00:55\n"
     ]
    }
   ],
   "source": [
    "title = parsed_doc.find('title').text\n",
    "paragraphs = [p.text for p in parsed_doc.find_all('p')]\n",
    "\n",
    "# Combine the title and paragraphs into a single text:\n",
    "article_text = title + '\\n\\n' + '\\n'.join(paragraphs)\n",
    "print(article_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eluDQCqxpdl7"
   },
   "source": [
    "Now we'll parse the text of the article with an Italian NLP engine to extract Named Entities.\n",
    "- First load the italian model 'it_core_news_sm' that we downloaded earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 1534,
     "status": "ok",
     "timestamp": 1743369875124,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "Qj0IIHlVpdl7"
   },
   "outputs": [],
   "source": [
    "nlp_it = spacy.load(\"it_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcWwDGlypdl8"
   },
   "source": [
    "Parse article and extract the entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 581,
     "status": "ok",
     "timestamp": 1743369875705,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "1X-Kuw6lpdl8",
    "outputId": "c1b95035-0e07-4146-94ab-61eb751968dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " positivo al test del coronavirus - Mondo - \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ANSA\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "<br><br>Se hai scelto di non accettare i cookie di  profilazione e tracciamento, puoi aderire all’abbonamento &quot;\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Consentless\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "&quot; a un  costo molto accessibile, oppure scegliere un altro abbonamento per accedere ad \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ANSA.it\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       ".<br>\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ti\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " invitiamo a leggere le \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Condizioni  Generali\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " di \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Servizio\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", la \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cookie Policy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " e l'\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Informativa Privacy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ". <br>Puoi leggere tutti i titoli di \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ANSA.it\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " e 10  contenuti ogni 30 giornia €16,99/anno<br>Per accedere senza limiti a tutti i contenuti di \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ANSA.it\n",
       "Scegli\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " il piano di  abbonamento più adatto alle tue esigenze.<br>Se hai cambiato idea e non ti vuoi abbonare, puoi sempre esprimere il tuo consenso ai cookie di profilazione e tracciamento per leggere tutti i titoli di \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ANSA.it\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " e 10 contenuti ogni 30 giorni (servizio base):<br>Se accetti tutti i cookie di profilazione pubblicitaria e di tracciamento, noi e terze  parti selezionate utilizzeremo cookie e tecnologie simili per raccogliere ed  elaborare i tuoi dati personali e fornirti annunci e contenuti personalizzati,  valutare l’interazione con annunci e contenuti, effettuare ricerche di mercato,  migliorare i prodotti e i servizi.Per maggiori  informazioni accedi alla \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cookie Policy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " e all'\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Informativa Privacy\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". <br>Per maggiori informazioni sui servizi di \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ANSA.it\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       ", puoi consultare le nostre risposte alle domande più frequenti, oppure contattarci inviando una mail a \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    register@ansa.it\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " o telefonando al numero verde 800 938 881. Il servizio di assistenza clienti è attivo dal lunedì al venerdì dalle ore 09.00 alle ore 18:30, il sabato dalle ore 09:00 alle ore 14:00.<br><br><br><br><br><br><br>    Il presidente brasiliano, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Jair Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", è risultato positivo al test sul Covid-19: lo ha reso noto lui stesso parlando in diretta a \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tv Brasil dal Palacio da Alvorada\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       ", sua residenza ufficiale a \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brasilia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".    \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ieri Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " aveva detto di sentirsi &quot;molto meglio, anche la febbre è scesa&quot;. \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro -\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " che ha già cancellato tutti gli impegni di lavoro previsti per questa settimana - aveva anche precisato che, non appena si è sentito male, ha iniziato ad assumere compresse di idrossiclorochina, seguendo l'esempio del suo omologo americano, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Donald Trump\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", anche lui favorevole alla cura con il farmaco, spesso indicato per i casi di malaria.    Intanto, si è scatenato scatenato l'odio sul web contro il presidente brasiliano, accusato da più parti di aver sempre minimizzato la pandemia da coronavirus nel suo \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Paese\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".    In vetta ai 'trending topic' su \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Twitter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brasile\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " c'è infatti l'\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    hashtag\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " &quot;forca covid&quot; (forza covid). Una tendenza simile si era registrata anche all'epoca della positività di \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Boris Johnson\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", pure lui inizialmente scettico sulla gravità della malattia. Il premier britannico poi guarì dopo essere stato ricoverato in gravi condizioni.    Nel caso di \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", il tenore della maggioranza dei tweet è forse ancora più violento, con migliaia di utenti che augurano apertamente la morte al capo di \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Stato\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " verdeoro.    Prima di sottoporsi al test, \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " ha effettuato anche un esame dei polmoni. &quot;\n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Vengo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " dall'ospedale, ho fatto una risonanza dei polmoni, sono puliti, tra un pò farò anche l'esame per il \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Covid\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       ", ma va tutto bene&quot;, aveva spiegato lunedì sera il presidente della \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Repubblica\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " a un gruppo di simpatizzanti che lo attendevano davanti al \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Palacio da Alvorada\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", la sua residenza ufficiale a \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brasilia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".   \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bolsonaro\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " si era già sottposto a due tamponi, poi risultati negativi, a marzo, dopo una visita negli \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Stati Uniti\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", al cui ritorno oltre 20 membri del suo staff erano risultati positivi. La scorsa settimana il presidente aveva detto che potrebbe avere contratto la malattia, pur senza manifestarne i sintomi, ma aveva ribadito la sua contrarietà al lockdown e ad altre misure restrittive imposte dalle autorità sanitarie per contenere la diffusione del coronavirus, difendendo la ripresa dell'economia.<br>11:42<br>10:27<br>09:42<br>06:09<br>06:08<br>06:04<br>04:41<br>00:55</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parsed_article = nlp_it(article_text)\n",
    "displacy.render(parsed_article, jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08h69wcxpdl8"
   },
   "source": [
    "That looks not great.\n",
    "- Here are the entities found in the news article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1743369875723,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "UKefi_fspdl8",
    "outputId": "35de4943-60f5-4259-d67b-8fb155d317f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ANSA',\n",
       " 'ANSA.it',\n",
       " 'ANSA.it\\nScegli',\n",
       " 'Bolsonaro',\n",
       " 'Bolsonaro -',\n",
       " 'Boris Johnson',\n",
       " 'Brasile',\n",
       " 'Brasilia',\n",
       " 'Condizioni  Generali',\n",
       " 'Consentless',\n",
       " 'Cookie Policy',\n",
       " 'Covid',\n",
       " 'Donald Trump',\n",
       " 'Ieri Bolsonaro',\n",
       " 'Informativa Privacy',\n",
       " 'Jair Bolsonaro',\n",
       " 'Paese',\n",
       " 'Palacio da Alvorada',\n",
       " 'Repubblica',\n",
       " 'Servizio',\n",
       " 'Stati Uniti',\n",
       " 'Stato',\n",
       " 'Ti',\n",
       " 'Tv Brasil dal Palacio da Alvorada',\n",
       " 'Twitter',\n",
       " 'Vengo',\n",
       " 'hashtag',\n",
       " 'register@ansa.it']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(x.text for x in parsed_article.ents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlicBTgepdl-"
   },
   "source": [
    "## Entity Linking in spaCy\n",
    "\n",
    "We don't want to just find entity mentions in a document but link them to a known entity in a knowledge base.\n",
    "- The task of linking the entity mentions to the corresponding entity in the knowledge base is called 'Entity Linking'.\n",
    "- Watch this video to learn more:\n",
    "https://spacy.io/universe/project/video-spacy-irl-entity-linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1743369875724,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "_BKB-yMKpdl-"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMb8j2-2XkPc"
   },
   "source": [
    "## Text Classification with a Recurrent Neural Network (using TensorFlow)\n",
    "\n",
    "In this last section of the notebook I will run through a quick example of using a Bidirectional LSTM (Long Short-term Memory) network for text classification.\n",
    "- RNNs extend embedding-based classification of text by taking word-order into account. They were, until relatively recently, the state-of-the-art when it came to training text classifiers.\n",
    "- Tensorflow is sophisticated toolkit for building Deep Neural Network models. We will use it to build the model. The tutorial follows mostly this Tensorflow tutorial: https://www.tensorflow.org/tutorials/text/text_classification_rnn\n",
    "    - Tensorflow is to deep learning learning what Java is to programming (joking...?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysjOGZrnXkPc"
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdiXno9jXkPc"
   },
   "source": [
    "First let's load the Twitter dataset we used in the second session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11260,
     "status": "ok",
     "timestamp": 1743369886990,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "WX-qsv-IXkPc",
    "outputId": "b157b9e0-8e80-4468-a1f1-893cc88f47f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /home/adrien/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('twitter_samples')\n",
    "\n",
    "from nltk.corpus import twitter_samples\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdKS2HdEXkPc"
   },
   "source": [
    "Remove emoticons from the positive and negative examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1743369887019,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "MQqqGPlYXkPc"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "emoticon_regex = '(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)'\n",
    "positive_tweets_noemoticons = [re.sub(emoticon_regex,'',tweet) for tweet in positive_tweets]\n",
    "negative_tweets_noemoticons = [re.sub(emoticon_regex,'',tweet) for tweet in negative_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMo6g9mcXkPc"
   },
   "source": [
    "And create the examples and labels as we did before. This time we will use numeric labels (0,1) instead of text labels ('negative','positive'), since the deep learning library we will use requires numeric class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1743369887029,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "sVAlgu-IXkPc"
   },
   "outputs": [],
   "source": [
    "tweets_x = positive_tweets_noemoticons + negative_tweets_noemoticons\n",
    "tweets_y = [1]*len(positive_tweets) + [0]*len(negative_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpMJO18SXkPc"
   },
   "source": [
    "And again, split the data into training, validation and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1743369887060,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "y2eXMPFuXkPc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "temp_x, test_x, temp_y, test_y = train_test_split(tweets_x, tweets_y, test_size=0.2)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(temp_x, temp_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFRtKN0gXkPc"
   },
   "source": [
    "Now that we have the training and validation data prepared, we can import the Tensorflow library, and use it to load the training and validaton datasets into the tensorflow format. Note that:\n",
    "- Tensorflow comes installed on Google Colab.\n",
    "- If you run this notebook on your own machine you will need to first install tensorflow using '!pip install'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13900,
     "status": "ok",
     "timestamp": 1743369900961,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "XBNoC2SQ6EKG",
    "outputId": "6aded9e9-a7a0-4cf6-ddce-4f7ac5a74f4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 14:49:14.737600: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-01 14:49:14.737641: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-01 14:49:14.739257: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-01 14:49:14.748575: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-01 14:49:16.058962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.1\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow 2 and tf.keras\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1743369901203,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "gykDCG4YXkPc"
   },
   "outputs": [],
   "source": [
    "train_tf = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "valid_tf = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeZgqPQYXkPc"
   },
   "source": [
    "Training will run on *batches* of the data at a time, so we need to create them.\n",
    "- We first use the shuffle command to randomise the order of the training data. (The buffer-size limits the number of instances loaded into memory when shuffling and is only for efficiency -- you could remove it.)\n",
    "- We then create the batches. Each batch will contain 64 examples.\n",
    "- The validation data needs to have the same format as the training data, so we batch it too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1743369901230,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "I3k_AJMVXkPc"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_tf.shuffle(buffer_size=10000).batch(batch_size=64).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_tf.batch(batch_size=64).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCIJun8hXkPc"
   },
   "source": [
    "Let's have a look at the first batch in the training data. It consists of:\n",
    "- an array of strings (tweets)\n",
    "- an array of binary values (class labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1743369901339,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "4sqXOO8JXkPd",
    "outputId": "02fc44e5-075e-43bb-f95d-8520f9b393ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(64,), dtype=string, numpy=\n",
      "array([b'@cericneesh Aspetti is good! I was boring and had chicken and chips for tea because my cupboards are empty. ',\n",
      "       b'Awww thank you   https://t.co/9tSQv2DWVm',\n",
      "       b'@PB_Furniture thanks peeps :)) @whittakerdesig1 @smart_bn @Klick_Business @makeyoucontent @REDlineCC @RedBizUK @earlybiz #HappyWeekend all!',\n",
      "       b'@jesuskylie @tothebeyhive thats not a good enough of a reason  please dont leave youre one of my fav barbs',\n",
      "       b'Good night  http://t.co/6JdSbTSeK5',\n",
      "       b'\\xe2\\x80\\x9c@MileyCyrus: Emu is stoked thank you  http://t.co/l5Xyt9EM6G\\xe2\\x80\\x9d @creampuffshinee',\n",
      "       b\"I miss everyone so much. Feel like I've not seen them in so long \",\n",
      "       b\"@nuttyxander didn't make it to the highlights then   They seem to have stopped talking about 'climbing on pure courage' - bit too fishy\",\n",
      "       b'@peterlizmaher Hi! Saw who u follow and thought u might like \"Dark\" https://t.co/aloXWsqdjh .Plz let us know what u think ',\n",
      "       b'@chuchuxiu shit rlly? i heard hamsters eat each other thats pretty fucked up hamsters r weird',\n",
      "       b'i was joking only man :(((((',\n",
      "       b\"@GeorgiaAnne1998 Aww I've already left!! I would have come and said hey if I had have seen it sooner  Have a good night! X\",\n",
      "       b'Thank you :-))) OK \\nHave fun!!\\n@anvy2446 @4HUMANITEEs @SexyAF12 @kikbella @adasamper @RachelLFilsoof\\nEnjoy day u all\\nhttp://t.co/5Y5OAESAzv',\n",
      "       b'@Aas2727 But living in good memories always cherish you as well ',\n",
      "       b\"@OL_EYY ahhh u see? U wouldn't wake up \",\n",
      "       b'@Raj_Poot_  ... mention not',\n",
      "       b'Kumpul cantik ganteng ~  (with Kresna, jelly, and 3 others at Simon &amp; Sons) [pic] \\xe2\\x80\\x94 https://t.co/n5N8XWYLXZ',\n",
      "       b\"I don't like this at all \",\n",
      "       b'@PKMN_Assassin GARRET!!! \\xe2\\x9d\\xa4 ',\n",
      "       b'i want all these bts merchs :(((',\n",
      "       b'@Gangesh_Gugi No thinking of writing myself ',\n",
      "       b\"@katjturgoose @artsjobs Link doesn't work! \",\n",
      "       b'@Wolf_Stack yeah by the looks of it ',\n",
      "       b'I could just really use a hug and maybe some icecream ',\n",
      "       b'\"@Real_Liam_Payne yeah thanks @zaynmalik for being so romantic and I love you too baby ! :)\"',\n",
      "       b'A little doodle of the star of my comic, Summoner, which will be back up soon  #art #doodle http://t.co/7bgF2Y1Zc2',\n",
      "       b'@stephbichard thank you Stephanie! Ily2 \\xf0\\x9f\\x92\\x96\\xf0\\x9f\\x92\\x96',\n",
      "       b\"Not 12 hours after my sister-in-law installed that new @DionoUSA seat we bought her she was rear-ended! everyone's fine but seat is trash \",\n",
      "       b'@pieterebersohn where are you watching the game? ',\n",
      "       b'Cant wait to get my Baller G Lil Faded chain \\nWhat Everybody Ought To Know',\n",
      "       b'@iamValC @keodancer @SashaFarber killin it! Meme worthy @EmmaSlaterDance? @Dance10Jenna  Cool shot of @Dance10Alan! http://t.co/hK74TOBM1u',\n",
      "       b\"Couldn't find any caramello koalas so I got a caramello bar... it's not the same \",\n",
      "       b\"@peacemakeruk Yes, Sue. It is a bit dreary isn't it? \",\n",
      "       b'@GrahamTownsend wait... is EVERYONE in that photo on the phone? I wonder if they are talking to each other lol ',\n",
      "       b'i have the least green fingers ever, I can\\xe2\\x80\\x99t even keep my basil plant alive ',\n",
      "       b\"@amyponce0830 I won't \", b\"@alyciasmarie but i wasn't :-((\",\n",
      "       b\"@LuiCalibre I'd be down but man i have to work right now \",\n",
      "       b'@jakeblackah what ya gotta be like that for  crapple!  @wigdogg agrees. Android FTW #phandroid',\n",
      "       b\"@jenxmish @wittykrushnic don't leave \",\n",
      "       b'@rivverofhoney Omg no way?! not you guys aswell  btw cat litter isnt good for pregnancy make sure u dont go near',\n",
      "       b\"@AllicioGloria She's gone :(, Hello, we offer you free perfume samples and Chanel/Burberry/Prada giveaway on our site! Please check our bio.\",\n",
      "       b\"I said gn along time ago my ass can't fall asleep \",\n",
      "       b'@seeyouelsewhere I hit the Map of The Googles and now I am more informed. Looks like quite a pretty little place ',\n",
      "       b'@nim_nams Hey hun! Unfortunately we would really have needed a model for a cut  Thanks so much though! &lt xxx',\n",
      "       b'@CMPunk @MattJackson13  please please come back to wwe  \\xd8\\xaa\\xd9\\x83\\xd9\\x81\\xd9\\x89',\n",
      "       b'@Migogos so true ',\n",
      "       b'@brigserman thanks for sharing! Wishing you a wicked weekend ',\n",
      "       b'Hungry ',\n",
      "       b'@davey_steven good morning Steve ...have a gooday! #ff ',\n",
      "       b'@NoraFrost the @therevnate is headlining in 2017 ',\n",
      "       b\"Wet holiday Friday  Console yourself in our cafe with Sophie Grigson's amazing carrot cake! http://t.co/WfzvRXz1Id\",\n",
      "       b'@Adacampbell thank you Ada . Long time no see',\n",
      "       b'Anyone who wants to be added to the bot just DM me!!  #bot',\n",
      "       b'@arsenalnewsasit  Thanks, wishing you back also. #LazyWeekend',\n",
      "       b'@AlexandraBjelk suger ',\n",
      "       b\"@EE I'm bad and kind of want an IPhone 6 but account says I can upgrade April 2016 too far  *cont\",\n",
      "       b'Collection.. http://t.co/TWLbiIbhUe #retweet',\n",
      "       b'@flurishing @blxcknicotine wow,looking good isabella! Makes me wanna start working out back ',\n",
      "       b'@urihoresh mb s/he needed more coffee  @cotterw',\n",
      "       b\"@__GiveawayDMs_ it's actually 1 AM here hehe  where do you live? It's strange to imagine...\",\n",
      "       b'Its Sept 4th #rudramadevi #anushka @RanaDaggubati #Gunashekar Sir  http://t.co/T0WI8giNeb',\n",
      "       b\"@lunatroye but snow is cold and gross and ew it's just a big mess because everyone just scrapes it into piles anyway \",\n",
      "       b\"this time in 20 days i'll have my results kms \"], dtype=object)>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0,\n",
      "       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0],\n",
      "      dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataset.take(1):\n",
    "  print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTwmMzIoXkPd"
   },
   "source": [
    "Now that we have the text data in the format required, we can vectorize it. We will need to make use a specific text vectorization module from tensorflow to do this.\n",
    "- We first limit the vocabulary of the vectorizer to 5000,\n",
    "- then extract only the text portion of the training dataset,\n",
    "- and finally fit the vectorizer to the text using the 'adapt' method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 1684,
     "status": "ok",
     "timestamp": 1743369903024,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "v6BrcfEoXkPd"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=5000)\n",
    "train_text = train_dataset.map(lambda text, label: text)\n",
    "vectorizer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lVOC3srXkPd"
   },
   "source": [
    "Let's print out the first tokens form the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1743369903066,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "hDErP-eLXkPd",
    "outputId": "95dcc3d5-0483-4032-d3a9-5cd6459f471c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'i',\n",
       " 'you',\n",
       " 'to',\n",
       " 'the',\n",
       " 'a',\n",
       " 'and',\n",
       " 'my',\n",
       " 'for',\n",
       " 'me',\n",
       " 'it',\n",
       " 'in',\n",
       " 'is',\n",
       " 'so',\n",
       " 'of',\n",
       " 'have',\n",
       " 'im',\n",
       " 'on',\n",
       " 'this',\n",
       " 'but',\n",
       " 'that',\n",
       " 'be',\n",
       " 'your',\n",
       " 'its',\n",
       " 'thanks',\n",
       " 'u',\n",
       " 'just',\n",
       " 'follow',\n",
       " 'like',\n",
       " 'no',\n",
       " 'with',\n",
       " 'we',\n",
       " 'love',\n",
       " 'not',\n",
       " 'all',\n",
       " 'was',\n",
       " 'are',\n",
       " 'at',\n",
       " 'too',\n",
       " 'please',\n",
       " 'get',\n",
       " 'do',\n",
       " 'can',\n",
       " 'dont',\n",
       " 'good',\n",
       " 'day',\n",
       " 'up',\n",
       " 'want',\n",
       " 'now',\n",
       " 'will',\n",
       " 'time',\n",
       " 'if',\n",
       " 'know',\n",
       " 'cant',\n",
       " 'thank',\n",
       " 'back',\n",
       " 'see',\n",
       " 'miss',\n",
       " 'what',\n",
       " 'one',\n",
       " 'amp',\n",
       " 'about',\n",
       " 'today',\n",
       " 'when',\n",
       " 'happy',\n",
       " 'out',\n",
       " 'much',\n",
       " 'go',\n",
       " 'our',\n",
       " 'hi',\n",
       " 'from',\n",
       " 'how',\n",
       " 'sorry',\n",
       " 'really',\n",
       " 'great',\n",
       " 'why',\n",
       " 'hope',\n",
       " 'they',\n",
       " 'more',\n",
       " 'as',\n",
       " 'new',\n",
       " 'he',\n",
       " 'got',\n",
       " 'still',\n",
       " 'some',\n",
       " 'there',\n",
       " 'ill',\n",
       " 'work',\n",
       " 'us',\n",
       " 'here',\n",
       " 'well',\n",
       " 'am',\n",
       " 'an',\n",
       " 'would',\n",
       " 'need',\n",
       " 'lt',\n",
       " 'going',\n",
       " 'been',\n",
       " 'again']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorizer.get_vocabulary()\n",
    "vocab[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2AnCbfIXkPd"
   },
   "source": [
    "Note that the first two tokens in the vocabulary are the empty token '', and the unknown token '[UNK]'. The latter is used to mask out-of-vocabulary tokens in the text\n",
    "\n",
    "We can now use the vectorizer to encode a tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1743369903119,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "reL7OIXpXkPd",
    "outputId": "f6aeb77b-57b1-4f16-d3f6-2011d6ab0215"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:      This is my first tweet! It contains one out-of-vocabulary term. Any suggestions for extending this tweet?\n",
      "Encoded:    [ 19  13   8 196 220  11   1  60   1   1 180   1   9   1  19 220]\n",
      "Recovered:  this is my first tweet it [UNK] one [UNK] [UNK] any [UNK] for [UNK] this tweet\n"
     ]
    }
   ],
   "source": [
    "text = 'This is my first tweet! It contains one out-of-vocabulary term. Any suggestions for extending this tweet?'\n",
    "encoding = vectorizer([text]).numpy()[0]\n",
    "print('Tweet:     ', text)\n",
    "print('Encoded:   ', encoding)\n",
    "print('Recovered: ',' '.join([vocab[i] for i in encoding]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0wCv-cPXkPd"
   },
   "source": [
    "Note that the vectorizer is not turning the text into a single vector, but is simply replacing the vocabulary words by their indices. If a word is not present in the dictionary it is replaced by the unknown token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAeaJ6WvXkPd"
   },
   "source": [
    "Let's have a look at some actual examples from the dataset, printing out the first 6 tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1743369903219,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "4aghpfMAXkPd",
    "outputId": "3577dc3c-cca6-41bb-9728-2e99348cc649"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:      @cericneesh Aspetti is good! I was boring and had chicken and chips for tea because my cupboards are empty. \n",
      "Encoded:    [   1    1   13   45    2   36 1114    7  126 1286    7 1595    9 1010\n",
      "  158    8    1   37 2067]\n",
      "Recovered:  [UNK] [UNK] is good i was boring and had chicken and chips for tea because my [UNK] are empty\n",
      "\n",
      "Tweet:      Awww thank you   https://t.co/9tSQv2DWVm\n",
      "Encoded:    [459  55   3   1]\n",
      "Recovered:  awww thank you [UNK]\n",
      "\n",
      "Tweet:      @PB_Furniture thanks peeps :)) @whittakerdesig1 @smart_bn @Klick_Business @makeyoucontent @REDlineCC @RedBizUK @earlybiz #HappyWeekend all!\n",
      "Encoded:    [2703   25 1435 1678 2487 1938    1 2610 2611 3275    1   35]\n",
      "Recovered:  pbfurniture thanks peeps whittakerdesig1 smartbn klickbusiness [UNK] redlinecc redbizuk earlybiz [UNK] all\n",
      "\n",
      "Tweet:      @jesuskylie @tothebeyhive thats not a good enough of a reason  please dont leave youre one of my fav barbs\n",
      "Encoded:    [   1 4861  100   34    6   45  349   15    6  638   40   44  329  101\n",
      "   60   15    8  956    1]\n",
      "Recovered:  [UNK] tothebeyhive thats not a good enough of a reason please dont leave youre one of my fav [UNK]\n",
      "\n",
      "Tweet:      Good night  http://t.co/6JdSbTSeK5\n",
      "Encoded:    [ 45 134   1]\n",
      "Recovered:  good night [UNK]\n",
      "\n",
      "Tweet:      “@MileyCyrus: Emu is stoked thank you  http://t.co/l5Xyt9EM6G” @creampuffshinee\n",
      "Encoded:    [3809    1   13    1   55    3    1    1]\n",
      "Recovered:  “mileycyrus [UNK] is [UNK] thank you [UNK] [UNK]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in batch[0][:6].numpy():\n",
    "    encoding = vectorizer([text]).numpy()[0]\n",
    "    print('Tweet:     ', text.decode(\"utf-8\"))\n",
    "    print('Encoded:   ', encoding)\n",
    "    print('Recovered: ',' '.join([vocab[i] for i in encoding]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeDyajurXkPd"
   },
   "source": [
    "### Defining and Training the RNN model\n",
    "\n",
    "Now we can define the model, which contains four layers:\n",
    "- an input embedding layer which produces word embeddings of size 64\n",
    "- a bidirectional LSTM layer\n",
    "- 2 dense (aka fully connected) layers that maps the 2 embedding vectors (of size 64) produced by the bidirectional LSTM down to a single neuron   \n",
    "\n",
    "This constitutes a relatively standard basic RNN architecture. (The details of why these specific components are chosen is beyond the scope of this tutorial.)  \n",
    "\n",
    "Once the model has been defined it is compiled in the following step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1743369903681,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "O7Db-xGTXkPd"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(1,), dtype=tf.string),\n",
    "    vectorizer,\n",
    "    tf.keras.layers.Embedding(input_dim=len(vectorizer.get_vocabulary()), output_dim=64, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'], optimizer=tf.keras.optimizers.Adam(1e-4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1rDwYISeVkR"
   },
   "source": [
    "Note that the output of a Bidirectional Layer is a concatenation of the forward and backward outputs. So the output of the Bidirectional layer is actually a tensor of size 128, which we project down first to a 64 size vector and than to a single neurons.\n",
    "- We can see this behaviour using the built in summary() method\n",
    "- We can also get an understanding of the number of parameters in the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1743369903684,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "5sTJuxM9eOXF",
    "outputId": "5ad47a28-e5b9-44c1-81e4-97ba63a2cf1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVe  (None, None)              0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 64)          320000    \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 128)               66048     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 394369 (1.50 MB)\n",
      "Trainable params: 394369 (1.50 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HfV0Z4Ff4z8"
   },
   "source": [
    "Most of the parameters are used to define the embedding, then the LSTMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDcdvj3fXkPd"
   },
   "source": [
    "Fit the model by running it for 10 epochs (iterations over the training data).\n",
    "- Note that we provide it with both the training dataset and the validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 100783,
     "status": "ok",
     "timestamp": 1743370004467,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "QNij_XUrXkPd",
    "outputId": "fba82206-d4c5-4d54-a029-98687fcf6886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 15s 49ms/step - loss: 0.6907 - accuracy: 0.4961 - val_loss: 0.6870 - val_accuracy: 0.5250\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.6639 - accuracy: 0.5175 - val_loss: 0.6300 - val_accuracy: 0.6508\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.5665 - accuracy: 0.6820 - val_loss: 0.5646 - val_accuracy: 0.7219\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.4824 - accuracy: 0.7597 - val_loss: 0.5395 - val_accuracy: 0.7492\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.4120 - accuracy: 0.8119 - val_loss: 0.5463 - val_accuracy: 0.7461\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.3559 - accuracy: 0.8481 - val_loss: 0.5611 - val_accuracy: 0.7484\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.3143 - accuracy: 0.8719 - val_loss: 0.5901 - val_accuracy: 0.7523\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.2774 - accuracy: 0.8873 - val_loss: 0.6220 - val_accuracy: 0.7516\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.2514 - accuracy: 0.9002 - val_loss: 0.6648 - val_accuracy: 0.7586\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 15ms/step - loss: 0.2264 - accuracy: 0.9098 - val_loss: 0.7463 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7a97a442e290>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=10, validation_data=valid_dataset, validation_steps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chkFHzAjXkPd"
   },
   "source": [
    "Once we've trained the model we can check the final accuracy on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1743370004852,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "6VGjzmPPXkPd",
    "outputId": "2d097a32-2082-4422-e8ad-ad022198212b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7248 - accuracy: 0.7619\n",
      "Validation Loss: 0.7247800230979919\n",
      "Validation Accuracy:  0.7618749737739563\n"
     ]
    }
   ],
   "source": [
    "valid_loss, valid_acc = model.evaluate(valid_dataset)\n",
    "\n",
    "print('Validation Loss: {}'.format(valid_loss))\n",
    "print('Validation Accuracy: ',valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUFlKyZwXkPd"
   },
   "source": [
    "We can have a look at the predictions from the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 607,
     "status": "ok",
     "timestamp": 1743370005467,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "n44pazsNXkPd",
    "outputId": "20f3131c-39bf-4973-fd00-eb950d3272f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "tweet:  I can't believe how much fun I'm having learning to train a text classifier with a bidirectional LSTM!\n",
      "encoded as:  i cant believe how much fun im having [UNK] to train a text [UNK] with a [UNK] [UNK]\n",
      "predicted value:  -3.5878637\n",
      "predicted label:  negative\n",
      "\n",
      "tweet:  I am really confused. I want my mommy.\n",
      "encoded as:  i am really confused i want my mommy\n",
      "predicted value:  -2.5696244\n",
      "predicted label:  negative\n",
      "\n",
      "tweet:  The internet connection has been pretty annoying today!\n",
      "encoded as:  the internet connection has been pretty annoying today\n",
      "predicted value:  -3.4238455\n",
      "predicted label:  negative\n",
      "\n",
      "tweet:  They just played my favourite song on the radio.\n",
      "encoded as:  they just [UNK] my favourite song on the radio\n",
      "predicted value:  0.16885017\n",
      "predicted label:  positive\n",
      "\n",
      "tweet:  I don't like going to the dentist.\n",
      "encoded as:  i dont like going to the [UNK]\n",
      "predicted value:  -0.23882802\n",
      "predicted label:  negative\n",
      "\n",
      "tweet:  I am so happy today!\n",
      "encoded as:  i am so happy today\n",
      "predicted value:  2.1249092\n",
      "predicted label:  positive\n",
      "\n",
      "tweet:  I am so unhappy today!\n",
      "encoded as:  i am so unhappy today\n",
      "predicted value:  -0.94986033\n",
      "predicted label:  negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "tweets.append('I can\\'t believe how much fun I\\'m having learning to train a text classifier with a bidirectional LSTM!')\n",
    "tweets.append('I am really confused. I want my mommy.')\n",
    "tweets.append('The internet connection has been pretty annoying today!')\n",
    "tweets.append('They just played my favourite song on the radio.')\n",
    "tweets.append(\"I don't like going to the dentist.\")\n",
    "tweets.append('I am so happy today!')\n",
    "tweets.append('I am so unhappy today!')\n",
    "\n",
    "predictions = model.predict(tf.convert_to_tensor(tweets))\n",
    "\n",
    "for i in range(len(tweets)):\n",
    "  print('tweet: ',tweets[i])\n",
    "  encoding = vectorizer([tweets[i]]).numpy()[0]\n",
    "  print('encoded as: ',' '.join([vocab[j] for j in encoding]))\n",
    "  print('predicted value: ', predictions[i][0])\n",
    "  print('predicted label: ', 'negative' if (predictions[i]<0) else 'positive')\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aV-2gZZtXkPd"
   },
   "source": [
    "And calculate the usual evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1282,
     "status": "ok",
     "timestamp": 1743370006750,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "-dBXIPMEXkPd",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "78d758cc-ee95-4ac1-a054-1bf57d781bd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 4ms/step\n",
      "accuracy: 0.73625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7a9729342c90>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "pred_y = [pred >= 0 for pred in model.predict(tf.convert_to_tensor(valid_x))]\n",
    "print('accuracy: '+ str(accuracy_score(pred_y, valid_y)))\n",
    "\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix(valid_y, pred_y,normalize='true'), display_labels=['negative', 'positive'])\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-BKhc-eXkPd"
   },
   "source": [
    "Finally, let's print out the model summary to get an understanding of the number of parameters in the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRDCLcREXkPe"
   },
   "source": [
    "### Encoder-Decoder models\n",
    "\n",
    "The next step after using sequential models for labelling and classification is to move to encoder-decoder models.\n",
    "Even better, encoder-decoder models with attention, to align the sequence processed by the encoder and the sequence processed by the decoder.\n",
    "\n",
    "We warmly recommend to take a look at this tutorial: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html (you can tun it in Google Colab).\n",
    "The tutorial shows how to build a translation model using recurrent neural networks and the attention mechanism.\n",
    "This was the last step before moving to the Transformer architectures (the current state-of-the-art).\n",
    "The tutorial is useful to get a better understanding of the attention mechanism and how it is used to learn the alignment between two sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1743370006751,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "nJoTyiqOXkPe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMS2GYrKXkPO"
   },
   "source": [
    "## Sequence labelling with Recurrent Neural Network (using PyTorch)\n",
    "\n",
    "In this section of the notebook I will run through an example of using LSTM (Long Short-term Memory) network for text sequence labelling.\n",
    "We can train our own model for POS-tagging or NER.\n",
    "Moreover, we can use pre-trained embedding models to encode the input text.\n",
    "\n",
    "- We are going to use PyTorch (https://pytorch.org) to build and train our model. Pytorch is a state-of-the-art framework for deep leaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6xs4SfcXkPP"
   },
   "source": [
    "### Data preparation\n",
    "\n",
    "As usual we start from data preparation.\n",
    "We can use the [CoNLL 2003](https://www.clips.uantwerpen.be/conll2003/ner/) corpus, which provides corpora for POS-tagging, Chunking and NER in English and German.\n",
    "Today we are going to focus on NER in English.\n",
    "\n",
    "You can find a copy the English split in the `docs/` directory.\n",
    "Usually the corpus should require preprocessing the data, here I am providing you with a version from Kaggle where documents have already been tagged (source: https://www.kaggle.com/datasets/alaakhaled/conll003-englishversion?resource=download)\n",
    "\n",
    "Let's start by loading the three files (train/validation/test) in memory and reading all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1174,
     "status": "ok",
     "timestamp": 1743370007926,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "BONoKuGNXkPP",
    "outputId": "bc40eb35-3dc8-4e4e-b83c-2327f218ef30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-DOCSTART- -X- -X- O\n",
      "\n",
      "EU NNP B-NP B-ORG\n",
      "rejects VBZ B-VP O\n",
      "German JJ B-NP B-MISC\n",
      "call NN I-NP O\n",
      "to TO B-VP O\n",
      "boycott VB I-VP O\n",
      "British JJ B-NP B-MISC\n",
      "lamb NN I-NP O\n",
      ". . O O\n",
      "\n",
      "Peter NNP B-NP B-PER\n",
      "Blackburn NNP I-NP I-PER\n",
      "\n",
      "BRUSSELS NNP B-NP B-LOC\n",
      "1996-08-22 CD I-NP O\n",
      "\n",
      "The DT B-NP O\n",
      "European NNP I-NP B-ORG\n",
      "Commission NNP I-NP I-ORG\n",
      "said VBD B-VP O\n",
      "on IN B-PP O\n",
      "Thursday NNP B-NP O\n",
      "it PRP B-NP O\n",
      "disagreed VBD B-VP O\n",
      "with IN B-PP O\n",
      "German JJ B-NP B-MISC\n",
      "advice NN I-NP O\n",
      "to TO B-PP O\n",
      "consumers NNS B-NP\n"
     ]
    }
   ],
   "source": [
    "raw_data = dict()\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    with open(f'docs/CoNLL - 2003/{split}.txt') as f:\n",
    "        raw_data[split] = f.read().strip()\n",
    "\n",
    "print(raw_data['train'][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vw6GFYkCXkPP"
   },
   "source": [
    "Now we can parse the data.\n",
    "Documents inside each split are separated by the sequence `-DOCSTART- -X- -X- O`.\n",
    "Sentences inside each document are separated by the sequence`\\n\\n` (two new-line characters).\n",
    "Each line inside a sentence represnets a token followed by the POS tag, the CHUNK tag and the NER tag, all separated by spaces.\n",
    "\n",
    "Here NER tags are written using a system called BIO-tagging.\n",
    "The 'B' stands for \"begin\" and introduces (starts) a new named entity, the tags are written as \"B-PER\" to indicate a person or \"B-LOC\" to indicate a location and so on.\n",
    "The 'I' stands for \"inside\" and continues a started named entity, the tags are written as \"I-PER\" to indicate a person or \"I-LOC\" to indicate a location and so on.\n",
    "The 'O' stands for outside, it means that the token is outside any named entity.\n",
    "There are other tagging systems.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1743370008440,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "xagcI6jWXkPP"
   },
   "outputs": [],
   "source": [
    "keys = ['text', 'pos_tag', 'chunk_tag', 'ner_tag']\n",
    "\n",
    "data = dict()\n",
    "\n",
    "for split in raw_data:\n",
    "    data[split] = list()\n",
    "    for doc in raw_data[split].split('-DOCSTART- -X- -X- O')[1:]:\n",
    "        for sentence in doc.strip().split('\\n\\n'):\n",
    "            data[split].append(list())\n",
    "            for elem in sentence.split('\\n'):\n",
    "                data[split][-1].append(dict(zip(keys, elem.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1743370008443,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "UXZPjL6RXkPP",
    "outputId": "b8d460db-ffa7-4958-83c4-de322005adc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'EU', 'pos_tag': 'NNP', 'chunk_tag': 'B-NP', 'ner_tag': 'B-ORG'},\n",
       " {'text': 'rejects', 'pos_tag': 'VBZ', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
       " {'text': 'German', 'pos_tag': 'JJ', 'chunk_tag': 'B-NP', 'ner_tag': 'B-MISC'},\n",
       " {'text': 'call', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
       " {'text': 'to', 'pos_tag': 'TO', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
       " {'text': 'boycott', 'pos_tag': 'VB', 'chunk_tag': 'I-VP', 'ner_tag': 'O'},\n",
       " {'text': 'British',\n",
       "  'pos_tag': 'JJ',\n",
       "  'chunk_tag': 'B-NP',\n",
       "  'ner_tag': 'B-MISC'},\n",
       " {'text': 'lamb', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
       " {'text': '.', 'pos_tag': '.', 'chunk_tag': 'O', 'ner_tag': 'O'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGQgUUNIXkPQ"
   },
   "source": [
    "Now all the labels are properly organised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtmKiY5eXkPQ"
   },
   "source": [
    "At this point we need a system to encode and decode the labels into categorical entities.\n",
    "We can use the label encoder from Scikit-Learn for that (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1743370008784,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "LjLyqAhgXkPQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pos_le = LabelEncoder().fit([token['pos_tag'] for split in data.values() for sentence in split for token in sentence])\n",
    "chunk_le = LabelEncoder().fit([token['pos_tag'] for split in data.values() for sentence in split for token in sentence])\n",
    "ner_le = LabelEncoder().fit([token['ner_tag'] for split in data.values() for sentence in split for token in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVFW52o8XkPQ"
   },
   "source": [
    "Now we have a module mapping from tags to IDs and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1743370008795,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "93KtbCVBXkPQ",
    "outputId": "ca94906d-0405-47c4-aa10-36b38ea814ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tag = ['I-PER']\n",
    "ner_tag = ['I-LOC']\n",
    "ner_tag = ['B-PER']\n",
    "# ner_tag = ['O']\n",
    "\n",
    "ner_le.transform(ner_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1743370008807,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "mFDxhaMnXkPQ",
    "outputId": "55de7c71-b945-4468-e17e-216d9b998952"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-LOC'], dtype='<U6')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tag_id = [0]\n",
    "\n",
    "ner_le.inverse_transform(ner_tag_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOVxouSbXkPQ"
   },
   "source": [
    "How many NER tags do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1743370008815,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "XP7h6lsQXkPQ",
    "outputId": "3111952b-8a96-4c8e-dc7e-969d9309941b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ner_le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObAM_0yLXkPQ"
   },
   "source": [
    "Which are those tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1743370008823,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "5cNrY9QmXkPQ",
    "outputId": "f9bccdfd-b12a-47e9-8a1f-3b2fbac57297"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG',\n",
       "       'I-PER', 'O'], dtype='<U6')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKcRUmgnXkPQ"
   },
   "source": [
    "Collect the same info for POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743370008827,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "6ywrLqj2XkPQ"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuOZxaJVXkPQ"
   },
   "source": [
    "Finally we separate our train-validation-test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743370008835,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "ghCasG1MXkPQ"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = data.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1743370008892,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "ejkBWKyN5kpo",
    "outputId": "85b62e22-0326-4092-d2ab-12f7dd5adbde"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'EU', 'pos_tag': 'NNP', 'chunk_tag': 'B-NP', 'ner_tag': 'B-ORG'},\n",
       " {'text': 'rejects', 'pos_tag': 'VBZ', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
       " {'text': 'German', 'pos_tag': 'JJ', 'chunk_tag': 'B-NP', 'ner_tag': 'B-MISC'},\n",
       " {'text': 'call', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
       " {'text': 'to', 'pos_tag': 'TO', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
       " {'text': 'boycott', 'pos_tag': 'VB', 'chunk_tag': 'I-VP', 'ner_tag': 'O'},\n",
       " {'text': 'British',\n",
       "  'pos_tag': 'JJ',\n",
       "  'chunk_tag': 'B-NP',\n",
       "  'ner_tag': 'B-MISC'},\n",
       " {'text': 'lamb', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
       " {'text': '.', 'pos_tag': '.', 'chunk_tag': 'O', 'ner_tag': 'O'}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PmNu1Rl3Yy_"
   },
   "source": [
    "Now let's build our simple vocabulary made up of all the words in our training set. We need a mapping of word->token to use to feed our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1743370008934,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "lZOW6gjY9LKJ",
    "outputId": "c3b0f457-5f0a-41f2-cb10-7116fb0b409c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 23625\n",
      "Number of NER tags: 10\n"
     ]
    }
   ],
   "source": [
    "def build_vocab_and_tags(data):\n",
    "    word2idx = {\"<PAD>\": 0, \"<UNK>\": 1}  # Il token di padding e il token delle parole out-of-vocabulary hanno indici riservati\n",
    "    tag2idx = {\"<PAD>\": 0}  # Deve essere lo stesso indice di padding degll'input!\n",
    "    for sent in data:\n",
    "        for token in sent:\n",
    "            word = token[\"text\"]\n",
    "            tag = token[\"ner_tag\"]\n",
    "            if word not in word2idx:\n",
    "                word2idx[word] = len(word2idx)\n",
    "            if tag not in tag2idx:\n",
    "                tag2idx[tag] = len(tag2idx)\n",
    "    return word2idx, tag2idx\n",
    "\n",
    "word2idx, tag2idx = build_vocab_and_tags(train_data)\n",
    "vocab_size = len(word2idx)\n",
    "num_tags = len(tag2idx)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Number of NER tags: {num_tags}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DchV6p61-nOf"
   },
   "source": [
    "We can inspect our mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1743370008990,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "sxSkn0M--qfx",
    "outputId": "bf67731e-337c-4103-9703-ef034c7f1609"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<UNK>': 1,\n",
       " 'EU': 2,\n",
       " 'rejects': 3,\n",
       " 'German': 4,\n",
       " 'call': 5,\n",
       " 'to': 6,\n",
       " 'boycott': 7,\n",
       " 'British': 8,\n",
       " 'lamb': 9,\n",
       " '.': 10,\n",
       " 'Peter': 11,\n",
       " 'Blackburn': 12,\n",
       " 'BRUSSELS': 13,\n",
       " '1996-08-22': 14,\n",
       " 'The': 15,\n",
       " 'European': 16,\n",
       " 'Commission': 17,\n",
       " 'said': 18,\n",
       " 'on': 19,\n",
       " 'Thursday': 20,\n",
       " 'it': 21,\n",
       " 'disagreed': 22,\n",
       " 'with': 23,\n",
       " 'advice': 24,\n",
       " 'consumers': 25,\n",
       " 'shun': 26,\n",
       " 'until': 27,\n",
       " 'scientists': 28,\n",
       " 'determine': 29,\n",
       " 'whether': 30,\n",
       " 'mad': 31,\n",
       " 'cow': 32,\n",
       " 'disease': 33,\n",
       " 'can': 34,\n",
       " 'be': 35,\n",
       " 'transmitted': 36,\n",
       " 'sheep': 37,\n",
       " 'Germany': 38,\n",
       " \"'s\": 39,\n",
       " 'representative': 40,\n",
       " 'the': 41,\n",
       " 'Union': 42,\n",
       " 'veterinary': 43,\n",
       " 'committee': 44,\n",
       " 'Werner': 45,\n",
       " 'Zwingmann': 46,\n",
       " 'Wednesday': 47,\n",
       " 'should': 48,\n",
       " 'buy': 49,\n",
       " 'sheepmeat': 50,\n",
       " 'from': 51,\n",
       " 'countries': 52,\n",
       " 'other': 53,\n",
       " 'than': 54,\n",
       " 'Britain': 55,\n",
       " 'scientific': 56,\n",
       " 'was': 57,\n",
       " 'clearer': 58,\n",
       " '\"': 59,\n",
       " 'We': 60,\n",
       " 'do': 61,\n",
       " \"n't\": 62,\n",
       " 'support': 63,\n",
       " 'any': 64,\n",
       " 'such': 65,\n",
       " 'recommendation': 66,\n",
       " 'because': 67,\n",
       " 'we': 68,\n",
       " 'see': 69,\n",
       " 'grounds': 70,\n",
       " 'for': 71,\n",
       " ',': 72,\n",
       " 'chief': 73,\n",
       " 'spokesman': 74,\n",
       " 'Nikolaus': 75,\n",
       " 'van': 76,\n",
       " 'der': 77,\n",
       " 'Pas': 78,\n",
       " 'told': 79,\n",
       " 'a': 80,\n",
       " 'news': 81,\n",
       " 'briefing': 82,\n",
       " 'He': 83,\n",
       " 'further': 84,\n",
       " 'study': 85,\n",
       " 'required': 86,\n",
       " 'and': 87,\n",
       " 'if': 88,\n",
       " 'found': 89,\n",
       " 'that': 90,\n",
       " 'action': 91,\n",
       " 'needed': 92,\n",
       " 'taken': 93,\n",
       " 'by': 94,\n",
       " 'proposal': 95,\n",
       " 'last': 96,\n",
       " 'month': 97,\n",
       " 'Farm': 98,\n",
       " 'Commissioner': 99,\n",
       " 'Franz': 100,\n",
       " 'Fischler': 101,\n",
       " 'ban': 102,\n",
       " 'brains': 103,\n",
       " 'spleens': 104,\n",
       " 'spinal': 105,\n",
       " 'cords': 106,\n",
       " 'human': 107,\n",
       " 'animal': 108,\n",
       " 'food': 109,\n",
       " 'chains': 110,\n",
       " 'highly': 111,\n",
       " 'specific': 112,\n",
       " 'precautionary': 113,\n",
       " 'move': 114,\n",
       " 'protect': 115,\n",
       " 'health': 116,\n",
       " 'proposed': 117,\n",
       " 'EU-wide': 118,\n",
       " 'measures': 119,\n",
       " 'after': 120,\n",
       " 'reports': 121,\n",
       " 'France': 122,\n",
       " 'under': 123,\n",
       " 'laboratory': 124,\n",
       " 'conditions': 125,\n",
       " 'could': 126,\n",
       " 'contract': 127,\n",
       " 'Bovine': 128,\n",
       " 'Spongiform': 129,\n",
       " 'Encephalopathy': 130,\n",
       " '(': 131,\n",
       " 'BSE': 132,\n",
       " ')': 133,\n",
       " '--': 134,\n",
       " 'But': 135,\n",
       " 'agreed': 136,\n",
       " 'review': 137,\n",
       " 'his': 138,\n",
       " 'standing': 139,\n",
       " 'mational': 140,\n",
       " 'officials': 141,\n",
       " 'questioned': 142,\n",
       " 'justified': 143,\n",
       " 'as': 144,\n",
       " 'there': 145,\n",
       " 'only': 146,\n",
       " 'slight': 147,\n",
       " 'risk': 148,\n",
       " 'Spanish': 149,\n",
       " 'Minister': 150,\n",
       " 'Loyola': 151,\n",
       " 'de': 152,\n",
       " 'Palacio': 153,\n",
       " 'had': 154,\n",
       " 'earlier': 155,\n",
       " 'accused': 156,\n",
       " 'at': 157,\n",
       " 'an': 158,\n",
       " 'farm': 159,\n",
       " 'ministers': 160,\n",
       " \"'\": 161,\n",
       " 'meeting': 162,\n",
       " 'of': 163,\n",
       " 'causing': 164,\n",
       " 'unjustified': 165,\n",
       " 'alarm': 166,\n",
       " 'through': 167,\n",
       " 'dangerous': 168,\n",
       " 'generalisation': 169,\n",
       " 'Only': 170,\n",
       " 'backed': 171,\n",
       " 'multidisciplinary': 172,\n",
       " 'committees': 173,\n",
       " 'are': 174,\n",
       " 'due': 175,\n",
       " 're-examine': 176,\n",
       " 'issue': 177,\n",
       " 'early': 178,\n",
       " 'next': 179,\n",
       " 'make': 180,\n",
       " 'recommendations': 181,\n",
       " 'senior': 182,\n",
       " 'Sheep': 183,\n",
       " 'have': 184,\n",
       " 'long': 185,\n",
       " 'been': 186,\n",
       " 'known': 187,\n",
       " 'scrapie': 188,\n",
       " 'brain-wasting': 189,\n",
       " 'similar': 190,\n",
       " 'which': 191,\n",
       " 'is': 192,\n",
       " 'believed': 193,\n",
       " 'transferred': 194,\n",
       " 'cattle': 195,\n",
       " 'feed': 196,\n",
       " 'containing': 197,\n",
       " 'waste': 198,\n",
       " 'farmers': 199,\n",
       " 'denied': 200,\n",
       " 'danger': 201,\n",
       " 'their': 202,\n",
       " 'but': 203,\n",
       " 'expressed': 204,\n",
       " 'concern': 205,\n",
       " 'government': 206,\n",
       " 'avoid': 207,\n",
       " 'might': 208,\n",
       " 'influence': 209,\n",
       " 'across': 210,\n",
       " 'Europe': 211,\n",
       " 'What': 212,\n",
       " 'extremely': 213,\n",
       " 'careful': 214,\n",
       " 'how': 215,\n",
       " 'going': 216,\n",
       " 'take': 217,\n",
       " 'lead': 218,\n",
       " 'Welsh': 219,\n",
       " 'National': 220,\n",
       " 'Farmers': 221,\n",
       " 'NFU': 222,\n",
       " 'chairman': 223,\n",
       " 'John': 224,\n",
       " 'Lloyd': 225,\n",
       " 'Jones': 226,\n",
       " 'BBC': 227,\n",
       " 'radio': 228,\n",
       " 'Bonn': 229,\n",
       " 'has': 230,\n",
       " 'led': 231,\n",
       " 'efforts': 232,\n",
       " 'public': 233,\n",
       " 'consumer': 234,\n",
       " 'confidence': 235,\n",
       " 'collapsed': 236,\n",
       " 'in': 237,\n",
       " 'March': 238,\n",
       " 'report': 239,\n",
       " 'suggested': 240,\n",
       " 'humans': 241,\n",
       " 'illness': 242,\n",
       " 'eating': 243,\n",
       " 'contaminated': 244,\n",
       " 'beef': 245,\n",
       " 'imported': 246,\n",
       " '47,600': 247,\n",
       " 'year': 248,\n",
       " 'nearly': 249,\n",
       " 'half': 250,\n",
       " 'total': 251,\n",
       " 'imports': 252,\n",
       " 'It': 253,\n",
       " 'brought': 254,\n",
       " '4,275': 255,\n",
       " 'tonnes': 256,\n",
       " 'mutton': 257,\n",
       " 'some': 258,\n",
       " '10': 259,\n",
       " 'percent': 260,\n",
       " 'overall': 261,\n",
       " 'Rare': 262,\n",
       " 'Hendrix': 263,\n",
       " 'song': 264,\n",
       " 'draft': 265,\n",
       " 'sells': 266,\n",
       " 'almost': 267,\n",
       " '$': 268,\n",
       " '17,000': 269,\n",
       " 'LONDON': 270,\n",
       " 'A': 271,\n",
       " 'rare': 272,\n",
       " 'handwritten': 273,\n",
       " 'U.S.': 274,\n",
       " 'guitar': 275,\n",
       " 'legend': 276,\n",
       " 'Jimi': 277,\n",
       " 'sold': 278,\n",
       " 'auction': 279,\n",
       " 'late': 280,\n",
       " 'musician': 281,\n",
       " 'favourite': 282,\n",
       " 'possessions': 283,\n",
       " 'Florida': 284,\n",
       " 'restaurant': 285,\n",
       " 'paid': 286,\n",
       " '10,925': 287,\n",
       " 'pounds': 288,\n",
       " '16,935': 289,\n",
       " 'Ai': 290,\n",
       " 'no': 291,\n",
       " 'telling': 292,\n",
       " 'penned': 293,\n",
       " 'piece': 294,\n",
       " 'London': 295,\n",
       " 'hotel': 296,\n",
       " 'stationery': 297,\n",
       " '1966': 298,\n",
       " 'At': 299,\n",
       " 'end': 300,\n",
       " 'January': 301,\n",
       " '1967': 302,\n",
       " 'concert': 303,\n",
       " 'English': 304,\n",
       " 'city': 305,\n",
       " 'Nottingham': 306,\n",
       " 'he': 307,\n",
       " 'threw': 308,\n",
       " 'sheet': 309,\n",
       " 'paper': 310,\n",
       " 'into': 311,\n",
       " 'audience': 312,\n",
       " 'where': 313,\n",
       " 'retrieved': 314,\n",
       " 'fan': 315,\n",
       " 'Buyers': 316,\n",
       " 'also': 317,\n",
       " 'snapped': 318,\n",
       " 'up': 319,\n",
       " '16': 320,\n",
       " 'items': 321,\n",
       " 'were': 322,\n",
       " 'put': 323,\n",
       " 'former': 324,\n",
       " 'girlfriend': 325,\n",
       " 'Kathy': 326,\n",
       " 'Etchingham': 327,\n",
       " 'who': 328,\n",
       " 'lived': 329,\n",
       " 'him': 330,\n",
       " '1969': 331,\n",
       " 'They': 332,\n",
       " 'included': 333,\n",
       " 'black': 334,\n",
       " 'lacquer': 335,\n",
       " 'mother': 336,\n",
       " 'pearl': 337,\n",
       " 'inlaid': 338,\n",
       " 'box': 339,\n",
       " 'used': 340,\n",
       " 'store': 341,\n",
       " 'drugs': 342,\n",
       " 'anonymous': 343,\n",
       " 'Australian': 344,\n",
       " 'purchaser': 345,\n",
       " 'bought': 346,\n",
       " '5,060': 347,\n",
       " '7,845': 348,\n",
       " 'guitarist': 349,\n",
       " 'died': 350,\n",
       " 'overdose': 351,\n",
       " '1970': 352,\n",
       " 'aged': 353,\n",
       " '27': 354,\n",
       " 'China': 355,\n",
       " 'says': 356,\n",
       " 'Taiwan': 357,\n",
       " 'spoils': 358,\n",
       " 'atmosphere': 359,\n",
       " 'talks': 360,\n",
       " 'BEIJING': 361,\n",
       " 'Taipei': 362,\n",
       " 'spoiling': 363,\n",
       " 'resumption': 364,\n",
       " 'Strait': 365,\n",
       " 'visit': 366,\n",
       " 'Ukraine': 367,\n",
       " 'Taiwanese': 368,\n",
       " 'Vice': 369,\n",
       " 'President': 370,\n",
       " 'Lien': 371,\n",
       " 'Chan': 372,\n",
       " 'this': 373,\n",
       " 'week': 374,\n",
       " 'infuriated': 375,\n",
       " 'Beijing': 376,\n",
       " 'Speaking': 377,\n",
       " 'hours': 378,\n",
       " 'Chinese': 379,\n",
       " 'state': 380,\n",
       " 'media': 381,\n",
       " 'time': 382,\n",
       " 'right': 383,\n",
       " 'engage': 384,\n",
       " 'political': 385,\n",
       " 'Foreign': 386,\n",
       " 'Ministry': 387,\n",
       " 'Shen': 388,\n",
       " 'Guofang': 389,\n",
       " 'Reuters': 390,\n",
       " ':': 391,\n",
       " 'necessary': 392,\n",
       " 'opening': 393,\n",
       " 'disrupted': 394,\n",
       " 'authorities': 395,\n",
       " 'State': 396,\n",
       " 'quoted': 397,\n",
       " 'top': 398,\n",
       " 'negotiator': 399,\n",
       " 'Tang': 400,\n",
       " 'Shubei': 401,\n",
       " 'visiting': 402,\n",
       " 'group': 403,\n",
       " 'rivals': 404,\n",
       " 'hold': 405,\n",
       " 'Now': 406,\n",
       " 'two': 407,\n",
       " 'sides': 408,\n",
       " '...': 409,\n",
       " 'hostility': 410,\n",
       " 'overseas': 411,\n",
       " 'edition': 412,\n",
       " 'People': 413,\n",
       " 'Daily': 414,\n",
       " 'saying': 415,\n",
       " 'foreign': 416,\n",
       " 'ministry': 417,\n",
       " 'Television': 418,\n",
       " 'interview': 419,\n",
       " 'read': 420,\n",
       " 'comments': 421,\n",
       " 'gave': 422,\n",
       " 'details': 423,\n",
       " 'why': 424,\n",
       " 'considered': 425,\n",
       " 'considers': 426,\n",
       " 'renegade': 427,\n",
       " 'province': 428,\n",
       " 'opposed': 429,\n",
       " 'all': 430,\n",
       " 'gain': 431,\n",
       " 'greater': 432,\n",
       " 'international': 433,\n",
       " 'recognition': 434,\n",
       " 'rival': 435,\n",
       " 'island': 436,\n",
       " 'practical': 437,\n",
       " 'steps': 438,\n",
       " 'towards': 439,\n",
       " 'goal': 440,\n",
       " 'Consultations': 441,\n",
       " 'held': 442,\n",
       " 'set': 443,\n",
       " 'format': 444,\n",
       " 'official': 445,\n",
       " 'Xinhua': 446,\n",
       " 'agency': 447,\n",
       " 'executive': 448,\n",
       " 'vice': 449,\n",
       " 'Association': 450,\n",
       " 'Relations': 451,\n",
       " 'Across': 452,\n",
       " 'Straits': 453,\n",
       " 'July': 454,\n",
       " 'car': 455,\n",
       " 'registrations': 456,\n",
       " '14.2': 457,\n",
       " 'pct': 458,\n",
       " 'yr': 459,\n",
       " '/': 460,\n",
       " 'FRANKFURT': 461,\n",
       " 'first-time': 462,\n",
       " 'motor': 463,\n",
       " 'vehicles': 464,\n",
       " 'jumped': 465,\n",
       " 'year-earlier': 466,\n",
       " 'period': 467,\n",
       " 'Federal': 468,\n",
       " 'office': 469,\n",
       " '356,725': 470,\n",
       " 'new': 471,\n",
       " 'cars': 472,\n",
       " 'registered': 473,\n",
       " '1996': 474,\n",
       " '304,850': 475,\n",
       " 'passenger': 476,\n",
       " '15,613': 477,\n",
       " 'trucks': 478,\n",
       " 'figures': 479,\n",
       " 'represent': 480,\n",
       " '13.6': 481,\n",
       " 'increase': 482,\n",
       " '2.2': 483,\n",
       " 'decline': 484,\n",
       " '1995': 485,\n",
       " 'Motor-bike': 486,\n",
       " 'registration': 487,\n",
       " 'rose': 488,\n",
       " '32.7': 489,\n",
       " 'growth': 490,\n",
       " 'partly': 491,\n",
       " 'increased': 492,\n",
       " 'number': 493,\n",
       " 'Germans': 494,\n",
       " 'buying': 495,\n",
       " 'abroad': 496,\n",
       " 'while': 497,\n",
       " 'manufacturers': 498,\n",
       " 'domestic': 499,\n",
       " 'demand': 500,\n",
       " 'weak': 501,\n",
       " 'federal': 502,\n",
       " 'Almost': 503,\n",
       " 'posted': 504,\n",
       " 'gains': 505,\n",
       " 'numbers': 506,\n",
       " 'Volkswagen': 507,\n",
       " 'AG': 508,\n",
       " 'won': 509,\n",
       " '77,719': 510,\n",
       " 'slightly': 511,\n",
       " 'more': 512,\n",
       " 'quarter': 513,\n",
       " 'Opel': 514,\n",
       " 'together': 515,\n",
       " 'General': 516,\n",
       " 'Motors': 517,\n",
       " 'came': 518,\n",
       " 'second': 519,\n",
       " 'place': 520,\n",
       " '49,269': 521,\n",
       " '16.4': 522,\n",
       " 'figure': 523,\n",
       " 'Third': 524,\n",
       " 'Ford': 525,\n",
       " '35,563': 526,\n",
       " 'or': 527,\n",
       " '11.7': 528,\n",
       " 'Seat': 529,\n",
       " 'Porsche': 530,\n",
       " 'fewer': 531,\n",
       " 'compared': 532,\n",
       " '3,420': 533,\n",
       " '5522': 534,\n",
       " 'fell': 535,\n",
       " '554': 536,\n",
       " '643': 537,\n",
       " 'GREEK': 538,\n",
       " 'SOCIALISTS': 539,\n",
       " 'GIVE': 540,\n",
       " 'GREEN': 541,\n",
       " 'LIGHT': 542,\n",
       " 'TO': 543,\n",
       " 'PM': 544,\n",
       " 'FOR': 545,\n",
       " 'ELECTIONS': 546,\n",
       " 'ATHENS': 547,\n",
       " 'Greek': 548,\n",
       " 'socialist': 549,\n",
       " 'party': 550,\n",
       " 'bureau': 551,\n",
       " 'green': 552,\n",
       " 'light': 553,\n",
       " 'Prime': 554,\n",
       " 'Costas': 555,\n",
       " 'Simitis': 556,\n",
       " 'snap': 557,\n",
       " 'elections': 558,\n",
       " 'its': 559,\n",
       " 'general': 560,\n",
       " 'secretary': 561,\n",
       " 'Skandalidis': 562,\n",
       " 'reporters': 563,\n",
       " 'announcement': 564,\n",
       " 'cabinet': 565,\n",
       " 'later': 566,\n",
       " 'Dimitris': 567,\n",
       " 'Kontogiannis': 568,\n",
       " 'Athens': 569,\n",
       " 'Newsroom': 570,\n",
       " '+301': 571,\n",
       " '3311812-4': 572,\n",
       " 'BayerVB': 573,\n",
       " 'sets': 574,\n",
       " 'C$': 575,\n",
       " '100': 576,\n",
       " 'million': 577,\n",
       " 'six-year': 578,\n",
       " 'bond': 579,\n",
       " 'following': 580,\n",
       " 'announced': 581,\n",
       " 'manager': 582,\n",
       " 'Toronto': 583,\n",
       " 'Dominion': 584,\n",
       " 'BORROWER': 585,\n",
       " 'BAYERISCHE': 586,\n",
       " 'VEREINSBANK': 587,\n",
       " 'AMT': 588,\n",
       " 'MLN': 589,\n",
       " 'COUPON': 590,\n",
       " '6.625': 591,\n",
       " 'MATURITY': 592,\n",
       " '24.SEP.02': 593,\n",
       " 'TYPE': 594,\n",
       " 'STRAIGHT': 595,\n",
       " 'ISS': 596,\n",
       " 'PRICE': 597,\n",
       " '100.92': 598,\n",
       " 'PAY': 599,\n",
       " 'DATE': 600,\n",
       " '24.SEP.96': 601,\n",
       " 'FULL': 602,\n",
       " 'FEES': 603,\n",
       " '1.875': 604,\n",
       " 'REOFFER': 605,\n",
       " '99.32': 606,\n",
       " 'SPREAD': 607,\n",
       " '+20': 608,\n",
       " 'BP': 609,\n",
       " 'MOODY': 610,\n",
       " 'AA1': 611,\n",
       " 'LISTING': 612,\n",
       " 'LUX': 613,\n",
       " 'FREQ': 614,\n",
       " '=': 615,\n",
       " 'S&P': 616,\n",
       " 'DENOMS': 617,\n",
       " 'K': 618,\n",
       " '1-10-100': 619,\n",
       " 'SALE': 620,\n",
       " 'LIMITS': 621,\n",
       " 'US': 622,\n",
       " 'UK': 623,\n",
       " 'CA': 624,\n",
       " 'NEG': 625,\n",
       " 'PLG': 626,\n",
       " 'NO': 627,\n",
       " 'CRS': 628,\n",
       " 'DEFLT': 629,\n",
       " 'FORCE': 630,\n",
       " 'MAJ': 631,\n",
       " 'GOV': 632,\n",
       " 'LAW': 633,\n",
       " 'GERMAN': 634,\n",
       " 'HOME': 635,\n",
       " 'CTRY': 636,\n",
       " 'TAX': 637,\n",
       " 'PROVS': 638,\n",
       " 'STANDARD': 639,\n",
       " 'MGT': 640,\n",
       " 'UND': 641,\n",
       " '0.275': 642,\n",
       " 'SELL': 643,\n",
       " 'CONC': 644,\n",
       " '1.60': 645,\n",
       " 'PRAECIP': 646,\n",
       " 'UNDERLYING': 647,\n",
       " 'GOVT': 648,\n",
       " 'BOND': 649,\n",
       " '7.0': 650,\n",
       " 'PCT': 651,\n",
       " 'SEPT': 652,\n",
       " '2001': 653,\n",
       " 'NOTES': 654,\n",
       " 'IS': 655,\n",
       " 'JOINT': 656,\n",
       " 'LEAD': 657,\n",
       " 'MANAGER': 658,\n",
       " '+44': 659,\n",
       " '171': 660,\n",
       " '542': 661,\n",
       " '7658': 662,\n",
       " 'Venantius': 663,\n",
       " '300': 664,\n",
       " '1999': 665,\n",
       " 'FRN': 666,\n",
       " 'floating-rate': 667,\n",
       " 'Lehman': 668,\n",
       " 'Brothers': 669,\n",
       " 'International': 670,\n",
       " 'VENANTIUS': 671,\n",
       " 'AB': 672,\n",
       " 'SWEDISH': 673,\n",
       " 'NATIONAL': 674,\n",
       " 'MORTGAGE': 675,\n",
       " 'AGENCY': 676,\n",
       " '-': 677,\n",
       " '12.5': 678,\n",
       " '21.JAN.99': 679,\n",
       " 'BASE': 680,\n",
       " '3M': 681,\n",
       " 'LIBOR': 682,\n",
       " 'S23.SEP.96': 683,\n",
       " 'LAST': 684,\n",
       " 'AA3': 685,\n",
       " '99.956': 686,\n",
       " 'AA+': 687,\n",
       " 'S': 688,\n",
       " 'SHORT': 689,\n",
       " 'FIRST': 690,\n",
       " 'JP': 691,\n",
       " 'FR': 692,\n",
       " 'YES': 693,\n",
       " 'IPMA': 694,\n",
       " '2': 695,\n",
       " 'ENGLISH': 696,\n",
       " 'SWEDEN': 697,\n",
       " '5': 698,\n",
       " 'ISSUED': 699,\n",
       " 'OFF': 700,\n",
       " 'EMTN': 701,\n",
       " 'PROGRAMME': 702,\n",
       " '8863': 703,\n",
       " 'Port': 704,\n",
       " 'update': 705,\n",
       " 'Syria': 706,\n",
       " 'Lloyds': 707,\n",
       " 'Shipping': 708,\n",
       " 'Intelligence': 709,\n",
       " 'Service': 710,\n",
       " 'LATTAKIA': 711,\n",
       " 'Aug': 712,\n",
       " 'waiting': 713,\n",
       " 'Lattakia': 714,\n",
       " 'Tartous': 715,\n",
       " 'presently': 716,\n",
       " '24': 717,\n",
       " 'Israel': 718,\n",
       " 'plays': 719,\n",
       " 'down': 720,\n",
       " 'fears': 721,\n",
       " 'war': 722,\n",
       " 'Colleen': 723,\n",
       " 'Siegel': 724,\n",
       " 'JERUSALEM': 725,\n",
       " 'outgoing': 726,\n",
       " 'peace': 727,\n",
       " 'current': 728,\n",
       " 'tensions': 729,\n",
       " 'between': 730,\n",
       " 'appeared': 731,\n",
       " 'storm': 732,\n",
       " 'teacup': 733,\n",
       " 'Itamar': 734,\n",
       " 'Rabinovich': 735,\n",
       " 'ambassador': 736,\n",
       " 'Washington': 737,\n",
       " 'conducted': 738,\n",
       " 'unfruitful': 739,\n",
       " 'negotiations': 740,\n",
       " 'Radio': 741,\n",
       " 'looked': 742,\n",
       " 'like': 743,\n",
       " 'Damascus': 744,\n",
       " 'wanted': 745,\n",
       " 'talk': 746,\n",
       " 'rather': 747,\n",
       " 'fight': 748,\n",
       " 'appears': 749,\n",
       " 'me': 750,\n",
       " 'Syrian': 751,\n",
       " 'priority': 752,\n",
       " 'still': 753,\n",
       " 'negotiate': 754,\n",
       " 'Syrians': 755,\n",
       " 'confused': 756,\n",
       " 'they': 757,\n",
       " 'definitely': 758,\n",
       " 'tense': 759,\n",
       " 'assessment': 760,\n",
       " 'here': 761,\n",
       " 'essentially': 762,\n",
       " 'winding': 763,\n",
       " 'term': 764,\n",
       " 'will': 765,\n",
       " 'replaced': 766,\n",
       " 'Eliahu': 767,\n",
       " 'Ben-Elissar': 768,\n",
       " 'Israeli': 769,\n",
       " 'envoy': 770,\n",
       " 'Egypt': 771,\n",
       " 'right-wing': 772,\n",
       " 'Likud': 773,\n",
       " 'politician': 774,\n",
       " 'sent': 775,\n",
       " 'message': 776,\n",
       " 'via': 777,\n",
       " 'committed': 778,\n",
       " 'open': 779,\n",
       " 'without': 780,\n",
       " 'preconditions': 781,\n",
       " 'slammed': 782,\n",
       " 'creating': 783,\n",
       " 'what': 784,\n",
       " 'called': 785,\n",
       " 'launching': 786,\n",
       " 'hysterical': 787,\n",
       " 'campaign': 788,\n",
       " 'against': 789,\n",
       " 'television': 790,\n",
       " 'reported': 791,\n",
       " 'recently': 792,\n",
       " 'test': 793,\n",
       " 'fired': 794,\n",
       " 'missile': 795,\n",
       " 'arms': 796,\n",
       " 'purchases': 797,\n",
       " 'defensive': 798,\n",
       " 'purposes': 799,\n",
       " 'Hafez': 800,\n",
       " 'al-': 801,\n",
       " 'Assad': 802,\n",
       " 'ready': 803,\n",
       " 'enter': 804,\n",
       " 'David': 805,\n",
       " 'Levy': 806,\n",
       " 'Tension': 807,\n",
       " 'mounted': 808,\n",
       " 'since': 809,\n",
       " 'Benjamin': 810,\n",
       " 'Netanyahu': 811,\n",
       " 'took': 812,\n",
       " 'June': 813,\n",
       " 'vowing': 814,\n",
       " 'retain': 815,\n",
       " 'Golan': 816,\n",
       " 'Heights': 817,\n",
       " 'captured': 818,\n",
       " 'Middle': 819,\n",
       " 'East': 820,\n",
       " 'Israeli-Syrian': 821,\n",
       " 'deadlocked': 822,\n",
       " 'over': 823,\n",
       " '1991': 824,\n",
       " 'despite': 825,\n",
       " 'previous': 826,\n",
       " 'willingness': 827,\n",
       " 'concessions': 828,\n",
       " 'Peace': 829,\n",
       " 'February': 830,\n",
       " 'voices': 831,\n",
       " 'coming': 832,\n",
       " 'out': 833,\n",
       " 'bad': 834,\n",
       " 'not': 835,\n",
       " 'good': 836,\n",
       " 'full': 837,\n",
       " 'expressions': 838,\n",
       " 'declarations': 839,\n",
       " 'must': 840,\n",
       " 'worrying': 841,\n",
       " 'artificial': 842,\n",
       " 'very': 843,\n",
       " 'those': 844,\n",
       " 'spread': 845,\n",
       " 'become': 846,\n",
       " 'prisoners': 847,\n",
       " 'expect': 848,\n",
       " 'face': 849,\n",
       " 'answer': 850,\n",
       " 'our': 851,\n",
       " 'want': 852,\n",
       " 'God': 853,\n",
       " 'forbid': 854,\n",
       " 'No': 855,\n",
       " 'one': 856,\n",
       " 'benefits': 857,\n",
       " 'wars': 858,\n",
       " 'Channel': 859,\n",
       " 'Two': 860,\n",
       " 'calming': 861,\n",
       " 'signal': 862,\n",
       " 'source': 863,\n",
       " 'spokesmen': 864,\n",
       " 'confirm': 865,\n",
       " 'messages': 866,\n",
       " 'reassure': 867,\n",
       " 'Cairo': 868,\n",
       " 'United': 869,\n",
       " 'States': 870,\n",
       " 'Moscow': 871,\n",
       " 'Polish': 872,\n",
       " 'diplomat': 873,\n",
       " 'denies': 874,\n",
       " 'nurses': 875,\n",
       " 'stranded': 876,\n",
       " 'Libya': 877,\n",
       " 'TUNIS': 878,\n",
       " 'tabloid': 879,\n",
       " 'refusing': 880,\n",
       " 'exit': 881,\n",
       " 'visas': 882,\n",
       " 'trying': 883,\n",
       " 'return': 884,\n",
       " 'home': 885,\n",
       " 'working': 886,\n",
       " 'North': 887,\n",
       " 'African': 888,\n",
       " 'country': 889,\n",
       " 'This': 890,\n",
       " 'true': 891,\n",
       " 'Up': 892,\n",
       " 'today': 893,\n",
       " 'knowledge': 894,\n",
       " 'nurse': 895,\n",
       " 'kept': 896,\n",
       " 'her': 897,\n",
       " 'received': 898,\n",
       " 'complaint': 899,\n",
       " 'embassy': 900,\n",
       " 'charge': 901,\n",
       " \"d'affaires\": 902,\n",
       " 'Tripoli': 903,\n",
       " 'Tadeusz': 904,\n",
       " 'Awdankiewicz': 905,\n",
       " 'telephone': 906,\n",
       " 'Poland': 907,\n",
       " 'labour': 908,\n",
       " 'would': 909,\n",
       " 'send': 910,\n",
       " 'team': 911,\n",
       " 'investigate': 912,\n",
       " 'probe': 913,\n",
       " 'prompted': 914,\n",
       " 'complaining': 915,\n",
       " 'about': 916,\n",
       " 'work': 917,\n",
       " 'non-payment': 918,\n",
       " 'salaries': 919,\n",
       " 'estimated': 920,\n",
       " '800': 921,\n",
       " 'Iranian': 922,\n",
       " 'opposition': 923,\n",
       " 'leaders': 924,\n",
       " 'meet': 925,\n",
       " 'Baghdad': 926,\n",
       " 'Hassan': 927,\n",
       " 'Hafidh': 928,\n",
       " 'BAGHDAD': 929,\n",
       " 'An': 930,\n",
       " 'exile': 931,\n",
       " 'based': 932,\n",
       " 'Iraq': 933,\n",
       " 'vowed': 934,\n",
       " 'extend': 935,\n",
       " 'Iran': 936,\n",
       " 'Kurdish': 937,\n",
       " 'rebels': 938,\n",
       " 'attacked': 939,\n",
       " 'troops': 940,\n",
       " 'deep': 941,\n",
       " 'inside': 942,\n",
       " 'Mujahideen': 943,\n",
       " 'Khalq': 944,\n",
       " 'statement': 945,\n",
       " 'leader': 946,\n",
       " 'Massoud': 947,\n",
       " 'Rajavi': 948,\n",
       " 'met': 949,\n",
       " 'Secretary-General': 950,\n",
       " 'Kurdistan': 951,\n",
       " 'Democratic': 952,\n",
       " 'Party': 953,\n",
       " 'KDPI': 954,\n",
       " 'Rastegar': 955,\n",
       " 'voiced': 956,\n",
       " 'rebel': 957,\n",
       " 'Kurds': 958,\n",
       " 'emphasised': 959,\n",
       " 'Resistance': 960,\n",
       " 'continue': 961,\n",
       " 'stand': 962,\n",
       " 'side': 963,\n",
       " 'compatriots': 964,\n",
       " 'resistance': 965,\n",
       " 'movement': 966,\n",
       " 'signals': 967,\n",
       " 'level': 968,\n",
       " 'cooperation': 969,\n",
       " 'oppositions': 970,\n",
       " 'heavily': 971,\n",
       " 'bombarded': 972,\n",
       " 'targets': 973,\n",
       " 'northern': 974,\n",
       " 'pursuit': 975,\n",
       " 'guerrillas': 976,\n",
       " 'Iraqi': 977,\n",
       " 'areas': 978,\n",
       " 'outside': 979,\n",
       " 'control': 980,\n",
       " 'bordering': 981,\n",
       " 'Patriotic': 982,\n",
       " 'PUK': 983,\n",
       " 'KDP': 984,\n",
       " 'main': 985,\n",
       " 'factions': 986,\n",
       " 'forces': 987,\n",
       " 'ousted': 988,\n",
       " 'Kuwait': 989,\n",
       " 'Gulf': 990,\n",
       " 'War': 991,\n",
       " 'Clashes': 992,\n",
       " 'parties': 993,\n",
       " 'broke': 994,\n",
       " 'weekend': 995,\n",
       " 'most': 996,\n",
       " 'serious': 997,\n",
       " 'fighting': 998,\n",
       " 'U.S.-sponsored': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjw4po7a-uNO"
   },
   "source": [
    "Now let's define the PyTorch Dataset:\n",
    "- It is common while building applications with PyTorch to use [Datasets and DataLoaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "\n",
    "We first define a Dataset by defining a custom class class (with Dataset as superclass). This class will reimplement at least three core methods:\n",
    "- `__init__` to initialize the variables used to store the actual data and labels\n",
    "-` __len__` methods to determine the length of the dataset (based on the variabels declared in the __init__ method)\n",
    "- `__getitem__` methods that will be called by the DataLoader object automatically, it must return a single sample of the dataset along with its label\n",
    "\n",
    "Subsequently, we will define our DataLoader, which in turn needs to arrange batches of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1743370008999,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "9K0K6KuHAXFA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class NERDataset(Dataset):\n",
    "    def __init__(self, data, word2idx, tag2idx):\n",
    "        self.data = data\n",
    "        self.word2idx = word2idx\n",
    "        self.tag2idx = tag2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sent = self.data[idx]\n",
    "        words = [token[\"text\"] for token in sent]\n",
    "        tags = [token[\"ner_tag\"] for token in sent]\n",
    "        # Mapping words to indices, using <UNK> if the word is not present in the vocabulary\n",
    "        word_indices = [self.word2idx.get(word, self.word2idx[\"<UNK>\"]) for word in words]\n",
    "        tag_indices = [self.tag2idx[tag] for tag in tags]\n",
    "        return torch.tensor(word_indices, dtype=torch.long), torch.tensor(tag_indices, dtype=torch.long)\n",
    "\n",
    "# Creazione dei dataset\n",
    "train_dataset = NERDataset(train_data, word2idx, tag2idx)\n",
    "valid_dataset = NERDataset(valid_data, word2idx, tag2idx)\n",
    "test_dataset  = NERDataset(test_data, word2idx, tag2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67W8rJefA1li"
   },
   "source": [
    "To define a DataLoader, having already define the DatasetObject, we need to define our custom collate function:\n",
    "- `collate_fn` is a function that the DataLoader is calling everytime it needs to build a new batch of data. This is done because we need a custom function which pads sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1743370009034,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "0FgmlDu8A4xK"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # batch: list of tuples (word_tensor, tag_tensor)\n",
    "    # Get input sentences\n",
    "    sentences = [item[0] for item in batch]\n",
    "    # Get labels\n",
    "    tags = [item[1] for item in batch]\n",
    "    # Get maximum length in the batch\n",
    "    lengths = [len(s) for s in sentences]\n",
    "    max_len = max(lengths)\n",
    "\n",
    "    # Pad shorter sentences to let the input tensors all have the same size\n",
    "    padded_sentences = []\n",
    "    padded_tags = []\n",
    "    for s, t in zip(sentences, tags):\n",
    "        pad_len = max_len - len(s)\n",
    "        # Padding uses index 0 both for words and labels\n",
    "        padded_sentences.append(torch.cat([s, torch.zeros(pad_len, dtype=torch.long)]))\n",
    "        padded_tags.append(torch.cat([t, torch.zeros(pad_len, dtype=torch.long)]))\n",
    "\n",
    "    #\n",
    "    return torch.stack(padded_sentences), torch.stack(padded_tags), lengths\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NwBTbAlXkPQ"
   },
   "source": [
    "### Defining and training the RNN model for NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKmcrDFTXkPQ"
   },
   "source": [
    "We start by importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1743370009041,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "5NeKieQnCsFM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1743370009042,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "zmctap4tCufE"
   },
   "outputs": [],
   "source": [
    "class BiLSTM_NER(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_tags):\n",
    "        super(BiLSTM_NER, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Bidirectional LSTM; we set batch_first=True to have input like [batch, seq_len, embedding_dim]\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        # Fully connected layer to map hidden state coming from LSTM to output labels\n",
    "        # (the hidden state is a concatenation of two LSTM outputs since it is bidirectional)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_tags)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, seq_len]\n",
    "        embeds = self.embedding(x)        # embeds: [batch_size, seq_len, embedding_dim]\n",
    "        lstm_out, _ = self.lstm(embeds)   # lstm_out: [batch_size, seq_len, hidden_dim*2]\n",
    "        logits = self.fc(lstm_out)        # logits: [batch_size, seq_len, num_tags]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1743370009042,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "CVRdsjaxCw-s"
   },
   "outputs": [],
   "source": [
    "# Parametri del modello\n",
    "EMBEDDING_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VM9PiFdM2gF"
   },
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1743370009084,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "vZLJs0eLM31w"
   },
   "outputs": [],
   "source": [
    "model = BiLSTM_NER(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, num_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4vR9yrIM4kH"
   },
   "source": [
    "Define loss and optimizer:\n",
    "- Note that we need to pay attention not computing the loss for padding tokens!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "executionInfo": {
     "elapsed": 7032,
     "status": "ok",
     "timestamp": 1743370016117,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "cJ6fSn3dCzLn"
   },
   "outputs": [],
   "source": [
    "# We ignore padding token to calculate the loss\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIaTvvQUOHPk"
   },
   "source": [
    "Let's identify the device we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1743370016123,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "BHAAK33POCoR",
    "outputId": "7497d015-712a-4107-940c-46f86560676c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XR0PlOeXONHm"
   },
   "source": [
    "Move to model to the available device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1743370016124,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "qFoUnLujOMfQ"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izCbLCbMC2rj"
   },
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 342730,
     "status": "ok",
     "timestamp": 1743370358855,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "R44xYtjNC5GP",
    "outputId": "e57acd85-f22a-465b-ae51-ed9c4564fe9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:08<00:00, 53.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 0.6261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:07<00:00, 61.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Loss: 0.3225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:07<00:00, 60.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Loss: 0.2067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:07<00:00, 57.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Loss: 0.1390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:07<00:00, 56.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Loss: 0.0930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:07<00:00, 58.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Loss: 0.0612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:07<00:00, 55.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Loss: 0.0374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:07<00:00, 57.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Loss: 0.0219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:07<00:00, 55.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:08<00:00, 51.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Loss: 0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for inputs, targets, lengths in tqdm(train_loader):\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        # Move input and output to target device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # Run input though the model\n",
    "        outputs = model(inputs)  # outputs: [batch, seq_len, num_tags]\n",
    "        # Flat batch and seq_len dimensions to compute the loss\n",
    "        outputs = outputs.view(-1, num_tags)\n",
    "        targets = targets.view(-1)\n",
    "        loss = criterion(outputs, targets)\n",
    "        # Call the backward pass\n",
    "        loss.backward()\n",
    "        # Tell the optimizer to do a step forward in the training\n",
    "        optimizer.step()\n",
    "        # Record loss logs\n",
    "        epoch_loss += loss.item()\n",
    "        history.append(loss.item())\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {epoch_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "executionInfo": {
     "elapsed": 152,
     "status": "ok",
     "timestamp": 1743370359008,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "QZZK7ruyUhRe",
    "outputId": "86d6455a-a81e-4c9c-960f-f957a848f460"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(len(history)), history)\n",
    "plt.xlabel('Update step')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNnlXnRuC8lZ"
   },
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2385,
     "status": "ok",
     "timestamp": 1743370361394,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "xYPGHJXPC9do",
    "outputId": "3778ab77-68ba-4a02-dbd5-d04bd975422a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3038798440093695\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    for inputs, targets, lengths in valid_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.view(-1, num_tags)\n",
    "        targets = targets.view(-1)\n",
    "        loss = criterion(outputs, targets)\n",
    "        total_loss += loss.item()\n",
    "    print(\"Validation Loss:\", total_loss / len(valid_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuBlZl8uDBR8"
   },
   "source": [
    "Test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1743370361395,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "TnNknBF3O2hi"
   },
   "outputs": [],
   "source": [
    "# Define an inverse dictionary to decode labels (idx -> tag)\n",
    "idx2tag = {idx: tag for tag, idx in tag2idx.items()}\n",
    "# If we also want to decode words, we need to build an inverse dictionary also for words\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1743370361415,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "GWDUdbkhDD8g",
    "outputId": "41b95470-97d4-4df6-bde8-d51e4a1b1307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence:  ['SOCCER', '-', '<UNK>', '<UNK>', '<UNK>', 'WIN', ',', 'CHINA', 'IN', '<UNK>', 'DEFEAT', '.']\n",
      "Ground Truth NER Tags: ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['<UNK>', '<UNK>']\n",
      "Ground Truth NER Tags: ['B-PER', 'I-PER']\n",
      "Predicted NER Tags:   ['O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['<UNK>', ',', 'United', 'Arab', 'Emirates', '<UNK>']\n",
      "Ground Truth NER Tags: ['B-LOC', 'O', 'B-LOC', 'I-LOC', 'I-LOC', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'B-LOC', 'I-LOC', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['Japan', 'began', 'the', 'defence', 'of', 'their', 'Asian', 'Cup', 'title', 'with', 'a', 'lucky', '2-1', 'win', 'against', 'Syria', 'in', 'a', 'Group', 'C', 'championship', 'match', 'on', 'Friday', '.']\n",
      "Ground Truth NER Tags: ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['But', 'China', 'saw', 'their', 'luck', 'desert', 'them', 'in', 'the', 'second', 'match', 'of', 'the', 'group', ',', 'crashing', 'to', 'a', 'surprise', '2-0', 'defeat', 'to', 'newcomers', '<UNK>', '.']\n",
      "Ground Truth NER Tags: ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
      "Predicted NER Tags:   ['O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['China', 'controlled', 'most', 'of', 'the', 'match', 'and', 'saw', 'several', 'chances', 'missed', 'until', 'the', '78th', 'minute', 'when', '<UNK>', 'striker', '<UNK>', '<UNK>', 'took', 'advantage', 'of', 'a', '<UNK>', 'defensive', 'header', 'to', 'lob', 'the', 'ball', 'over', 'the', 'advancing', 'Chinese', 'keeper', 'and', 'into', 'an', 'empty', 'net', '.']\n",
      "Ground Truth NER Tags: ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['<UNK>', '<UNK>', 'made', 'sure', 'of', 'the', 'win', 'in', 'injury', 'time', ',', 'hitting', 'an', '<UNK>', 'left', 'foot', 'shot', 'from', 'just', 'outside', 'the', 'area', '.']\n",
      "Ground Truth NER Tags: ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['The', 'former', 'Soviet', 'republic', 'was', 'playing', 'in', 'an', 'Asian', 'Cup', 'finals', 'tie', 'for', 'the', 'first', 'time', '.']\n",
      "Ground Truth NER Tags: ['O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['Despite', 'winning', 'the', 'Asian', 'Games', 'title', 'two', 'years', 'ago', ',', '<UNK>', 'are', 'in', 'the', 'finals', 'as', 'outsiders', '.']\n",
      "Ground Truth NER Tags: ['O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['Two', 'goals', 'from', 'defensive', 'errors', 'in', 'the', 'last', 'six', 'minutes', 'allowed', 'Japan', 'to', 'come', 'from', 'behind', 'and', 'collect', 'all', 'three', 'points', 'from', 'their', 'opening', 'meeting', 'against', 'Syria', '.']\n",
      "Ground Truth NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['<UNK>', '<UNK>', 'scored', 'the', 'winner', 'in', 'the', '<UNK>', 'minute', ',', 'rising', 'to', 'head', 'a', '<UNK>', '<UNK>', 'cross', 'towards', 'the', 'Syrian', 'goal', 'which', 'goalkeeper', '<UNK>', '<UNK>', 'appeared', 'to', 'have', 'covered', 'but', 'then', 'allowed', 'to', 'slip', 'into', 'the', 'net', '.']\n",
      "Ground Truth NER Tags: ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['It', 'was', 'the', 'second', 'costly', 'blunder', 'by', 'Syria', 'in', 'four', 'minutes', '.']\n",
      "Ground Truth NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['<UNK>', 'Hassan', 'Abbas', 'rose', 'to', '<UNK>', 'a', 'long', 'ball', 'into', 'the', 'area', 'in', 'the', '84th', 'minute', 'but', 'only', 'managed', 'to', '<UNK>', 'it', 'into', 'the', 'top', 'corner', 'of', '<UNK>', \"'s\", 'goal', '.']\n",
      "Ground Truth NER Tags: ['O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['<UNK>', '<UNK>', 'had', 'given', 'Syria', 'the', 'lead', 'with', 'a', '<UNK>', 'header', 'in', 'the', 'seventh', 'minute', '.']\n",
      "Ground Truth NER Tags: ['B-PER', 'I-PER', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['Japan', 'then', 'laid', '<UNK>', 'to', 'the', 'Syrian', 'penalty', 'area', 'for', 'most', 'of', 'the', 'game', 'but', 'rarely', '<UNK>', 'the', 'Syrian', 'defence', '.']\n",
      "Ground Truth NER Tags: ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n",
      "Predicted NER Tags:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['<UNK>', 'pulled', 'off', 'fine', '<UNK>', '<UNK>', 'they', 'did', '.']\n",
      "Ground Truth NER Tags: ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['Japan', 'coach', '<UNK>', '<UNK>', 'said', ':', \"'\", \"'\", 'The', 'Syrian', 'own', 'goal', 'proved', 'lucky', 'for', 'us', '.']\n",
      "Ground Truth NER Tags: ['B-LOC', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['The', 'Syrians', 'scored', 'early', 'and', 'then', 'played', '<UNK>', 'and', 'adopted', 'long', 'balls', 'which', 'made', 'it', 'hard', 'for', 'us', '.', \"'\"]\n",
      "Ground Truth NER Tags: ['O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  [\"'\"]\n",
      "Ground Truth NER Tags: ['O']\n",
      "Predicted NER Tags:   ['O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['Japan', ',', '<UNK>', 'of', 'the', 'World', 'Cup', 'in', '2002', 'and', 'ranked', '20th', 'in', 'the', 'world', 'by', 'FIFA', ',', 'are', 'favourites', 'to', 'regain', 'their', 'title', 'here', '.']\n",
      "Ground Truth NER Tags: ['B-LOC', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['B-LOC', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['<UNK>', 'UAE', 'play', 'Kuwait', 'and', 'South', 'Korea', 'take', 'on', 'Indonesia', 'on', 'Saturday', 'in', 'Group', 'A', 'matches', '.']\n",
      "Ground Truth NER Tags: ['O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'B-LOC', 'O', 'B-LOC', 'O', 'B-LOC', 'I-LOC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['All', 'four', 'teams', 'are', 'level', 'with', 'one', 'point', 'each', 'from', 'one', 'game', '.']\n",
      "Ground Truth NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['RUGBY', 'UNION', '-', '<UNK>', 'BACK', 'FOR', '<UNK>', 'AFTER', 'A', 'YEAR', '.']\n",
      "Ground Truth NER Tags: ['B-ORG', 'I-ORG', 'O', 'B-PER', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['ROME', '<UNK>']\n",
      "Ground Truth NER Tags: ['B-LOC', 'O']\n",
      "Predicted NER Tags:   ['O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['Italy', 'recalled', '<UNK>', '<UNK>']\n",
      "Ground Truth NER Tags: ['B-LOC', 'O', 'B-PER', 'I-PER']\n",
      "Predicted NER Tags:   ['B-LOC', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['on', 'Friday', 'for', 'their', 'friendly', 'against', 'Scotland', 'at', '<UNK>', 'more', 'than', 'a', 'year', 'after', 'the', '30-year-old', 'wing', 'announced', 'he', 'was', 'retiring', 'following', 'differences', 'over', 'selection', '.']\n",
      "Ground Truth NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['<UNK>', ',', 'who', 'trainer', 'George', '<UNK>', 'said', 'was', 'certain', 'to', 'play', 'on', 'Saturday', 'week', ',', 'was', 'named', 'in', 'a', '<UNK>', 'squad', 'lacking', 'only', 'two', 'of', 'the', 'team', 'beaten', '<UNK>', 'by', 'England', 'at', '<UNK>', 'last', 'month', '.']\n",
      "Ground Truth NER Tags: ['B-PER', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'B-MISC', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['Stefano', '<UNK>', 'is', 'out', 'through', 'illness', 'and', '<UNK>', 'said', 'he', 'had', 'dropped', 'back', 'row', '<UNK>', '<UNK>', ',', 'who', 'had', 'been', 'recalled', 'for', 'the', 'England', 'game', 'after', 'five', 'years', 'out', 'of', 'the', 'national', 'team', '.']\n",
      "Ground Truth NER Tags: ['B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['<UNK>', 'announced', 'his', 'retirement', 'after', 'the', '1995', 'World', 'Cup', ',', 'where', 'he', 'took', 'issue', 'with', 'being', 'dropped', 'from', 'the', 'Italy', 'side', 'that', 'faced', 'England', 'in', 'the', 'pool', 'stages', '.']\n",
      "Ground Truth NER Tags: ['B-PER', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['<UNK>', 'said', 'he', 'had', 'approached', 'the', 'player', 'two', 'months', 'ago', 'about', 'a', 'comeback', '.']\n",
      "Ground Truth NER Tags: ['B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['\"', 'He', 'ended', 'the', 'World', 'Cup', 'on', 'the', 'wrong', 'note', ',', '\"', '<UNK>', 'said', '.']\n",
      "Ground Truth NER Tags: ['O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-PER', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "Original Sentence:  ['\"', 'I', 'thought', 'it', 'would', 'be', 'useful', 'to', 'have', 'him', 'back', 'and', 'he', 'said', 'he', 'would', 'be', 'available', '.']\n",
      "Ground Truth NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted NER Tags:   ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Esempio di inference e decodifica per il Test Set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, targets, lengths in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # Run the model with the current input\n",
    "        outputs = model(inputs)\n",
    "        # Get the tag with the highest probability for each token\n",
    "        predicted_tags = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "        # Decoding and printing predicted ner tags for every sample in the batch\n",
    "        for i in range(len(inputs)):\n",
    "          seq_len = lengths[i]\n",
    "\n",
    "          # Extract original indices (not considering padding)\n",
    "          sentence_indices = inputs[i][:seq_len].tolist()\n",
    "          true_tag_indices = targets[i][:seq_len].tolist()\n",
    "          pred_tag_indices = predicted_tags[i][:seq_len].tolist()\n",
    "\n",
    "          # Deconde indices in words and tags\n",
    "          sentence_tokens = [idx2word.get(idx, \"<UNK>\") for idx in sentence_indices]\n",
    "          true_tags = [idx2tag[idx] for idx in true_tag_indices]\n",
    "          pred_tags = [idx2tag[idx] for idx in pred_tag_indices]\n",
    "\n",
    "          print(\"Original Sentence: \", sentence_tokens)\n",
    "          print(\"Ground Truth NER Tags:\", true_tags)\n",
    "          print(\"Predicted NER Tags:  \", pred_tags)\n",
    "          print(\"-\" * 50)\n",
    "        break  # Run only the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3043,
     "status": "ok",
     "timestamp": 1743370364459,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -120
    },
    "id": "-0qbTRYDTmst",
    "outputId": "53e86e5b-ca72-4d98-e8a8-6fff3525ca94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-ORG       0.80      0.58      0.67      1661\n",
      "           O       0.94      0.99      0.96     38323\n",
      "      B-MISC       0.66      0.65      0.65       702\n",
      "       B-PER       0.84      0.49      0.62      1617\n",
      "       I-PER       0.90      0.45      0.60      1156\n",
      "       B-LOC       0.88      0.71      0.79      1668\n",
      "       I-ORG       0.78      0.62      0.69       835\n",
      "      I-MISC       0.55      0.61      0.58       216\n",
      "       I-LOC       0.85      0.54      0.66       257\n",
      "\n",
      "    accuracy                           0.92     46435\n",
      "   macro avg       0.80      0.63      0.69     46435\n",
      "weighted avg       0.92      0.92      0.91     46435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "all_true = []\n",
    "all_pred = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, targets, lengths in test_loader:\n",
    "      inputs = inputs.to(device)\n",
    "      targets = targets.to(device)\n",
    "      outputs = model(inputs)\n",
    "      predicted_tags = torch.argmax(outputs, dim=-1)\n",
    "      # For each sequence in the batch, collect true and predicted labels (excluding padding)\n",
    "      for i in range(len(inputs)):\n",
    "          seq_len = lengths[i]\n",
    "          true_tag_indices = targets[i][:seq_len].tolist()\n",
    "          pred_tag_indices = predicted_tags[i][:seq_len].tolist()\n",
    "          all_true.extend(true_tag_indices)\n",
    "          all_pred.extend(pred_tag_indices)\n",
    "\n",
    "# Optionally, filter out the padding index (0) if it might be present in the evaluation,\n",
    "# but since we use the actual sequence lengths, padding should not be included.\n",
    "# Create a list of target names sorted by tag index, excluding the PAD tag\n",
    "target_names = [idx2tag[idx] for idx in sorted(idx2tag.keys()) if idx != 0]\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(all_true, all_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ym-G2h-xXkPb"
   },
   "source": [
    "What do we see from these results?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4uE1efbqpdl3",
    "VS1PK7ifpdl5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
