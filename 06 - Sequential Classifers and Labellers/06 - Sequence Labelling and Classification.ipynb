{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giKsby3Lpdlp"
   },
   "source": [
    "# Sequence Labelling and Classification\n",
    "\n",
    "In this session we will train a Text classifier that makes use of a Bidirectional LSTM (Long Short-term Memory) model.\n",
    "\n",
    "In the second part of the tutorial we will first investigate Part-of-Speech (POS) tagging and Named-entity recognition (NER).\n",
    "- For this we will make use of the spaCy natural langauge processing API: https://spacy.io/\n",
    "- spaCy is an opensource API that provides state-of-the-art performance on sequence labeling tasks such as POS tagging and NER.\n",
    "- Parts of this tutorial are based on code from: https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMS2GYrKXkPO"
   },
   "source": [
    "## Sequence labelling with embeddings and a Recurrent Neural Network\n",
    "\n",
    "In this section of the notebook I will run through an example of using LSTM (Long Short-term Memory) network for text sequence labelling.\n",
    "We can train our own model for POS-tagging or NER.\n",
    "Moreover, we can use pre-trained embedding models to encode the input text.\n",
    "\n",
    "- We are going to use PyTorch (https://pytorch.org) to build and train our model. Pytorch is a state-of-the-art framework for deep leaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F6xs4SfcXkPP"
   },
   "source": [
    "### Data preparation\n",
    "\n",
    "As usual we start from data preparation.\n",
    "We can use the [CoNLL 2003](https://www.clips.uantwerpen.be/conll2003/ner/) corpus, which provides corpora for POS-tagging, Chunking and NER in English and German.\n",
    "Today we are going to focus on NER in English.\n",
    "\n",
    "You can find a copy the English split in the `docs/` directory.\n",
    "Usually the corpus should require preprocessing the data, here I am providing you with a version from Kaggle where documents have already been tagged (source: https://www.kaggle.com/datasets/alaakhaled/conll003-englishversion?resource=download)\n",
    "\n",
    "Let's start by loading the three files (train/validation/test) in memory and reading all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1742332557662,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "BONoKuGNXkPP",
    "outputId": "b06521f9-44cf-4b41-94b5-e6b137e4cc4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-DOCSTART- -X- -X- O\n",
      "\n",
      "EU NNP B-NP B-ORG\n",
      "rejects VBZ B-VP O\n",
      "German JJ B-NP B-MISC\n",
      "call NN I-NP O\n",
      "to TO B-VP O\n",
      "boycott VB I-VP O\n",
      "British JJ B-NP B-MISC\n",
      "lamb NN I-NP O\n",
      ". . O O\n",
      "\n",
      "Peter NNP B-NP B-PER\n",
      "Blackburn NNP I-NP I-PER\n",
      "\n",
      "BRUSSELS NNP B-NP B-LOC\n",
      "1996-08-22 CD I-NP O\n",
      "\n",
      "The DT B-NP O\n",
      "European NNP I-NP B-ORG\n",
      "Commission NNP I-NP I-ORG\n",
      "said VBD B-VP O\n",
      "on IN B-PP O\n",
      "Thursday NNP B-NP O\n",
      "it PRP B-NP O\n",
      "disagreed VBD B-VP O\n",
      "with IN B-PP O\n",
      "German JJ B-NP B-MISC\n",
      "advice NN I-NP O\n",
      "to TO B-PP O\n",
      "consumers NNS B-NP\n"
     ]
    }
   ],
   "source": [
    "raw_data = dict()\n",
    "\n",
    "for split in ['train', 'valid', 'test']:\n",
    "    with open(f'docs/CoNLL - 2003/{split}.txt') as f:\n",
    "        raw_data[split] = f.read().strip()\n",
    "\n",
    "print(raw_data['train'][:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vw6GFYkCXkPP"
   },
   "source": [
    "Now we can parse the data.\n",
    "Documents inside each split are separated by the sequence `-DOCSTART- -X- -X- O`.\n",
    "Sentences inside each document are separated by the sequence`\\n\\n` (two new-line characters).\n",
    "Each line inside a sentence represnets a token followed by the POS tag, the CHUNK tag and the NER tag, all separated by spaces.\n",
    "\n",
    "Here NER tags are written using a system called BIO-tagging.\n",
    "The 'B' stands for \"begin\" and introduces (starts) a new named entity, the tags are written as \"B-PER\" to indicate a person or \"B-LOC\" to indicate a location and so on.\n",
    "The 'I' stands for \"inside\" and continues a started named entity, the tags are written as \"I-PER\" to indicate a person or \"I-LOC\" to indicate a location and so on.\n",
    "The 'O' stands for outside, it means that the token is outside any named entity.\n",
    "There are other tagging systems.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "xagcI6jWXkPP"
   },
   "outputs": [],
   "source": [
    "keys = ['text', 'pos_tag', 'chunk_tag', 'ner_tag']\n",
    "\n",
    "data = dict()\n",
    "\n",
    "for split in raw_data:\n",
    "    data[split] = list()\n",
    "    for doc in raw_data[split].split('-DOCSTART- -X- -X- O')[1:]:\n",
    "        for sentence in doc.strip().split('\\n\\n'):\n",
    "            data[split].append(list())\n",
    "            for elem in sentence.split('\\n'):\n",
    "                data[split][-1].append(dict(zip(keys, elem.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1742332559710,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "UXZPjL6RXkPP",
    "outputId": "cc1e7ae0-dc0c-4d87-dce7-5f8a7d8e4d9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'EU', 'pos_tag': 'NNP', 'chunk_tag': 'B-NP', 'ner_tag': 'B-ORG'},\n",
       " {'text': 'rejects', 'pos_tag': 'VBZ', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
       " {'text': 'German', 'pos_tag': 'JJ', 'chunk_tag': 'B-NP', 'ner_tag': 'B-MISC'},\n",
       " {'text': 'call', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
       " {'text': 'to', 'pos_tag': 'TO', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
       " {'text': 'boycott', 'pos_tag': 'VB', 'chunk_tag': 'I-VP', 'ner_tag': 'O'},\n",
       " {'text': 'British',\n",
       "  'pos_tag': 'JJ',\n",
       "  'chunk_tag': 'B-NP',\n",
       "  'ner_tag': 'B-MISC'},\n",
       " {'text': 'lamb', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
       " {'text': '.', 'pos_tag': '.', 'chunk_tag': 'O', 'ner_tag': 'O'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGQgUUNIXkPQ"
   },
   "source": [
    "Now all the labels are properly organised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtmKiY5eXkPQ"
   },
   "source": [
    "At this point we need a system to encode and decode the labels into categorical entities.\n",
    "We can use the label encoder from Scikit-Learn for that (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LjLyqAhgXkPQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pos_le = LabelEncoder().fit([token['pos_tag'] for split in data.values() for sentence in split for token in sentence])\n",
    "chunk_le = LabelEncoder().fit([token['pos_tag'] for split in data.values() for sentence in split for token in sentence])\n",
    "ner_le = LabelEncoder().fit([token['ner_tag'] for split in data.values() for sentence in split for token in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVFW52o8XkPQ"
   },
   "source": [
    "Now we have a module mapping from tags to IDs and vice-versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1742332563909,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "93KtbCVBXkPQ",
    "outputId": "e1d5d1fa-497e-42cb-9b48-1274e8a0374d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tag = ['I-PER']\n",
    "ner_tag = ['I-LOC']\n",
    "ner_tag = ['B-PER']\n",
    "# ner_tag = ['O']\n",
    "\n",
    "ner_le.transform(ner_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742332563917,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "mFDxhaMnXkPQ",
    "outputId": "adb4aeec-8748-4ff4-8c2f-08cb62bca3f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-LOC'], dtype='<U6')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tag_id = [0]\n",
    "\n",
    "ner_le.inverse_transform(ner_tag_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOVxouSbXkPQ"
   },
   "source": [
    "How many NER tags do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742332564008,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "XP7h6lsQXkPQ",
    "outputId": "55adec31-b6aa-4449-be73-20d7f917451e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ner_le.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObAM_0yLXkPQ"
   },
   "source": [
    "Which are those tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1742332564010,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "5cNrY9QmXkPQ",
    "outputId": "04bc1711-bb7c-44b6-9930-035c5561fd1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-LOC', 'B-MISC', 'B-ORG', 'B-PER', 'I-LOC', 'I-MISC', 'I-ORG',\n",
       "       'I-PER', 'O'], dtype='<U6')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKcRUmgnXkPQ"
   },
   "source": [
    "Collect the same info for POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6ywrLqj2XkPQ"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuOZxaJVXkPQ"
   },
   "source": [
    "Finally we separate our train-validation-test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ghCasG1MXkPQ"
   },
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = data.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4NwBTbAlXkPQ"
   },
   "source": [
    "### Defining and training the RNN model for NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKmcrDFTXkPQ"
   },
   "source": [
    "We start by installing PyTorch and importing the required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2216,
     "status": "ok",
     "timestamp": 1742332746432,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "JOz8WMvJHrXs",
    "outputId": "bb54774e-0fe3-41ed-801b-71f292b3fd28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q gensim torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "iyMkbwDLXkPR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfmmttGYXkPR"
   },
   "source": [
    "Then we load the Word Embedding model we want to use. We can re-use the 50 dimensional GloVe emebddings from last time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wTTztembXkPR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "we_model = api.load(\"glove-wiki-gigaword-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uExHPXquXkPR"
   },
   "source": [
    "Before creating the LSTM we decide where to train our model, either cpu or gpu, depending on which is avaialble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1742332865910,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "BtlzrvG5XkPR",
    "outputId": "7fc76e22-b7cc-4843-e92c-df367a5db90d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQ3aDdLKXkPR"
   },
   "source": [
    "Now we can create our RNN module.\n",
    "Here are the available modules for PyTorch: https://pytorch.org/docs/stable/nn.html#recurrent-layers\n",
    "\n",
    "We define a custom LSTM using PyTorch API.\n",
    "In our model we stack one or more LSTM layers (we can make it variable) and we put a linear layer (a.k.a. dense layer or fully connected layer on top of it).\n",
    "\n",
    "When you define a neural network in PyTorch you need it to extend the `torch.nn.Module` class and implement the forward method (the one that computes the output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UQkVBi_bXkPR"
   },
   "outputs": [],
   "source": [
    "class CustomLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_lstm=1):\n",
    "        super().__init__()\n",
    "        # List of LSTM layers\n",
    "        self.lstm = nn.ModuleList([\n",
    "            nn.LSTM(\n",
    "                input_size=input_size if i == 0 else hidden_size,\n",
    "                hidden_size=hidden_size,\n",
    "                batch_first=True,\n",
    "                bidirectional=True,\n",
    "                dropout=0.2\n",
    "            )\n",
    "            for i in range(n_lstm)\n",
    "        ])\n",
    "        # Lat linear projection\n",
    "        self.cls_head = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run though all the LSTM layers\n",
    "        for lstm_layer in self.lstm:\n",
    "            # Compute new hidden representation\n",
    "            x, _ = lstm_layer(x)\n",
    "            # Average the hidden output from the two directions of the LSTM\n",
    "            x = (x[..., :x.size(-1) // 2] + x[..., x.size(-1) // 2:]) / 2\n",
    "        # Apply last lineat projection\n",
    "        y = self.cls_head(x)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uw6Vx9LOXkPR"
   },
   "source": [
    "Let's create an instance of our LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1742332868674,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "tPTLsJBLXkPR",
    "outputId": "cd2aa3e6-93ec-4404-aff6-b04baf81c27e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrien/Documents/PoliMi/TP/Natural Language Processing/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomLSTM(\n",
       "  (lstm): ModuleList(\n",
       "    (0-2): 3 x LSTM(300, 300, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (cls_head): Linear(in_features=300, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm = CustomLSTM(300, 300, len(ner_le.classes_), n_lstm=3)\n",
    "lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOnljCiCXkPR"
   },
   "source": [
    "Now we can move the LSTM to the target device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MPqved6HXkPR"
   },
   "outputs": [],
   "source": [
    "lstm = lstm.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFpAIMl6XkPa"
   },
   "source": [
    "Once we have the model we need to create an optimizer that will take care of updating the weights. Here are the available optimizers: https://pytorch.org/docs/stable/optim.html.\n",
    "I'm going to use RMSProp.\n",
    "\n",
    "The optimizer needs to receive the parameters of the neural network and the selected learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vFekRmmIXkPa"
   },
   "outputs": [],
   "source": [
    "lr = 0.0005\n",
    "optimizer = torch.optim.RMSprop(params=lstm.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3ASQNmFXkPa"
   },
   "source": [
    "Now we need to prepare our data.\n",
    "Before doing so we prepare a function that maps a mini-batch of samples (i.e., a subset of the lists of dictionaries we prepared) to input tensors to use with our model. The function willl take care of:\n",
    "- Mapping all words to their embeddings with size $d$\n",
    "- Collect the emebddings of the same sentence into a matrix with shape $(n_\\textit{words in sentence}, d)$\n",
    "- Collect the different matrices of the same batch into a single tensor with shape $(n_\\textit{batch elements}, n_\\textit{words in longest sentence}, d)$ (this will be input).\n",
    "- Mapping all the labels to their IDs\n",
    "- Collecting all the IDs of the same sentence into a vector with size $n_\\textit{words in sentence}$\n",
    "- Collecting all the different vectors into a matrix with shape $(n_\\textit{batch elements}, n_\\textit{words in longest sentence})$ (this will be target output).\n",
    "\n",
    "Note that different sentences have different lengths, to cope with this issue we apply a process called padding: we are going to add to the input tensor and the target output matrix  dummy values to have all the same \"sentence length\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "IaGkRWFlXkPb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def collate(mini_batch):\n",
    "    # Get the length of the longest sentence\n",
    "    longest_len = max(len(sample) for sample in mini_batch)\n",
    "    # Create an input tensor with all zero values\n",
    "    input_embeds = np.zeros((len(mini_batch), longest_len, 300))\n",
    "    # Create a target output matrix with all -100 (PyTorch ignores this value by default)\n",
    "    output_lbl = np.full((len(mini_batch), longest_len), -100)\n",
    "    # Fill the tensor and the matrix\n",
    "    for i, sample in enumerate(mini_batch):\n",
    "        for j, token in enumerate(sample):\n",
    "            # Manage missing tokens in vocabulary\n",
    "            if token['text'].lower() in we_model:\n",
    "                input_embeds[i,j] = we_model[token['text'].lower()]\n",
    "            output_lbl[i,j] = ner_le.transform([token['ner_tag']])[0]\n",
    "    # Convert to PyTorch tensor\n",
    "    input_embeds = torch.tensor(input_embeds, dtype=torch.float)\n",
    "    output_lbl = torch.tensor(output_lbl)\n",
    "\n",
    "    return input_embeds, output_lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtUbxPYkXkPb"
   },
   "source": [
    "How does an encoded batch looks like? Let's enode the first three sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742332897388,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "2T-85SA1XkPb",
    "outputId": "c4b800fd-a4c8-4162-dd12-26ac38e53fca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'text': 'EU', 'pos_tag': 'NNP', 'chunk_tag': 'B-NP', 'ner_tag': 'B-ORG'},\n",
       "  {'text': 'rejects', 'pos_tag': 'VBZ', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
       "  {'text': 'German',\n",
       "   'pos_tag': 'JJ',\n",
       "   'chunk_tag': 'B-NP',\n",
       "   'ner_tag': 'B-MISC'},\n",
       "  {'text': 'call', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
       "  {'text': 'to', 'pos_tag': 'TO', 'chunk_tag': 'B-VP', 'ner_tag': 'O'},\n",
       "  {'text': 'boycott', 'pos_tag': 'VB', 'chunk_tag': 'I-VP', 'ner_tag': 'O'},\n",
       "  {'text': 'British',\n",
       "   'pos_tag': 'JJ',\n",
       "   'chunk_tag': 'B-NP',\n",
       "   'ner_tag': 'B-MISC'},\n",
       "  {'text': 'lamb', 'pos_tag': 'NN', 'chunk_tag': 'I-NP', 'ner_tag': 'O'},\n",
       "  {'text': '.', 'pos_tag': '.', 'chunk_tag': 'O', 'ner_tag': 'O'}],\n",
       " [{'text': 'Peter', 'pos_tag': 'NNP', 'chunk_tag': 'B-NP', 'ner_tag': 'B-PER'},\n",
       "  {'text': 'Blackburn',\n",
       "   'pos_tag': 'NNP',\n",
       "   'chunk_tag': 'I-NP',\n",
       "   'ner_tag': 'I-PER'}],\n",
       " [{'text': 'BRUSSELS',\n",
       "   'pos_tag': 'NNP',\n",
       "   'chunk_tag': 'B-NP',\n",
       "   'ner_tag': 'B-LOC'},\n",
       "  {'text': '1996-08-22',\n",
       "   'pos_tag': 'CD',\n",
       "   'chunk_tag': 'I-NP',\n",
       "   'ner_tag': 'O'}]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1742332898530,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "1wuZ5_q4XkPb",
    "outputId": "5c31fa1c-60db-4313-bad8-c326c84c471d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the input is: torch.Size([3, 9, 300])\n",
      "The shape of the output is: torch.Size([3, 9])\n"
     ]
    }
   ],
   "source": [
    "embeds, lbl = collate(train_data[:3])\n",
    "\n",
    "print(f\"The shape of the input is: {embeds.size()}\")\n",
    "print(f\"The shape of the output is: {lbl.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1742332899861,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "PGKJiKjMXkPb",
    "outputId": "4d20e393-a5aa-4b34-82c2-0b3a9bc97063"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5473, -0.2364, -0.2143,  ..., -0.3137, -0.4393,  0.1852],\n",
       "         [ 0.4056, -0.0393, -0.2357,  ..., -0.2026,  0.1970,  0.4861],\n",
       "         [-0.1740,  0.2612, -0.5919,  ..., -0.1950,  0.2041,  0.3530],\n",
       "         ...,\n",
       "         [ 0.4436, -0.2418,  0.2366,  ...,  0.1857, -0.2956, -0.1999],\n",
       "         [ 0.1964, -0.2666,  0.1819,  ...,  0.1678,  0.0395,  0.4751],\n",
       "         [-0.1256,  0.0136,  0.1031,  ..., -0.3422, -0.0224,  0.1368]],\n",
       "\n",
       "        [[ 0.1093, -0.1402,  0.0930,  ...,  0.3865,  0.3444,  0.0214],\n",
       "         [-0.4132,  0.2175, -0.0505,  ..., -0.4873, -0.4033, -0.3469],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.4693, -0.0993,  0.0016,  ..., -0.4687, -0.7363,  0.1922],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742332900909,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "EhGEiUIJXkPb",
    "outputId": "31cc868d-c1ff-43b4-8b22-cd250c0fde5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2,    8,    1,    8,    8,    8,    1,    8,    8],\n",
       "        [   3,    7, -100, -100, -100, -100, -100, -100, -100],\n",
       "        [   0,    8, -100, -100, -100, -100, -100, -100, -100]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OVQpLMlXkPb"
   },
   "source": [
    "Now we can finally wrap a DataLoader around our samples. PyTorch data loaders take care of generating batches on a given data set. We just need to set the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "po78xTDaXkPb"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, collate_fn=collate, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_size, collate_fn=collate)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wxzgtIjZXkPb"
   },
   "source": [
    "We can train the lst iterating over the data set for a given number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 309130,
     "status": "ok",
     "timestamp": 1742333217654,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "iySokQbJXkPb",
    "outputId": "dc5023f8-7e35-466d-c384-867064ea30f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [01:33<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [01:33<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [01:34<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [01:28<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [01:28<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [01:26<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [01:35<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [01:27<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [01:34<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110/110 [01:30<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Import nice loading bar using tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set model in training mode\n",
    "lstm.train()\n",
    "\n",
    "# Accumulator of loss\n",
    "history = []\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "# Iterate over epochs\n",
    "for i in range(n_epochs):\n",
    "    print(f\"Starting epoch {i + 1}/{n_epochs}\")\n",
    "    # Iterate over training batches\n",
    "    for embeds, lbl in tqdm(train_loader):\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        lbl = lbl.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = lstm(embeds)\n",
    "        # Flatten logits to a shape (batch_size * max_sentence_len, n_classes)\n",
    "        logits = logits.reshape(-1, len(ner_le.classes_))\n",
    "        # Flatten targets to a shape (batch_size * max_sentence_len)\n",
    "        lbl = lbl.reshape(-1)\n",
    "        # Compute loss\n",
    "        loss = F.cross_entropy(logits, lbl)\n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Save loss\n",
    "        history.append(loss.detach())\n",
    "\n",
    "history = [loss.cpu().item() for loss in history]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVeUY6ONXkPb"
   },
   "source": [
    "Now we can plot the evolution of the loss at each update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1742333295455,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "hlB3uqseXkPb",
    "outputId": "ea94a4e4-f24f-45ae-a0dc-452b7ce48219"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(len(history)), history)\n",
    "plt.xlabel('Update step')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CD3oP7LMXkPb"
   },
   "source": [
    "We can also test out model using the dedicated split. We iterate over the mini batches, collect the prediction as the value with the highest logit value and we store these values until we go through the entire data set. Then we compute the classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8386,
     "status": "ok",
     "timestamp": 1742333335880,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "RHLkLpTcXkPb",
    "outputId": "0425cfcf-5851-4b16-a03f-bce874ce32c9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:11<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.95      0.92      0.93      1837\n",
      "      B-MISC       0.86      0.82      0.84       922\n",
      "       B-ORG       0.88      0.84      0.86      1341\n",
      "       B-PER       0.94      0.95      0.95      1842\n",
      "       I-LOC       0.90      0.80      0.84       257\n",
      "      I-MISC       0.85      0.65      0.73       346\n",
      "       I-ORG       0.87      0.68      0.77       751\n",
      "       I-PER       0.97      0.95      0.96      1307\n",
      "           O       0.98      0.99      0.99     42759\n",
      "\n",
      "    accuracy                           0.97     51362\n",
      "   macro avg       0.91      0.84      0.88     51362\n",
      "weighted avg       0.97      0.97      0.97     51362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set model in evaluation mode\n",
    "lstm.eval()\n",
    "\n",
    "# Accumulators for target labels and predictions\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Disable gradients\n",
    "with torch.no_grad():\n",
    "    # Iterate over validation batches\n",
    "    for embeds, lbl in tqdm(valid_loader):\n",
    "        # Move input and output to target device\n",
    "        embeds = embeds.to(device)\n",
    "        # Compute logits (i.e., softmax values before exponential normalisation)\n",
    "        logits = lstm(embeds)\n",
    "        # Get predictions as the index corresponding to the highest logit score\n",
    "        pred_lbl = torch.argmax(logits, dim=-1)\n",
    "        # Append predicted labels\n",
    "        y_pred.append(pred_lbl.reshape(-1).cpu().numpy())\n",
    "        # Append target labels\n",
    "        y_true.append(lbl.reshape(-1).numpy())\n",
    "\n",
    "# Concatenate all the vectors of target labels and predicted labels\n",
    "y_true = np.concatenate(y_true)\n",
    "y_pred = np.concatenate(y_pred)\n",
    "# Remove elements to ignore (the -100 labels)\n",
    "mask = y_true == -100\n",
    "y_true = y_true[~mask]\n",
    "y_pred = y_pred[~mask]\n",
    "\n",
    "# Finally compute classification report\n",
    "print()\n",
    "print(classification_report(y_true, y_pred, target_names=ner_le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ym-G2h-xXkPb"
   },
   "source": [
    "What do we see from these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovToorHEXkPb"
   },
   "source": [
    "We can play a bit with the model directly.\n",
    "\n",
    "Let's define a function to compute the predictions given a sentence. We will use the NLTK tokenizer to split the sentence into word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742333523317,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "NYWr8JyhXkPb",
    "outputId": "3077870f-7908-4920-96a1-d6015341b45f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/adrien/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to /home/adrien/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def predict(sample):\n",
    "    # Tokenize sample\n",
    "    tokenized_sample = word_tokenize(sample)\n",
    "    # Create an input tensor with all zero values\n",
    "    input_embeds = np.zeros((1, len(tokenized_sample), 300))\n",
    "    # Fill the tensor and the matrix\n",
    "    for i, token in enumerate(tokenized_sample):\n",
    "        # Manage missing tokens in vocabulary\n",
    "        if token.lower() in we_model:\n",
    "            input_embeds[0, i] = we_model[token.lower()]\n",
    "    # Convert to PyTorch tensor\n",
    "    input_embeds = torch.tensor(input_embeds, dtype=torch.float, device=device)\n",
    "    # Run model over input\n",
    "    logits = lstm(input_embeds)\n",
    "    # Get predictions as the index corresponding to the highest logit score\n",
    "    pred_lbl = torch.argmax(logits, dim=-1)\n",
    "    # Decode labels\n",
    "    pred_labels = ner_le.inverse_transform(pred_lbl.reshape(-1).cpu().numpy())\n",
    "    # Group together tokens and predicted NER labels\n",
    "    labelled_sample = [{'text': token, 'ner_tag': str(lbl)} for token, lbl in zip(tokenized_sample, pred_labels)]\n",
    "\n",
    "    return labelled_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEC_9swOXkPc"
   },
   "source": [
    "And now call it on a custom sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1742333524017,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "Bb0EkaTfXkPc",
    "outputId": "700b7635-b8f3-4c04-a150-19945a7cc95a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Hello', 'ner_tag': 'O'},\n",
       " {'text': ',', 'ner_tag': 'O'},\n",
       " {'text': 'my', 'ner_tag': 'O'},\n",
       " {'text': 'name', 'ner_tag': 'O'},\n",
       " {'text': 'is', 'ner_tag': 'O'},\n",
       " {'text': 'Nicolò', 'ner_tag': 'B-MISC'},\n",
       " {'text': 'Brunello', 'ner_tag': 'I-MISC'},\n",
       " {'text': ',', 'ner_tag': 'O'},\n",
       " {'text': 'I', 'ner_tag': 'O'},\n",
       " {'text': 'am', 'ner_tag': 'O'},\n",
       " {'text': 'from', 'ner_tag': 'O'},\n",
       " {'text': 'Italy', 'ner_tag': 'B-LOC'},\n",
       " {'text': 'and', 'ner_tag': 'O'},\n",
       " {'text': 'I', 'ner_tag': 'O'},\n",
       " {'text': 'like', 'ner_tag': 'O'},\n",
       " {'text': 'pizza', 'ner_tag': 'O'},\n",
       " {'text': '.', 'ner_tag': 'O'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"Hello, my name is Nicolò Brunello, I am from Italy and I like pizza.\"\n",
    "\n",
    "predict(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff5-0SUKXkPc"
   },
   "source": [
    "Look how our custom model fails flawlessly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6G3EZtdXkPc"
   },
   "source": [
    "### Defining and training the RNN model for POS-tagging or Chunking\n",
    "\n",
    "You can do this at home to start getting familiar with PyTorch and RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "QitvSR1gXkPc"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMb8j2-2XkPc"
   },
   "source": [
    "## Text Classification with a Recurrent Neural Network\n",
    "\n",
    "In this last section of the notebook I will run through a quick example of using a Bidirectional LSTM (Long Short-term Memory) network for text classification.\n",
    "- RNNs extend embedding-based classification of text by taking word-order into account. They were, until relatively recently, the state-of-the-art when it came to training text classifiers.\n",
    "- Tensorflow is sophisticated toolkit for building Deep Neural Network models. We will use it to build the model. The tutorial follows mostly this Tensorflow tutorial: https://www.tensorflow.org/tutorials/text/text_classification_rnn\n",
    "    - Tensorflow is to deep learning learning what Java is to programming (joking...?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysjOGZrnXkPc"
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdiXno9jXkPc"
   },
   "source": [
    "First let's load the Twitter dataset we used in the second session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11889,
     "status": "ok",
     "timestamp": 1742334384694,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "WX-qsv-IXkPc",
    "outputId": "a6cb0918-5a42-4f40-f8c9-7c365cba0ca8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /home/adrien/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('twitter_samples')\n",
    "\n",
    "from nltk.corpus import twitter_samples\n",
    "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdKS2HdEXkPc"
   },
   "source": [
    "Remove emoticons from the positive and negative examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "MQqqGPlYXkPc"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "emoticon_regex = '(\\:\\w+\\:|\\<[\\/\\\\]?3|[\\(\\)\\\\\\D|\\*\\$][\\-\\^]?[\\:\\;\\=]|[\\:\\;\\=B8][\\-\\^]?[3DOPp\\@\\$\\*\\\\\\)\\(\\/\\|])(?=\\s|[\\!\\.\\?]|$)'\n",
    "positive_tweets_noemoticons = [re.sub(emoticon_regex,'',tweet) for tweet in positive_tweets]\n",
    "negative_tweets_noemoticons = [re.sub(emoticon_regex,'',tweet) for tweet in negative_tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMo6g9mcXkPc"
   },
   "source": [
    "And create the examples and labels as we did before. This time we will use numeric labels (0,1) instead of text labels ('negative','positive'), since the deep learning library we will use requires numeric class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "sVAlgu-IXkPc"
   },
   "outputs": [],
   "source": [
    "tweets_x = positive_tweets_noemoticons + negative_tweets_noemoticons\n",
    "tweets_y = [1]*len(positive_tweets) + [0]*len(negative_tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpMJO18SXkPc"
   },
   "source": [
    "And again, split the data into training, validation and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "y2eXMPFuXkPc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "temp_x, test_x, temp_y, test_y = train_test_split(tweets_x, tweets_y, test_size=0.2)\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(temp_x, temp_y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFRtKN0gXkPc"
   },
   "source": [
    "Now that we have the training and validation data prepared, we can import the Tensorflow library, and use it to load the training and validaton datasets into the tensorflow format. Note that:\n",
    "- Tensorflow comes installed on Google Colab.\n",
    "- If you run this notebook on your own machine you will need to first install tensorflow using '!pip install'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "wmwzZwBVMpbM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13108,
     "status": "ok",
     "timestamp": 1742334402993,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "XxX5PQ1-XkPc",
    "outputId": "0f31abf8-9500-446a-c14e-eada10f6046d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "gykDCG4YXkPc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 10:58:49.590789: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743411529.721846   42891 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743411529.760809   42891 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743411530.014061   42891 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743411530.014100   42891 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743411530.014105   42891 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743411530.014109   42891 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-31 10:58:50.045957: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-31 10:58:55.707482: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "train_tf = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "valid_tf = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeZgqPQYXkPc"
   },
   "source": [
    "Training will run on *batches* of the data at a time, so we need to create them.\n",
    "- We first use the shuffle command to randomise the order of the training data. (The buffer-size limits the number of instances loaded into memory when shuffling and is only for efficiency -- you could remove it.)\n",
    "- We then create the batches. Each batch will contain 64 examples.\n",
    "- The validation data needs to have the same format as the training data, so we batch it too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "I3k_AJMVXkPc"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_tf.shuffle(buffer_size=10000).batch(batch_size=64).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_tf.batch(batch_size=64).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCIJun8hXkPc"
   },
   "source": [
    "Let's have a look at the first batch in the training data. It consists of:\n",
    "- an array of strings (tweets)\n",
    "- an array of binary values (class labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1742334426274,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "4sqXOO8JXkPd",
    "outputId": "37f18cbd-f417-4dbb-9290-e7d49f8e327f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(64,), dtype=string, numpy=\n",
      "array([b'@AllRiseSilver uuu you make me hungry  haha enjoy your meal~',\n",
      "       b'@zouiriaII Good luck for ur exam ',\n",
      "       b'Anyone who wants to be added to the bot just DM me!!  #bot',\n",
      "       b\"@VickiCartagena The episode is excellent so far. I love Adam Beach's movies &amp; shows.I'm looking forward to seeing Suicide Squad next year\",\n",
      "       b'hey my fav nirvana song is smells like teen spirit rip amy winehouse :-)))))',\n",
      "       b'Dobar dan \\nThe Brand New Heavies #musicology2015 #day2 http://t.co/ejDalpfixn',\n",
      "       b'Our lovely intern @NicolaPantelli is leaving us today  but look at all these yummy treats she brought us! #yumyum http://t.co/zR2iuOYO5H',\n",
      "       b'Donna Thurston Collins we saw him today, he was the only dog sitting quietly in the kennel  911 NEEDS OUT... http://t.co/T8O7X2aRTm',\n",
      "       b'@CptFrantastic tentatively nibbling an apple and it seems okay  xxx',\n",
      "       b'@tsncblog good reasons I hope ',\n",
      "       b\"ugh I reaaly don't know what to do.  -ja\",\n",
      "       b'@April_Todd aww  what do you do?', b'Test ',\n",
      "       b'@_mahzo oh cool it worked. Cheers ',\n",
      "       b'how did i go to sleep at 12 last night but rn im up ',\n",
      "       b'@xWinnerMino yess im 1 year younger than u  no wonder youre huge boy',\n",
      "       b\"@JaydnNeal1 Aw bless you, this made me smile! I'm missing you too \",\n",
      "       b'@jaimeemelanie_ lmaoo! The best songs ever &lt We shall have our own little throwback this week (y) ',\n",
      "       b'why does she look so  http://t.co/2NajN7LP0c',\n",
      "       b'@HitItRichSlots Hey there, just a good suggestion, you guys should make a minions slot!! It would be so fun and cute ',\n",
      "       b'In the boat business maybe it\\'s \"outboarding\" too;)) coming back from a spell, reboarding? firing=offboarding! #HR https://t.co/l2Mcd1bW3w',\n",
      "       b'hi everyone, i love u all ', b'@triciadzn thanks ',\n",
      "       b'Pixgram is an app to have a creative slideshow with photos and music you love. Download Pixgram for free  https://t.co/iiqnFeiB5s \\xf0\\x9f\\x98\\x92\\xf0\\x9f\\x8c\\x9a',\n",
      "       b'@Mecastor01Mica  follow @jnlazts &amp; http://t.co/RCvcYYO0Iq follow u back ',\n",
      "       b\"At least there's one cool thing :-))))\", b'Life is smile ',\n",
      "       b\"Sure mate i will don't worry  thanks! https://t.co/H5bWUM9S3u\",\n",
      "       b'@grannaHarmony fback  indo harmos',\n",
      "       b'its leo season  \\xe2\\x99\\x8c\\xef\\xb8\\x8f', b'@mcjen thank you ',\n",
      "       b'@KatGraham_Italy You did save their lives! ',\n",
      "       b'@RichyCee93 \\xc2\\xa320 deposit to secure one ',\n",
      "       b'@Chabeezumba I miss the team na and coach and training :((((',\n",
      "       b'@fivedorkz why omg ',\n",
      "       b'ALMOST DONE WITH MY MASTER SWORD  -Princess Zelda http://t.co/dPcL2mGjdc',\n",
      "       b\"@woIfgaang it's the story of our life  haha look who's talking\",\n",
      "       b\"@muhammadskates  that's a long time\",\n",
      "       b'making Alyssa rub my tummy :)))',\n",
      "       b'When people tell me I have good taste in music  ^.^',\n",
      "       b\"@TruDan97 @iphonetips1 @FuzionDroid Hmm i thought I was #1? Well, I'll just go and turn off the server then ... ciao \",\n",
      "       b'ph vips next week na :((((',\n",
      "       b\"I wish I had Cara Delevingne's face \",\n",
      "       b'@itspatgonzales  follow @jnlazts &amp; http://t.co/RCvcYYO0Iq follow u back ',\n",
      "       b'hopeless for tmr ',\n",
      "       b\"I'm thinking garden party ... #N04JS Buy 6 bottles of wine save 25%!! @chrisyamahar201 @sainsburys #prosecco http://t.co/M3kvcw24N7\",\n",
      "       b'Oh my god ',\n",
      "       b'@brigserman thanks for sharing! Wishing you a wicked weekend ',\n",
      "       b'Thank you Beiruting!  http://t.co/BPl4vWRgPU',\n",
      "       b\"@RMBLees @dicehateme can't get them anywhere now. \",\n",
      "       b\"@aepfel our pleasure! Let us know if there's anything else you need \",\n",
      "       b'MY snapchat - JillMill19 #snapchat #kikmeboys #hot #webcam #teens #elfindelmundo #sexi  http://t.co/HFYIeohQZv',\n",
      "       b\"@RoyalMail I'm following now \",\n",
      "       b'@derabbie Hi Doug, how are you today? Thanks a lot for the follow, I look forward to tweeting with you ',\n",
      "       b\"@RookieSenpai @arcadester it is the id conflict thanks for the help  here's the screenshot of it working\",\n",
      "       b'@Mark23Baracael mark followback ',\n",
      "       b'I wanna change my avi but uSanele ',\n",
      "       b'My week off work is going far too quick!! ',\n",
      "       b'@keevacrampton @AineAbbott1998 I always forget to tag ppl:):)',\n",
      "       b'Stats for the week have arrived. 1 new follower and NO unfollowers  via http://t.co/zybHHnSkwl.',\n",
      "       b'@dreesti \\nWaiter: here is your bill sir??\\nCustomer: Ok, where is the kitchen??\\n',\n",
      "       b\"Please keep him in your prayers. He's very fragile. I can't even cry, I feel like I've done too much of that this week already. \",\n",
      "       b'First time travelling to expo by myself. &amp; the worse part is, ive not been to expo before ',\n",
      "       b\"i slept all day and now i can't sleep \"], dtype=object)>, <tf.Tensor: shape=(64,), dtype=int32, numpy=\n",
      "array([0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
      "      dtype=int32)>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 10:58:55.857000: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataset.take(1):\n",
    "  print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTwmMzIoXkPd"
   },
   "source": [
    "Now that we have the text data in the format required, we can vectorize it. We will need to make use a specific text vectorization module from tensorflow to do this.\n",
    "- We first limit the vocabulary of the vectorizer to 5000,\n",
    "- then extract only the text portion of the training dataset,\n",
    "- and finally fit the vectorizer to the text using the 'adapt' method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "v6BrcfEoXkPd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 10:58:56.582802: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "vectorizer = TextVectorization(max_tokens=5000)\n",
    "train_text = train_dataset.map(lambda text, label: text)\n",
    "vectorizer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6lVOC3srXkPd"
   },
   "source": [
    "Let's print out the first tokens form the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1742334431965,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "hDErP-eLXkPd",
    "outputId": "0162586b-4b12-4600-8bbc-4e06973b689a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'i',\n",
       " 'you',\n",
       " 'to',\n",
       " 'the',\n",
       " 'a',\n",
       " 'and',\n",
       " 'my',\n",
       " 'for',\n",
       " 'me',\n",
       " 'it',\n",
       " 'in',\n",
       " 'is',\n",
       " 'so',\n",
       " 'have',\n",
       " 'of',\n",
       " 'im',\n",
       " 'this',\n",
       " 'but',\n",
       " 'that',\n",
       " 'on',\n",
       " 'be',\n",
       " 'its',\n",
       " 'thanks',\n",
       " 'follow',\n",
       " 'no',\n",
       " 'not',\n",
       " 'your',\n",
       " 'just',\n",
       " 'like',\n",
       " 'love',\n",
       " 'with',\n",
       " 'u',\n",
       " 'all',\n",
       " 'at',\n",
       " 'we',\n",
       " 'please',\n",
       " 'too',\n",
       " 'was',\n",
       " 'are',\n",
       " 'good',\n",
       " 'get',\n",
       " 'can',\n",
       " 'do',\n",
       " 'up',\n",
       " 'dont',\n",
       " 'want',\n",
       " 'day',\n",
       " 'cant',\n",
       " 'back',\n",
       " 'now',\n",
       " 'thank',\n",
       " 'will',\n",
       " 'know',\n",
       " 'one',\n",
       " 'miss',\n",
       " 'see',\n",
       " 'if',\n",
       " 'time',\n",
       " 'amp',\n",
       " 'out',\n",
       " 'when',\n",
       " 'happy',\n",
       " 'about',\n",
       " 'go',\n",
       " 'much',\n",
       " 'what',\n",
       " 'today',\n",
       " 'really',\n",
       " 'why',\n",
       " 'hope',\n",
       " 'hi',\n",
       " 'he',\n",
       " 'more',\n",
       " 'from',\n",
       " 'our',\n",
       " 'new',\n",
       " 'great',\n",
       " 'us',\n",
       " 'how',\n",
       " 'as',\n",
       " 'here',\n",
       " 'an',\n",
       " 'would',\n",
       " 'ill',\n",
       " 'been',\n",
       " 'work',\n",
       " 'there',\n",
       " 'oh',\n",
       " 'am',\n",
       " 'well',\n",
       " 'sorry',\n",
       " 'lt',\n",
       " 'need',\n",
       " 'got',\n",
       " 'still',\n",
       " 'they',\n",
       " 'thats',\n",
       " 'them']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorizer.get_vocabulary()\n",
    "vocab[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2AnCbfIXkPd"
   },
   "source": [
    "Note that the first two tokens in the vocabulary are the empty token '', and the unknown token '[UNK]'. The latter is used to mask out-of-vocabulary tokens in the text\n",
    "\n",
    "We can now use the vectorizer to encode a tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1742334432038,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "reL7OIXpXkPd",
    "outputId": "658aea25-acd5-4ef9-c0e7-d0c526503ede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:      This is my first tweet! It contains one out-of-vocabulary term. Any suggestions for extending this tweet?\n",
      "Encoded:    [  18   13    8  192  232   11    1   55    1 2360  165    1    9    1\n",
      "   18  232]\n",
      "Recovered:  this is my first tweet it [UNK] one [UNK] term any [UNK] for [UNK] this tweet\n"
     ]
    }
   ],
   "source": [
    "text = 'This is my first tweet! It contains one out-of-vocabulary term. Any suggestions for extending this tweet?'\n",
    "encoding = vectorizer([text]).numpy()[0]\n",
    "print('Tweet:     ', text)\n",
    "print('Encoded:   ', encoding)\n",
    "print('Recovered: ',' '.join([vocab[i] for i in encoding]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0wCv-cPXkPd"
   },
   "source": [
    "Note that the vectorizer is not turning the text into a single vector, but is simply replacing the vocabulary words by their indices. If a word is not present in the dictionary it is replaced by the unknown token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAeaJ6WvXkPd"
   },
   "source": [
    "Let's have a look at some actual examples from the dataset, printing out the first 6 tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1742334432489,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "4aghpfMAXkPd",
    "outputId": "103c9bf1-22c1-4055-bc4f-b31a66db029a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:      @AllRiseSilver uuu you make me hungry  haha enjoy your meal~\n",
      "Encoded:    [3546 4534    3  112   10  440  156  209   28 1853]\n",
      "Recovered:  allrisesilver uuu you make me hungry haha enjoy your meal\n",
      "\n",
      "Tweet:      @zouiriaII Good luck for ur exam \n",
      "Encoded:    [3772   41  375    9  231 1508]\n",
      "Recovered:  zouiriaii good luck for ur exam\n",
      "\n",
      "Tweet:      Anyone who wants to be added to the bot just DM me!!  #bot\n",
      "Encoded:    [ 546  193  579    4   22  961    4    5 1574   29  235   10 1574]\n",
      "Recovered:  anyone who wants to be added to the bot just dm me bot\n",
      "\n",
      "Tweet:      @VickiCartagena The episode is excellent so far. I love Adam Beach's movies &amp; shows.I'm looking forward to seeing Suicide Squad next year\n",
      "Encoded:    [4465    5 1063   13 1254   14  428    2   31    1    1  903   60    1\n",
      "  190  427    4  363 2406    1  186  300]\n",
      "Recovered:  vickicartagena the episode is excellent so far i love [UNK] [UNK] movies amp [UNK] looking forward to seeing suicide [UNK] next year\n",
      "\n",
      "Tweet:      hey my fav nirvana song is smells like teen spirit rip amy winehouse :-)))))\n",
      "Encoded:    [ 130    8  844    1  316   13 1722   30 2367 1138  646 3538 4175]\n",
      "Recovered:  hey my fav [UNK] song is smells like teen spirit rip amy winehouse\n",
      "\n",
      "Tweet:      Dobar dan \n",
      "The Brand New Heavies #musicology2015 #day2 http://t.co/ejDalpfixn\n",
      "Encoded:    [   1 1540    5 1570   77    1    1    1    1]\n",
      "Recovered:  [UNK] dan the brand new [UNK] [UNK] [UNK] [UNK]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in batch[0][:6].numpy():\n",
    "    encoding = vectorizer([text]).numpy()[0]\n",
    "    print('Tweet:     ', text.decode(\"utf-8\"))\n",
    "    print('Encoded:   ', encoding)\n",
    "    print('Recovered: ',' '.join([vocab[i] for i in encoding]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JeDyajurXkPd"
   },
   "source": [
    "### Defining the RNN model\n",
    "\n",
    "Now we can define the model, which contains four layers:\n",
    "- an input embedding layer which produces word embeddings of size 64\n",
    "- a bidirectional LSTM layer\n",
    "- 2 dense (aka fully connected) layers that maps the 2 embedding vectors (of size 64) produced by the bidirectional LSTM down to a single neuron   \n",
    "\n",
    "This constitutes a relatively standard basic RNN architecture. (The details of why these specific components are chosen is beyond the scope of this tutorial.)  \n",
    "\n",
    "Once the model has been defined it is compiled in the following step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "O7Db-xGTXkPd"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    vectorizer,\n",
    "    tf.keras.layers.Embedding(input_dim=len(vectorizer.get_vocabulary()), output_dim=64, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'], optimizer=tf.keras.optimizers.Adam(1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDcdvj3fXkPd"
   },
   "source": [
    "Fit the model by running it for 10 epochs (iterations over the training data).\n",
    "- Note that we provide it with both the training dataset and the validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 75615,
     "status": "ok",
     "timestamp": 1742334508672,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "QNij_XUrXkPd",
    "outputId": "77ec584b-68d2-405e-9504-6f72e4483d83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.5115 - loss: 0.6924 - val_accuracy: 0.4984 - val_loss: 0.6856\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5170 - loss: 0.6745 - val_accuracy: 0.6336 - val_loss: 0.6377\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6838 - loss: 0.5722 - val_accuracy: 0.7016 - val_loss: 0.5680\n",
      "Epoch 4/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7557 - loss: 0.4853 - val_accuracy: 0.7305 - val_loss: 0.5645\n",
      "Epoch 5/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8037 - loss: 0.4179 - val_accuracy: 0.7469 - val_loss: 0.5522\n",
      "Epoch 6/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8351 - loss: 0.3618 - val_accuracy: 0.7484 - val_loss: 0.5656\n",
      "Epoch 7/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8680 - loss: 0.3062 - val_accuracy: 0.7531 - val_loss: 0.5781\n",
      "Epoch 8/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8914 - loss: 0.2708 - val_accuracy: 0.7563 - val_loss: 0.6366\n",
      "Epoch 9/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8973 - loss: 0.2395 - val_accuracy: 0.7594 - val_loss: 0.6597\n",
      "Epoch 10/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9147 - loss: 0.2214 - val_accuracy: 0.7422 - val_loss: 0.7954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x70ec9044f590>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=10, validation_data=valid_dataset, validation_steps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chkFHzAjXkPd"
   },
   "source": [
    "Once we've trained the model we can check the final accuracy on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1742334514147,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "6VGjzmPPXkPd",
    "outputId": "dc1ddd8c-6fcd-45f4-bd26-125c822bf4b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7401 - loss: 0.8012\n",
      "Validation Loss: 0.7541018128395081\n",
      "Validation Accuracy:  0.7481250166893005\n"
     ]
    }
   ],
   "source": [
    "valid_loss, valid_acc = model.evaluate(valid_dataset)\n",
    "\n",
    "print('Validation Loss: {}'.format(valid_loss))\n",
    "print('Validation Accuracy: ',valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUFlKyZwXkPd"
   },
   "source": [
    "We can have a look at the predictions from the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 709,
     "status": "ok",
     "timestamp": 1742334516906,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "n44pazsNXkPd",
    "outputId": "e453a8a2-acc1-4d23-ca55-22170664d690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564ms/step\n",
      "tweet:  I can't believe how much fun I'm having learning to train a text classifier with a bidirectional LSTM!\n",
      "encoded as:  i cant believe how much fun im having [UNK] to train a text [UNK] with a [UNK] [UNK]\n",
      "predicted value:  0.23580222\n",
      "predicted label:  positive\n",
      "\n",
      "tweet:  I am really confused. I want my mommy.\n",
      "encoded as:  i am really confused i want my mommy\n",
      "predicted value:  -2.225406\n",
      "predicted label:  negative\n",
      "\n",
      "tweet:  The internet connection has been pretty annoying today!\n",
      "encoded as:  the internet [UNK] has been pretty annoying today\n",
      "predicted value:  -3.1503272\n",
      "predicted label:  negative\n",
      "\n",
      "tweet:  They just played my favourite song on the radio.\n",
      "encoded as:  they just played my favourite song on the radio\n",
      "predicted value:  1.3934795\n",
      "predicted label:  positive\n",
      "\n",
      "tweet:  I don't like going to the dentist.\n",
      "encoded as:  i dont like going to the dentist\n",
      "predicted value:  -2.1029565\n",
      "predicted label:  negative\n",
      "\n",
      "tweet:  I am so happy today!\n",
      "encoded as:  i am so happy today\n",
      "predicted value:  1.8663625\n",
      "predicted label:  positive\n",
      "\n",
      "tweet:  I am so unhappy today!\n",
      "encoded as:  i am so unhappy today\n",
      "predicted value:  -1.6495366\n",
      "predicted label:  negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "tweets.append('I can\\'t believe how much fun I\\'m having learning to train a text classifier with a bidirectional LSTM!')\n",
    "tweets.append('I am really confused. I want my mommy.')\n",
    "tweets.append('The internet connection has been pretty annoying today!')\n",
    "tweets.append('They just played my favourite song on the radio.')\n",
    "tweets.append(\"I don't like going to the dentist.\")\n",
    "tweets.append('I am so happy today!')\n",
    "tweets.append('I am so unhappy today!')\n",
    "\n",
    "predictions = model.predict(tf.convert_to_tensor(tweets))\n",
    "\n",
    "for i in range(len(tweets)):\n",
    "  print('tweet: ',tweets[i])\n",
    "  encoding = vectorizer([tweets[i]]).numpy()[0]\n",
    "  print('encoded as: ',' '.join([vocab[j] for j in encoding]))\n",
    "  print('predicted value: ', predictions[i][0])\n",
    "  print('predicted label: ', 'negative' if (predictions[i]<0) else 'positive')\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aV-2gZZtXkPd"
   },
   "source": [
    "And calculate the usual evaluation metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 7667,
     "status": "ok",
     "timestamp": 1742334782112,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "-dBXIPMEXkPd",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "00d791cf-9436-429b-ff4d-b9bbaf598049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "accuracy: 0.744375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x70ec4c1dbe90>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_y = [0 if (pred < 0) else 1 for pred in model.predict(tf.convert_to_tensor(valid_x))]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy: '+ str(accuracy_score(pred_y, valid_y)))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix(valid_y, pred_y,normalize='true'), display_labels=['negative', 'positive'])\n",
    "cmd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-BKhc-eXkPd"
   },
   "source": [
    "Finally, let's print out the model summary to get an understanding of the number of parameters in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1742334793622,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "v3Flbj4zXkPd",
    "outputId": "57b8e84b-fb25-4377-f075-3fc0dec86f56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ text_vectorization              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │       \u001b[38;5;34m320,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m66,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,183,109</span> (4.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,183,109\u001b[0m (4.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">394,369</span> (1.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m394,369\u001b[0m (1.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">788,740</span> (3.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m788,740\u001b[0m (3.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdT7hq_rXkPe"
   },
   "source": [
    "Most of the parameters are used to define the embedding, then the LSTMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRDCLcREXkPe"
   },
   "source": [
    "### Encoder-Decoder models\n",
    "\n",
    "The next step after using sequential models for labelling and classification is to move to encoder-decoder models.\n",
    "Even better, encoder-decoder models with attention, to align the sequence processed by the encoder and the sequence processed by the decoder.\n",
    "\n",
    "We warmly recommend to take a look at this tutorial: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html (you can tun it in Google Colab).\n",
    "The tutorial shows how to build a translation model using recurrent neural networks and the attention mechanism.\n",
    "This was the last step before moving to the Transformer architectures (the current state-of-the-art).\n",
    "The tutorial is useful to get a better understanding of the attention mechanism and how it is used to learn the alignment between two sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OgRPEb6pdlv"
   },
   "source": [
    "## Installing spaCy and downloading models\n",
    "\n",
    "First we need to check whether the spaCy library is installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4468,
     "status": "ok",
     "timestamp": 1742335852823,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "3083U81cpdlv",
    "outputId": "6a7e6daa-df88-4795-f0f5-1cc3e04e713b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJ1xLIcHpdlw"
   },
   "source": [
    "Then we need to download pretrained models for use with spaCy. We will load models for both English and Italian:\n",
    "- The models are called 'en_core_web_sm' and 'it_core_news_sm', where the 'web'/'news' indicates what type of collection the model was trained on and the 'sm' at the end indicates that we are using the 'small' version of the models\n",
    "- Other models are available here: https://spacy.io/models\n",
    "- The following code calls the python executable instructing it to run the module 'spacy', which in turn download the models. See discussion here: https://stackoverflow.com/questions/46148033/unable-to-load-en-from-spacy-in-jupyter-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28318,
     "status": "ok",
     "timestamp": 1742335881140,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "dyv-NpFbpdlw",
    "outputId": "da163398-7b66-4309-c545-c2a9c69dfd38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting it-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.8.0/it_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('it_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm\n",
    "!python -m spacy download it_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYRlbtvspdlx"
   },
   "source": [
    "We are now ready to import spacy and load a model. Let's start with the English model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "4KHrsza0pdlx"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp_model = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jy4K8dRApdlx"
   },
   "source": [
    "Consider the following piece of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1742335888334,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "3MGjLJU0pdlx",
    "outputId": "fb6db651-678c-4cd6-cc9b-976c003ac196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melbourne is to re-enter Stage 3 lockdown after a record increase in cases. Victorian state premier Daniel Andrews said there was “simply no alternative” to reimposing stay at home restrictions in Australia’s second-biggest city.\n"
     ]
    }
   ],
   "source": [
    "text = 'Melbourne is to re-enter Stage 3 lockdown after a record increase in cases. Victorian state premier Daniel Andrews said there was “simply no alternative” to reimposing stay at home restrictions in Australia’s second-biggest city.'\n",
    "# text = \"Good evening, London. Allow me first to apologize for this interruption. I do, like many of you, appreciate the comforts of everyday routine, the security of the familiar, the tranquillity of repetition. I enjoy them as much as any bloke. But in the spirit of commemoration, whereby those important events of the past, usually associated with someone's death or the end of some awful bloody struggle, are celebrated with a nice holiday, I thought we could mark this November the fifth, a day that is sadly no longer remembered, by taking some time out of our daily lives to sit down and have a little chat.\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_rCI0Hbpdly"
   },
   "source": [
    "Parse the text using the NLP engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 55,
     "status": "ok",
     "timestamp": 1742335888390,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "xmpvXvjapdly",
    "outputId": "4460a448-b323-4cd8-cd82-84c5e84704b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melbourne is to re-enter Stage 3 lockdown after a record increase in cases. Victorian state premier Daniel Andrews said there was “simply no alternative” to reimposing stay at home restrictions in Australia’s second-biggest city.\n"
     ]
    }
   ],
   "source": [
    "parsed_text = nlp_model(text)\n",
    "print(parsed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnXyGOx0pdlz"
   },
   "source": [
    "Did it do something? It looks like it has just output the same text.\n",
    "- Actually, yes. It has parsed the input and built its internal datastructure from it.\n",
    "- Note that the length of the parsed object is in words, not characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1742335888408,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "fbAOI2Mnpdlz",
    "outputId": "ed11c137-3490-4dbb-a445-a5ef6ca51b24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the original text is 229 chacacters\n",
      "The length of the parsed text is 43 words\n"
     ]
    }
   ],
   "source": [
    "print(f'The length of the original text is {len(text)} chacacters')\n",
    "print(f'The length of the parsed text is {len(parsed_text)} words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xImJ-i_Lpdlz"
   },
   "source": [
    "## Part-of-Speech Tagging\n",
    "\n",
    "While parsing the text, spaCy performs part-of-speech (POS) tagging.\n",
    "- We can see the POS tag for each token as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1742335888453,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "Ho4HEJTLpdlz",
    "outputId": "56e6d8dc-26ab-4b04-f2ac-4bce2e2eb6b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Melbourne, 'PROPN'),\n",
       " (is, 'AUX'),\n",
       " (to, 'PART'),\n",
       " (re, 'VERB'),\n",
       " (-, 'VERB'),\n",
       " (enter, 'VERB'),\n",
       " (Stage, 'PROPN'),\n",
       " (3, 'NUM'),\n",
       " (lockdown, 'NOUN'),\n",
       " (after, 'ADP'),\n",
       " (a, 'DET'),\n",
       " (record, 'ADJ'),\n",
       " (increase, 'NOUN'),\n",
       " (in, 'ADP'),\n",
       " (cases, 'NOUN'),\n",
       " (., 'PUNCT'),\n",
       " (Victorian, 'ADJ'),\n",
       " (state, 'NOUN'),\n",
       " (premier, 'NOUN'),\n",
       " (Daniel, 'PROPN'),\n",
       " (Andrews, 'PROPN'),\n",
       " (said, 'VERB'),\n",
       " (there, 'PRON'),\n",
       " (was, 'VERB'),\n",
       " (“, 'PUNCT'),\n",
       " (simply, 'ADV'),\n",
       " (no, 'DET'),\n",
       " (alternative, 'NOUN'),\n",
       " (”, 'PUNCT'),\n",
       " (to, 'ADP'),\n",
       " (reimposing, 'VERB'),\n",
       " (stay, 'NOUN'),\n",
       " (at, 'ADP'),\n",
       " (home, 'NOUN'),\n",
       " (restrictions, 'NOUN'),\n",
       " (in, 'ADP'),\n",
       " (Australia, 'PROPN'),\n",
       " (’s, 'PART'),\n",
       " (second, 'ADV'),\n",
       " (-, 'PUNCT'),\n",
       " (biggest, 'ADJ'),\n",
       " (city, 'NOUN'),\n",
       " (., 'PUNCT')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(w,w.pos_) for w in parsed_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFEzvleepdlz"
   },
   "source": [
    "Who remembers their grammar from high school? What do all those POS symbols mean?\n",
    "- You can find an explanation of the POS tags on this website https://spacy.io/api/annotation in the section \"Universal Part-of-speech Tags\"\n",
    "\n",
    "What can we do with POS tags?\n",
    "- Well, we could select all terms that have a certain tag, such as all adjectives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1742335888454,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "6Kcjc28lpdl0",
    "outputId": "5fd7f8ac-4d4a-494e-9088-f53c3f10909c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{record, Victorian, biggest}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(w for w in parsed_text if w.pos_=='ADJ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftw5HEYEpdl0"
   },
   "source": [
    "That was a little underwhelming.\n",
    "- Let's try it on Alice in Wonderland chapter 1 text. (You'll need to upload it again to Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 602,
     "status": "ok",
     "timestamp": 1742335889055,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "tGRt3HF8pdl0",
    "outputId": "dc8e1e34-6fd4-4525-da7e-7c71e86beb8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['afraid', 'best', 'brave', 'bright', 'certain', 'close', 'common', 'cool', 'curious', 'dark', 'deep', 'dreamy', 'dry', 'dull', 'empty', 'enough', 'fancy', 'few', 'first', 'fond', 'funny', 'glad', 'golden', 'good', 'grand', 'great', 'high', 'hot', 'hurt', 'ignorant', 'impossible', 'large', 'larger', 'late', 'legged', 'likely', 'little', 'long', 'loveliest', 'lovely', 'low', 'many', 'mixed', 'much', 'natural', 'nervous', 'nice', 'other', 'out', 'own', 'pine', 'pink', 'poor', 'red', 'remarkable', 'respectable', 'right', 'same', 'second', 'several', 'simple', 'sleepy', 'slippery', 'small', 'smaller', 'solid', 'stupid', 'such', 'sure', 'surprised', 'tart', 'tiny', 'tired', 'true', 'unpleasant', 'wild', 'wise', 'worth']\n"
     ]
    }
   ],
   "source": [
    "adjectives = sorted(set(w.text for w in nlp_model(open(\"docs/Alice_Chapter1.txt\", \"r\").read()) if w.pos_=='ADJ'))\n",
    "print(adjectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pct1jNdEpdl0"
   },
   "source": [
    "You can see how descriptive a writer Lewis Carroll was!\n",
    "\n",
    "This leads us to one explanation as to why we might want to extract POS tags from text:\n",
    "- They can sometimes be useful for **extracting features** (often handcrafted ones) for certain text classification tasks (such as authorship identification).\n",
    "- This is particularly the case if only a small amount of training data is available.  \n",
    "- For example, in this article (https://towardsdatascience.com/automatically-detect-covid-19-misinformation-f7ceca1dc1c7) hand-crafted features are extracted for classifying covid misinformation.\n",
    "\n",
    "Another reason why we might consider POS tagging is to **reduce ambiguity** in our bag-of-words representation by appending POS tags to word occurrences.\n",
    "- Consider the following two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742335889055,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "2iO992Q-pdl0",
    "outputId": "7186fbd8-389a-415a-9c46-76e938d3f438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I catch the train to and from work.      <-- 'train' is a NOUN\n",
      "I like to train at least 6 times a week. <-- 'train' is a VERB\n"
     ]
    }
   ],
   "source": [
    "ex1 = 'I catch the train to and from work.'       # This is Prof. Mark Carman speaking\n",
    "ex2 = 'I like to train at least 6 times a week.'  # This is Prof. Jacked Carman speaking\n",
    "\n",
    "print(ex1, '     <-- \\'train\\' is a', nlp_model(ex1)[3].pos_)\n",
    "print(ex2, '<-- \\'train\\' is a', nlp_model(ex2)[3].pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHlqof06pdl1"
   },
   "source": [
    "The second sentence has nothing to do with trains, despite containing the word 'train'!\n",
    "- We could deal with this issue by appending the POS tag to the observed literal to form vocabulary elements: train_NOUN, train_VERB\n",
    "\n",
    "A final reason why we might think about running POS tagging would be to extract proper nouns from the text, since they refer to real entities that are being discussed in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1742335889055,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "kW4TbHffpdl1",
    "outputId": "c865f77c-c137-4007-b1ef-31779504e96a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Melbourne', 'Stage', 'Daniel', 'Andrews', 'Australia']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.text for w in parsed_text if w.pos_=='PROPN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDl1pPoSpdl1"
   },
   "source": [
    "Shortly though, we will talk about Entity-extraction, which is the task of identifying and categorising the entities discussed in the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDh0iS65pdl1"
   },
   "source": [
    "## Lemmatization\n",
    "\n",
    "While parsing, spaCy also performs lemmatization.\n",
    "- Lemmatization is the process of extracting the 'lemma' for each token, which is the canonical form of the word that would be found in the dictionary, (see https://en.wikipedia.org/wiki/Lemma_(morphology))\n",
    "- Basically, verbs converted to their root form, e.g.: **went, going, goes, gone => go**\n",
    "- And nouns are retuned to singular form: **kittens => kitten**\n",
    "- Lemmatization is a more complicated POS-aware process than stemming (https://en.wikipedia.org/wiki/Stemming). Stemmers simply apply a set of language-specific syntax rules to recover the stem of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1742335889055,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "EevBrQRbpdl1",
    "outputId": "2080eb28-8fc2-441d-b480-9431ddc82bb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Melbourne, 'Melbourne'),\n",
       " (is, 'be'),\n",
       " (to, 'to'),\n",
       " (re, 're'),\n",
       " (-, '-'),\n",
       " (enter, 'enter'),\n",
       " (Stage, 'Stage'),\n",
       " (3, '3'),\n",
       " (lockdown, 'lockdown'),\n",
       " (after, 'after'),\n",
       " (a, 'a'),\n",
       " (record, 'record'),\n",
       " (increase, 'increase'),\n",
       " (in, 'in'),\n",
       " (cases, 'case'),\n",
       " (., '.'),\n",
       " (Victorian, 'victorian'),\n",
       " (state, 'state'),\n",
       " (premier, 'premier'),\n",
       " (Daniel, 'Daniel'),\n",
       " (Andrews, 'Andrews'),\n",
       " (said, 'say'),\n",
       " (there, 'there'),\n",
       " (was, 'be'),\n",
       " (“, '\"'),\n",
       " (simply, 'simply'),\n",
       " (no, 'no'),\n",
       " (alternative, 'alternative'),\n",
       " (”, '\"'),\n",
       " (to, 'to'),\n",
       " (reimposing, 'reimpose'),\n",
       " (stay, 'stay'),\n",
       " (at, 'at'),\n",
       " (home, 'home'),\n",
       " (restrictions, 'restriction'),\n",
       " (in, 'in'),\n",
       " (Australia, 'Australia'),\n",
       " (’s, '’s'),\n",
       " (second, 'second'),\n",
       " (-, '-'),\n",
       " (biggest, 'big'),\n",
       " (city, 'city'),\n",
       " (., '.')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(x, x.lemma_) for x in parsed_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEIoq1RFpdl1"
   },
   "source": [
    "Why would one want to perfom lemmatization? -- Or stemming for that matter?\n",
    "- to **reduce the vocabulary size** and thereby generalise the representation. -- This used to be very important for improving performance of search engine performance (better similarity measures between documents) and also classifiers on small datasets, (before word embeddings came along).\n",
    "- to **look-up information** about the word in a dictionary/ontology, such as WordNet (https://en.wikipedia.org/wiki/WordNet). This used to be an important way to compute semantic similarity between words, but again, word embeddngs probably do a better job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vBQ7f0tpdl2"
   },
   "source": [
    "## Dependency Parsing\n",
    "\n",
    "Tradititonally in Natural Language Processing, text is processed in a pipeline that first tokenizes, then POS tags, lemmatizes and finaly dependency parses a piece of text.\n",
    "- The idea with dependency parsing is to determine what function each of the word instances is fulfilling in the sentence.\n",
    "- What is the subject and object of the sentence?\n",
    "- Which noun is each adjective referring to?\n",
    "\n",
    "So while parsing the text, the spaCy model also generates a **dependency parse tree**, which can be displayed using 'displacy':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1742335889068,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "Dbz57hc5pdl2",
    "outputId": "4ed55b42-b135-4281-aeab-1b7d22506ae4"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "# displacy.render(parsed_text, jupyter=True, style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quwWOjbOpdl3"
   },
   "source": [
    "Such dependency trees are interesting for understanding and visualising language (particularly for linguists) and could possibly be used for some downstream tasks (say checking ambiguity in legal documents).  \n",
    "\n",
    "Consider the sentences:\n",
    "- *The girl saw a man carrying a telescope.*\n",
    "- *The girl saw a man with a telescope.*\n",
    "\n",
    "Who had the telescope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1742335889094,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "_AxJLNswpdl3",
    "outputId": "b115785e-262f-420b-8725-bcb73d2d3bc3"
   },
   "outputs": [],
   "source": [
    "# displacy.render(nlp_model('The girl saw a man carrying a telescope.'),jupyter=True,style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1742335889110,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "7abgGOdwpdl3",
    "outputId": "1e7bcd76-41e0-49ed-a87c-6c95fa9aedea"
   },
   "outputs": [],
   "source": [
    "# displacy.render(nlp_model('The girl saw a man with a telescope.'),jupyter=True,style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fIZq6zIhPbk"
   },
   "source": [
    "The second sentence is ambiguous: The girl may have made use of her telescope or the man may have been using the girl's telescope...\n",
    "- Language is full of such ambiguities which we as humans naturally deal with using our prior knowledge and abilty to construct mental models of the situations described.\n",
    "- This process is not without its biases:\n",
    "  - *The doctor went over to talk to the nurse. She told him that she had just given the patient 5mg of Vicodin and the child had started convulsing. He listened attentively as she explained what had happened. The doctor was worried that the patient should not be given any more painkillers. The nurse told the doctor not to worry, that the patient was in good hands, and that he would let her know immediately if the child's condition changed.*\n",
    "  - What gender are the doctor and the nurse?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uE1efbqpdl3"
   },
   "source": [
    "## Extracting Entities\n",
    "\n",
    "A more important output than the depency parse, from a text mining perspective, is the list of named-entities present in the text\n",
    "- **named entities** are objects in the real world, e.g. persons, products, organizations, locations, etc.\n",
    "  - see https://en.wikipedia.org/wiki/Named_entity\n",
    "- if spacy has found any named entities while parsing the text, we can access them as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742335889116,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "irYwH5WVpdl3",
    "outputId": "c6e1b673-71a0-4dbb-d26e-560d5a9da6f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Melbourne, 3, Victorian, Daniel Andrews, Australia, second)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_text.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rv6krbXmpdl3"
   },
   "source": [
    "Note that the entities are not single word tokens but short sequences of words: 'Stage 3' and 'Daniel Andrews'.\n",
    "\n",
    "Not only does spacy extract the entities, but also categorises them based on their type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1742335889125,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "EXA2FRzXpdl4",
    "outputId": "a74825f8-e712-4fbd-8e9c-88101b064b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Melbourne', 'GPE'), ('3', 'CARDINAL'), ('Victorian', 'NORP'), ('Daniel Andrews', 'PERSON'), ('Australia', 'GPE'), ('second', 'ORDINAL')]\n"
     ]
    }
   ],
   "source": [
    "print([(ent.text, ent.label_) for ent in parsed_text.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyp09Uelpdl4"
   },
   "source": [
    "The city and country locations have been labeled 'GPE' for 'geopolitical entity', while the Premier of Victoria has been correctly identified as a person.\n",
    "- Here is the list of all entity types that spaCy looks for: https://spacy.io/api/annotation#section-named-entities\n",
    "\n",
    "Internally, the output of the Named Entity Recogniser is a sequence annotated with entities using inside-outside-beginning encoding:\n",
    "- see https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)\n",
    "- We can print out this labeling as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1742335889128,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "-E1H-RM6pdl4",
    "outputId": "5b9ac0c8-5f80-47ab-d356-994907984e63"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Melbourne, 'B', 'GPE'),\n",
       " (is, 'O', ''),\n",
       " (to, 'O', ''),\n",
       " (re, 'O', ''),\n",
       " (-, 'O', ''),\n",
       " (enter, 'O', ''),\n",
       " (Stage, 'O', ''),\n",
       " (3, 'B', 'CARDINAL'),\n",
       " (lockdown, 'O', ''),\n",
       " (after, 'O', ''),\n",
       " (a, 'O', ''),\n",
       " (record, 'O', ''),\n",
       " (increase, 'O', ''),\n",
       " (in, 'O', ''),\n",
       " (cases, 'O', ''),\n",
       " (., 'O', ''),\n",
       " (Victorian, 'B', 'NORP'),\n",
       " (state, 'O', ''),\n",
       " (premier, 'O', ''),\n",
       " (Daniel, 'B', 'PERSON'),\n",
       " (Andrews, 'I', 'PERSON'),\n",
       " (said, 'O', ''),\n",
       " (there, 'O', ''),\n",
       " (was, 'O', ''),\n",
       " (“, 'O', ''),\n",
       " (simply, 'O', ''),\n",
       " (no, 'O', ''),\n",
       " (alternative, 'O', ''),\n",
       " (”, 'O', ''),\n",
       " (to, 'O', ''),\n",
       " (reimposing, 'O', ''),\n",
       " (stay, 'O', ''),\n",
       " (at, 'O', ''),\n",
       " (home, 'O', ''),\n",
       " (restrictions, 'O', ''),\n",
       " (in, 'O', ''),\n",
       " (Australia, 'B', 'GPE'),\n",
       " (’s, 'O', ''),\n",
       " (second, 'B', 'ORDINAL'),\n",
       " (-, 'O', ''),\n",
       " (biggest, 'O', ''),\n",
       " (city, 'O', ''),\n",
       " (., 'O', '')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(X, X.ent_iob_, X.ent_type_) for X in parsed_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10tU8n44pdl4"
   },
   "source": [
    "The above format is a bit hard to read though, so spaCy also provides a far more natural visualisation of the tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1742335889141,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "9PmUl2y5pdl4",
    "outputId": "7cbb6baa-3d64-4035-cca4-00e8564c390e"
   },
   "outputs": [],
   "source": [
    "# displacy.render(parsed_text, jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VS1PK7ifpdl5"
   },
   "source": [
    "## Extracting entities from a web document\n",
    "\n",
    "Now that we know how to perform entity recognition on text, let's apply it to a full document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "8pY-nN0Zpdl5"
   },
   "outputs": [],
   "source": [
    "url = 'https://www.bbc.com/news/world-latin-america-53319517'\n",
    "#url = 'https://en.wikipedia.org/wiki/Apple_(disambiguation)'\n",
    "\n",
    "import requests\n",
    "html_doc = requests.get(url).text\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "parsed_doc = BeautifulSoup(html_doc, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRe5AUvCpdl5"
   },
   "source": [
    "Now lets extract the title and paragraph text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742335889431,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "e5YGoQISpdl5",
    "outputId": "efe1e337-54dd-49b3-9d67-5187e3f29c32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coronavirus: Brazil's President Bolsonaro tests positive\n",
      "\n",
      "Brazil's President Jair Bolsonaro has tested positive for coronavirus.\n",
      "He took the test, his fourth, on Monday after developing symptoms, including a high temperature.\n",
      "Mr Bolsonaro has repeatedly played down risks of what he has called the \"little flu\", saying he would not be seriously affected. He has opposed lockdowns, which he says hurt the economy.\n",
      "Brazil has the second-highest number of Covid-19 cases and deaths in the world, after the US. \n",
      "He made the announcement in a TV interview on Tuesday, saying the fever he had been experiencing had gone down and that he felt \"very well\".\n",
      "Mr Bolsonaro said that he had started experiencing symptoms on Sunday. He said he had had a high temperature, a cough and had felt unwell. \n",
      "He added that on Monday he had felt worse, which prompted him to take the coronavirus test.\n",
      "Mr Bolsonaro is in a higher-risk group because of his age, 65.\n",
      "He said he was taking hydroxychloroquine - championed by US President Donald Trump - and azithromycin, an antibiotic, to treat the illness. Neither has been proven to be effective against the virus.\n",
      "Contact tracing and tests will be carried out for the people Mr Bolsonaro has met recently.\n",
      "His previous three tests for the virus all came back negative.\n",
      "The executive director of the World Health Organization, Dr Mike Ryan, wished President Bolsonaro \"a speedy and full recovery from this disease\", adding: \"I think the message to us all is: we are vulnerable to this virus.\"\n",
      "Back in April, Mr Bolsonaro said that even if infected, he would \"not have to worry as I wouldn't feel anything, at most it would be like a little flu or a little cold\".\n",
      "The number of Covid-19-related deaths and infections - at that time under 3,000 and 40,000 - has since soared.\n",
      "Despite this, President Bolsonaro has argued that regional lockdowns are having a more damaging effect than the virus itself, and accused the media of spreading panic and paranoia.\n",
      "His other comments on the virus include:\n",
      "He has since continued to rail against measures that he deems \"dictatorial\" such as the closing beaches or requirements to wear face coverings. \n",
      "On Monday, he made further changes to a law that would require Brazilians to wear masks in public.\n",
      "He has attended a number of public events without a mask, even when local rules required him to wear one.\n",
      "On Sunday, Foreign Minister Ernesto Araújo posted a photo on social media showing himself with President Bolsonaro and others attending an Independence Day celebration at the US embassy in Brasilia. \n",
      "None of those in the photo is wearing a mask or observing social distancing.\n",
      "The US embassy said that the ambassador had had lunch with Mr Bolsonaro and others on 4 July. It added that the ambassador had no symptoms but that he would undergo testing.\n",
      "The ambassador had earlier tweeted a picture of himself with President Bolsonaro.\n",
      "For so long, Jair Bolsonaro has tried to brush off this virus - the irony that he has now caught it has not been missed in Brazil. \n",
      "His detractors - of which he has many - have weighed in, calling this karma - that Jair Bolsonaro invited this to happen. \n",
      "There was even a column in one of the biggest newspapers, Folha de São Paulo, entitled \"Why I'm Cheering for Bolsonaro to Die\" - this is how divided, how toxic  the political picture is here in Brazil as the pandemic takes hold. \n",
      "But the fact is, Bolsonaro joins the nearly 1.7 million Brazilians who've contracted Covid-19. They're scary numbers and Brazil is a country in trouble, where coronavirus is spreading fast. \n",
      "Will Jair Bolsonaro get away with mild symptoms and carry on downplaying it? Or change tack now the virus has hit home? Whatever happens, with the man at the top suffering from Covid-19, it symbolises the crisis this country is in. \n",
      "Infections in Brazil and Latin America as a whole took a while to take hold but then started to rise, initially for Brazil in its Amazonas region but then more starkly in Rio de Janeiro and São Paulo.\n",
      "Brazil became only the second country to pass one million cases on 20 June and has continued to rise, passing 1.5 million. Many experts believe deficiencies in testing mean the overall figures for cases and deaths could be considerably higher.\n",
      "Nevertheless lockdowns began to be lifted in many areas even as the cases surged. Both Rio and São Paulo have reopened bars and restaurants in the past week.\n",
      "Two health ministers - both doctors - have left their posts after disagreements with the president.\n",
      "One ray of hope though is Brazil's renowned expertise in vaccines. Two major vaccine tests, in partnership with AstraZeneca and Sinovac, are to begin final phase testing on thousands of Brazilian volunteers.\n",
      "Copyright 2025 BBC. All rights reserved.  The BBC is not responsible for the content of external sites. Read about our approach to external linking.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "title = parsed_doc.find('title').text\n",
    "paragraphs = [p.text for p in parsed_doc.find_all('p')]\n",
    "\n",
    "# Combine the title and paragraphs into a single text:\n",
    "article_text = title + '\\n\\n' + '\\n'.join(paragraphs)\n",
    "print(article_text)\n",
    "\n",
    "#article_text = parsed_doc.get_text()\n",
    "#print(article_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_dqist0pdl5"
   },
   "source": [
    "Parse the article to identify the entities and display them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1742335889605,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "RMTsfAhYpdl6",
    "outputId": "54830406-13fc-47b1-e405-4810f30cd4ba"
   },
   "outputs": [],
   "source": [
    "parsed_article = nlp_model(article_text)\n",
    "# displacy.render(parsed_article,jupyter=True,style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6I8_zJQrpdl6"
   },
   "source": [
    "What do you think? Did it work?\n",
    "\n",
    "Let's have a bit of a better look at the entities found\n",
    "- List all the distinct entities found in the article, sorted alphabetically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1742335889617,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "SakcaXuypdl6",
    "outputId": "ede1a33d-f574-437d-a31f-b46ef6849287"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.5 million',\n",
       " '20 June',\n",
       " '2025',\n",
       " '4 July',\n",
       " 'Amazonas',\n",
       " 'April',\n",
       " 'AstraZeneca and Sinovac',\n",
       " 'BBC',\n",
       " 'Bolsonaro',\n",
       " 'Brasilia',\n",
       " 'Brazil',\n",
       " 'Brazilian',\n",
       " 'Brazilians',\n",
       " 'Donald Trump',\n",
       " 'Ernesto Araújo',\n",
       " 'Folha de São Paulo',\n",
       " 'Independence Day',\n",
       " 'Jair Bolsonaro',\n",
       " 'Latin America',\n",
       " 'Mike Ryan',\n",
       " 'Monday',\n",
       " 'One',\n",
       " 'Rio de Janeiro',\n",
       " 'Sunday',\n",
       " 'São Paulo',\n",
       " 'Tuesday',\n",
       " 'Two',\n",
       " 'US',\n",
       " 'Will Jair Bolsonaro',\n",
       " 'fourth',\n",
       " 'his age, 65',\n",
       " 'nearly 1.7 million',\n",
       " 'one million',\n",
       " 'second',\n",
       " 'the World Health Organization',\n",
       " 'the past week',\n",
       " 'thousands',\n",
       " 'three',\n",
       " 'under 3,000 and 40,000 -']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(x.text for x in parsed_article.ents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyGeLXs8pdl6"
   },
   "source": [
    "We can count the number of times each **entity type** occurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1742335889681,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "mcmsbiUkpdl6",
    "outputId": "f6657154-1ac6-488c-e7b7-2df359e0e29f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'PERSON': 21,\n",
       "         'GPE': 16,\n",
       "         'DATE': 12,\n",
       "         'CARDINAL': 8,\n",
       "         'ORG': 6,\n",
       "         'ORDINAL': 3,\n",
       "         'NORP': 3,\n",
       "         'QUANTITY': 1,\n",
       "         'EVENT': 1,\n",
       "         'LOC': 1})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "labels = [x.label_ for x in parsed_article.ents]\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tb3g9y5Kpdl6"
   },
   "source": [
    "We can also count the number of times each **entity name** occurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1742335889682,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "JPdOsoiApdl6",
    "outputId": "dd24e6a6-7064-4811-c997-2fbe2adc34c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bolsonaro', 12),\n",
       " ('Brazil', 10),\n",
       " ('US', 4),\n",
       " ('Jair Bolsonaro', 3),\n",
       " ('Monday', 3),\n",
       " ('second', 2),\n",
       " ('Sunday', 2),\n",
       " ('Brazilians', 2),\n",
       " ('São Paulo', 2),\n",
       " ('Two', 2),\n",
       " ('BBC', 2),\n",
       " ('fourth', 1),\n",
       " ('Tuesday', 1),\n",
       " ('his age, 65', 1),\n",
       " ('Donald Trump', 1),\n",
       " ('three', 1),\n",
       " ('the World Health Organization', 1),\n",
       " ('Mike Ryan', 1),\n",
       " ('April', 1),\n",
       " ('under 3,000 and 40,000 -', 1),\n",
       " ('Ernesto Araújo', 1),\n",
       " ('Independence Day', 1),\n",
       " ('Brasilia', 1),\n",
       " ('4 July', 1),\n",
       " ('Folha de São Paulo', 1),\n",
       " ('nearly 1.7 million', 1),\n",
       " ('Will Jair Bolsonaro', 1),\n",
       " ('Latin America', 1),\n",
       " ('Amazonas', 1),\n",
       " ('Rio de Janeiro', 1),\n",
       " ('one million', 1),\n",
       " ('20 June', 1),\n",
       " ('1.5 million', 1),\n",
       " ('the past week', 1),\n",
       " ('One', 1),\n",
       " ('AstraZeneca and Sinovac', 1),\n",
       " ('thousands', 1),\n",
       " ('Brazilian', 1),\n",
       " ('2025', 1)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [x.text for x in parsed_article.ents]\n",
    "Counter(items).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEV2BJCTpdl7"
   },
   "source": [
    "Note that some of the phrases refer to the same entity, e.g. 'Mr Bolsonaro' and just 'Bolsonaro'.\n",
    "- Entity Linking and Reference Resolution are the NLP problems that deal with resolving the different references to the same entity in the text.\n",
    "\n",
    "If we were only interested in what was being said about Bolsonaro,\n",
    "- we could select only sentences refering to him:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 787
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1742335889728,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "oNXjt46Jpdl7",
    "outputId": "bf975511-1182-4103-d5d4-d815caf3e87c"
   },
   "outputs": [],
   "source": [
    "sentences_containing_Bolsonaro = [x for x in parsed_article.sents if 'Bolsonaro' in x.text]\n",
    "# displacy.render(sentences_containing_Bolsonaro,jupyter=True,style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkJvASO9pdl7"
   },
   "source": [
    "## Named Entity Extraction in Italian\n",
    "\n",
    "But wait, SpaCy can speak Italian too!\n",
    "- Let's make use of the pretrained italian model that we downloaded earlier: https://spacy.io/models/it\n",
    "- to recognise entities in an article from 'Il Corriere'\n",
    "\n",
    "First download the article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "BCTkJTsopdl7"
   },
   "outputs": [],
   "source": [
    "url = 'https://www.ansa.it/sito/notizie/mondo/2020/07/07/bolsonaro-ha-i-sintomi-del-coronavirus_40d26967-e377-4455-9b42-83c2756cf5f1.html'\n",
    "html_doc = requests.get(url).text\n",
    "parsed_doc = BeautifulSoup(html_doc, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrnqQcMOpdl7"
   },
   "source": [
    "Now let's extract the title and paragraph text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742335890811,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "OIyIysghpdl7",
    "outputId": "3149ff1c-c7d4-402c-c8e8-8628e3351214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bolsonaro positivo al test del coronavirus - Mondo - ANSA\n",
      "\n",
      "Se hai scelto di non accettare i cookie di  profilazione e tracciamento, puoi aderire all’abbonamento \"Consentless\" a un  costo molto accessibile, oppure scegliere un altro abbonamento per accedere ad ANSA.it.\n",
      "Ti invitiamo a leggere le Condizioni  Generali di Servizio, la Cookie Policy e l'Informativa Privacy. \n",
      "Puoi leggere tutti i titoli di ANSA.it e 10  contenuti ogni 30 giornia €16,99/anno\n",
      "Per accedere senza limiti a tutti i contenuti di ANSA.it\n",
      "Scegli il piano di  abbonamento più adatto alle tue esigenze.\n",
      "Se hai cambiato idea e non ti vuoi abbonare, puoi sempre esprimere il tuo consenso ai cookie di profilazione e tracciamento per leggere tutti i titoli di ANSA.it e 10 contenuti ogni 30 giorni (servizio base):\n",
      "Se accetti tutti i cookie di profilazione pubblicitaria e di tracciamento, noi e terze  parti selezionate utilizzeremo cookie e tecnologie simili per raccogliere ed  elaborare i tuoi dati personali e fornirti annunci e contenuti personalizzati,  valutare l’interazione con annunci e contenuti, effettuare ricerche di mercato,  migliorare i prodotti e i servizi.Per maggiori  informazioni accedi alla Cookie Policy e all'Informativa Privacy. \n",
      "Per maggiori informazioni sui servizi di ANSA.it, puoi consultare le nostre risposte alle domande più frequenti, oppure contattarci inviando una mail a register@ansa.it o telefonando al numero verde 800 938 881. Il servizio di assistenza clienti è attivo dal lunedì al venerdì dalle ore 09.00 alle ore 18:30, il sabato dalle ore 09:00 alle ore 14:00.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Il presidente brasiliano, Jair Bolsonaro, è risultato positivo al test sul Covid-19: lo ha reso noto lui stesso parlando in diretta a Tv Brasil dal Palacio da Alvorada, sua residenza ufficiale a Brasilia.    Ieri Bolsonaro aveva detto di sentirsi \"molto meglio, anche la febbre è scesa\". Bolsonaro - che ha già cancellato tutti gli impegni di lavoro previsti per questa settimana - aveva anche precisato che, non appena si è sentito male, ha iniziato ad assumere compresse di idrossiclorochina, seguendo l'esempio del suo omologo americano, Donald Trump, anche lui favorevole alla cura con il farmaco, spesso indicato per i casi di malaria.    Intanto, si è scatenato scatenato l'odio sul web contro il presidente brasiliano, accusato da più parti di aver sempre minimizzato la pandemia da coronavirus nel suo Paese.    In vetta ai 'trending topic' su Twitter in Brasile c'è infatti l'hashtag \"forca covid\" (forza covid). Una tendenza simile si era registrata anche all'epoca della positività di Boris Johnson, pure lui inizialmente scettico sulla gravità della malattia. Il premier britannico poi guarì dopo essere stato ricoverato in gravi condizioni.    Nel caso di Bolsonaro, il tenore della maggioranza dei tweet è forse ancora più violento, con migliaia di utenti che augurano apertamente la morte al capo di Stato verdeoro.    Prima di sottoporsi al test, Bolsonaro ha effettuato anche un esame dei polmoni. \"Vengo dall'ospedale, ho fatto una risonanza dei polmoni, sono puliti, tra un pò farò anche l'esame per il Covid, ma va tutto bene\", aveva spiegato lunedì sera il presidente della Repubblica a un gruppo di simpatizzanti che lo attendevano davanti al Palacio da Alvorada, la sua residenza ufficiale a Brasilia.   Bolsonaro si era già sottposto a due tamponi, poi risultati negativi, a marzo, dopo una visita negli Stati Uniti, al cui ritorno oltre 20 membri del suo staff erano risultati positivi. La scorsa settimana il presidente aveva detto che potrebbe avere contratto la malattia, pur senza manifestarne i sintomi, ma aveva ribadito la sua contrarietà al lockdown e ad altre misure restrittive imposte dalle autorità sanitarie per contenere la diffusione del coronavirus, difendendo la ripresa dell'economia.\n",
      "09:37\n",
      "03:43\n",
      "02:54\n",
      "02:12\n",
      "19:14\n",
      "12:06\n",
      "12:04\n",
      "12:01\n"
     ]
    }
   ],
   "source": [
    "title = parsed_doc.find('title').text\n",
    "paragraphs = [p.text for p in parsed_doc.find_all('p')]\n",
    "\n",
    "# Combine the title and paragraphs into a single text:\n",
    "article_text = title + '\\n\\n' + '\\n'.join(paragraphs)\n",
    "print(article_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eluDQCqxpdl7"
   },
   "source": [
    "Now we'll parse the text of the article with an Italian NLP engine to extract Named Entities.\n",
    "- First load the italian model 'it_core_news_sm' that we downloaded earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Qj0IIHlVpdl7"
   },
   "outputs": [],
   "source": [
    "nlp_it = spacy.load(\"it_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BcWwDGlypdl8"
   },
   "source": [
    "Parse article and extract the entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1742335893577,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "1X-Kuw6lpdl8",
    "outputId": "daab419f-a9d0-494f-cffa-18090677e3fc"
   },
   "outputs": [],
   "source": [
    "parsed_article = nlp_it(article_text)\n",
    "# displacy.render(parsed_article, jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08h69wcxpdl8"
   },
   "source": [
    "That looks not great.\n",
    "- Here are the entities found in the news article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742335893580,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "UKefi_fspdl8",
    "outputId": "a1676ded-8278-4804-96a0-4fe07a3cd089"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ANSA',\n",
       " 'ANSA.it',\n",
       " 'ANSA.it\\nScegli',\n",
       " 'Bolsonaro',\n",
       " 'Bolsonaro -',\n",
       " 'Boris Johnson',\n",
       " 'Brasile',\n",
       " 'Brasilia',\n",
       " 'Condizioni  Generali',\n",
       " 'Consentless',\n",
       " 'Cookie Policy',\n",
       " 'Covid',\n",
       " 'Donald Trump',\n",
       " 'Ieri Bolsonaro',\n",
       " 'Informativa Privacy',\n",
       " 'Jair Bolsonaro',\n",
       " 'Paese',\n",
       " 'Palacio da Alvorada',\n",
       " 'Repubblica',\n",
       " 'Servizio',\n",
       " 'Stati Uniti',\n",
       " 'Stato',\n",
       " 'Ti',\n",
       " 'Tv Brasil dal Palacio da Alvorada',\n",
       " 'Twitter',\n",
       " 'Vengo',\n",
       " 'hashtag',\n",
       " 'register@ansa.it']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(set(x.text for x in parsed_article.ents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GNZaLqN4Dx-"
   },
   "source": [
    "Alterantively you can use Stanza (https://stanfordnlp.github.io/stanza/). It's very similar to spaCy:\n",
    "- Python package\n",
    "- Supports multiple languages\n",
    "- Uses deep neural network modules\n",
    "\n",
    "Let's start installing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4968,
     "status": "ok",
     "timestamp": 1742335898549,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "a6JmKZ3xLPwI",
    "outputId": "fd6b18e5-5452-426c-a699-1f4d88a2519a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "\n",
    "def get_pref_encoding(*args, **kwargs):\n",
    "    return \"UTF-8\"\n",
    "\n",
    "locale.getpreferredencoding = get_pref_encoding\n",
    "%pip install -q stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NazOsrqKLgtW"
   },
   "source": [
    "Now we can import Stanza and create a pipeline for Italian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364,
     "referenced_widgets": [
      "73b14e84e45e4cfc9c251c1b07385a33",
      "c91068862a6742b6955f99801598a785",
      "5ea397e611e74f42bd078bdac7c4bbd1",
      "dc5e6bdaaa804d09873ae781c00a69da",
      "c8f7a7d87fee479cbbafc7d03ec44aba",
      "9bc354e617a8453daf0a3ba3782a8498",
      "26677e9072a64d16a6f4059e769cae5e",
      "49ea17ee73084fbbb8db7c6bc8e4da97",
      "c2a51ebcde1b46b38e36f6ac6b52422f",
      "3ec31dad4b344b2590aff92734f5a720",
      "f15a6508f63e43079bacafb2cf90855c"
     ]
    },
    "executionInfo": {
     "elapsed": 18464,
     "status": "ok",
     "timestamp": 1742335917014,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "X2vbIhiQLfhH",
    "outputId": "5d10ce16-8099-4824-b63c-fa24854dcffe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrien/Documents/PoliMi/TP/Natural Language Processing/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-31 10:59:48 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 424kB [00:00, 60.0MB/s]                    \n",
      "2025-03-31 10:59:48 INFO: Downloaded file to /home/adrien/stanza_resources/resources.json\n",
      "2025-03-31 10:59:48 WARNING: Language it package default expects mwt, which has been added\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.10.0/models/tokenize/combined.pt: 100%|██████████| 637k/637k [00:00<00:00, 8.09MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.10.0/models/mwt/combined.pt: 100%|██████████| 1.17M/1.17M [00:00<00:00, 5.68MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.10.0/models/ner/fbk.pt: 100%|██████████| 55.0M/55.0M [00:14<00:00, 3.67MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.10.0/models/pretrain/conll17.pt: 100%|██████████| 107M/107M [00:30<00:00, 3.52MB/s] \n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.10.0/models/forward_charlm/conll17.pt: 100%|██████████| 22.6M/22.6M [00:05<00:00, 4.13MB/s]\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-it/resolve/v1.10.0/models/backward_charlm/conll17.pt: 100%|██████████| 22.6M/22.6M [00:06<00:00, 3.50MB/s]\n",
      "2025-03-31 11:00:49 INFO: Loading these models for language: it (Italian):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| mwt       | combined |\n",
      "| ner       | fbk      |\n",
      "========================\n",
      "\n",
      "2025-03-31 11:00:49 INFO: Using device: cpu\n",
      "2025-03-31 11:00:49 INFO: Loading: tokenize\n",
      "2025-03-31 11:00:49 INFO: Loading: mwt\n",
      "2025-03-31 11:00:49 INFO: Loading: ner\n",
      "2025-03-31 11:00:54 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "stanza_nlp_model = stanza.Pipeline(lang='it', processors='tokenize,ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aN8vExE_MWGK"
   },
   "source": [
    "As before we need to parse the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "OHqxZTBALfm7"
   },
   "outputs": [],
   "source": [
    "stanza_parsed_article = stanza_nlp_model(article_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHx67HKdMtNi"
   },
   "source": [
    "Given a document, Stanza breaks it into sentences and then tokens.\n",
    "For each token adds the tags using the sleected processors (here we are using only the NER processors).\n",
    "\n",
    "Let's give a look at the identified entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1742335931034,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "Cw98dV1yLfsu",
    "outputId": "9802051e-2315-4518-f1e1-9fe8f997a06e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANSA.it: ORG\n",
      "ANSA.it: ORG\n",
      "ANSA.it: ORG\n",
      "ANSA.it: ORG\n",
      "ANSA.it: ORG\n",
      "register@ansa.it: ORG\n",
      "Jair Bolsonaro: PER\n",
      "Tv Brasil: LOC\n",
      "Palacio: LOC\n",
      "Alvorada: LOC\n",
      "Brasilia: LOC\n",
      "Bolsonaro: PER\n",
      "Bolsonaro: PER\n",
      "Donald Trump: PER\n",
      "Brasile: LOC\n",
      "Boris Johnson: PER\n",
      "Bolsonaro: PER\n",
      "Bolsonaro: PER\n",
      "Repubblica: ORG\n",
      "Palacio: PER\n",
      "Alvorada: LOC\n",
      "Brasilia: LOC\n",
      "Bolsonaro: PER\n",
      "Stati Uniti: LOC\n"
     ]
    }
   ],
   "source": [
    "for sentence in stanza_parsed_article.sentences:\n",
    "    for entity in sentence.ents:  # Hello, Treebeard!\n",
    "        print(f\"{entity.text}: {entity.type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LDtG1YcN__S"
   },
   "source": [
    "That's a bit better than before, don't you think?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzFM8cAUpdl8"
   },
   "source": [
    "## Fine-tuning your own NER Model\n",
    "\n",
    "What if you want to update the Named Entity Extraction model yourself in order to customize it to your set of entities? We'll have a look at that now based on:\n",
    "- this instructions page: https://spacy.io/usage/training#ner\n",
    "- and this blog post: https://towardsdatascience.com/custom-named-entity-recognition-using-spacy-7140ebbb3718\n",
    "\n",
    "In order to fine-tune the model, we need to prepare data in the following format:\n",
    "- a piece of text,\n",
    "- plus a list of entity types that occur it along with their positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1742335934944,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "d8aaj2uepdl8",
    "outputId": "69394691-8034-4a69-cc40-9a811b20b13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Have you heard of an associate professor from the Politecnico di Milano called Mark Carman?',\n",
       "  {'entities': [(50, 71, 'ORG'), (79, 90, 'PERSON')]}),\n",
       " (\"No, I haven't, but I don't know many people at the Politecnico. What does he work on?\",\n",
       "  {'entities': [(51, 62, 'ORG')]}),\n",
       " ('Mainly machine learning and text mining. I met him a couple of years ago at SIGIR in Tokyo.',\n",
       "  {'entities': [(76, 81, 'EVENT'), (85, 90, 'GPE')]})]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data = [\n",
    "    (\"Have you heard of an associate professor from the Politecnico di Milano called Mark Carman?\", {\"entities\": [(50, 71, \"ORG\"),(79, 90, \"PERSON\")]}),\n",
    "    (\"No, I haven't, but I don't know many people at the Politecnico. What does he work on?\", {\"entities\": [(51, 62, \"ORG\")]}),\n",
    "    (\"Mainly machine learning and text mining. I met him a couple of years ago at SIGIR in Tokyo.\", {\"entities\": [(76, 81, \"EVENT\"),(85, 90, \"GPE\")]}),\n",
    "]\n",
    "my_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnVIriSEpdl9"
   },
   "source": [
    "Where would this data come from?\n",
    "- either created manually, perhaps by searching for known individuals in a text collection,\n",
    "- or by using an annotation tool such as https://doccano.herokuapp.com/, see for example: https://medium.com/@justindavies/training-spacy-ner-models-with-doccano-8d8203e29bfa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1s9T3Whe5lZJ"
   },
   "source": [
    "The following code comes from here: https://github.com/explosion/spaCy/blob/master/examples/training/train_ner.py\n",
    "- The only change made was to remove the training data\n",
    "\n",
    "Before starting we need to install the plac package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3828,
     "status": "ok",
     "timestamp": 1742335941139,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "P057B5jUQjqM",
    "outputId": "391a679a-ad0a-4dcc-aa1f-fd0d5bd4adfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plac in /home/adrien/Documents/PoliMi/TP/Natural Language Processing/.venv/lib/python3.11/site-packages (1.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install plac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-oMt4jRQj2k"
   },
   "source": [
    "Now we define function with the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "jVjhWJ1Zpdl9"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import plac\n",
    "import random\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training.example import Example\n",
    "\n",
    "TRAIN_DATA = []\n",
    "\n",
    "@plac.annotations(\n",
    "    model=(\"Model name. Defaults to blank 'en' model.\", \"option\", \"m\", str),\n",
    "    output_dir=(\"Optional output directory\", \"option\", \"o\", Path),\n",
    "    n_iter=(\"Number of training iterations\", \"option\", \"n\", int),\n",
    ")\n",
    "def main(model=None, output_dir=None, n_iter=100):\n",
    "    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe(\"ner\")\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "    # otherwise, get it so we can add labels\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    # only train NER\n",
    "    with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():\n",
    "        # show warnings for misaligned entity spans once\n",
    "        warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
    "\n",
    "        # reset and initialize the weights randomly – but only if we're\n",
    "        # training a new model\n",
    "        if model is None:\n",
    "            nlp.begin_training()\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "            for batch in batches:\n",
    "                # Create example\n",
    "                examples = [\n",
    "                    Example.from_dict(nlp.make_doc(text), annotation)\n",
    "                    for text, annotation in batch\n",
    "                ]\n",
    "                # Update the model\n",
    "                nlp.update(\n",
    "                    examples,   # batch of texts and annotations\n",
    "                    drop=0.5,  # dropout - make it harder to memorise data\n",
    "                    losses=losses,\n",
    "                )\n",
    "            print(\"Losses\", losses)\n",
    "\n",
    "    # test the trained model\n",
    "    for text, _ in TRAIN_DATA:\n",
    "        doc = nlp(text)\n",
    "        print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "        print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])\n",
    "\n",
    "    # save model to output directory\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "\n",
    "        # test the saved model\n",
    "        print(\"Loading from\", output_dir)\n",
    "        nlp2 = spacy.load(output_dir)\n",
    "        for text, _ in TRAIN_DATA:\n",
    "            doc = nlp2(text)\n",
    "            print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "            print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1pM_VOIpdl9"
   },
   "source": [
    "Once the above model has been defined, we can update and save the model\n",
    "- Note that this code doesn't currently run in Google colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4350,
     "status": "ok",
     "timestamp": 1742335954553,
     "user": {
      "displayName": "Nicolò Brunello",
      "userId": "03655516846124206133"
     },
     "user_tz": -60
    },
    "id": "o1cpkZGWpdl9",
    "outputId": "679aced6-7076-4b77-baa6-b18e92cdbee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'en_core_web_sm'\n",
      "Losses {'ner': 5.858362685051438}\n",
      "Losses {'ner': 3.307922473954876}\n",
      "Losses {'ner': 3.500810892800912}\n",
      "Losses {'ner': 5.712573759924554}\n",
      "Losses {'ner': 6.42105248067982}\n",
      "Entities [('a couple of years ago', 'DATE'), ('Tokyo', 'GPE')]\n",
      "Tokens [('Mainly', '', 2), ('machine', '', 2), ('learning', '', 2), ('and', '', 2), ('text', '', 2), ('mining', '', 2), ('.', '', 2), ('I', '', 2), ('met', '', 2), ('him', '', 2), ('a', 'DATE', 3), ('couple', 'DATE', 1), ('of', 'DATE', 1), ('years', 'DATE', 1), ('ago', 'DATE', 1), ('at', '', 2), ('SIGIR', '', 2), ('in', '', 2), ('Tokyo', 'GPE', 3), ('.', '', 2)]\n",
      "Entities [('the Politecnico di Milano', 'ORG'), ('Mark Carman', 'PERSON')]\n",
      "Tokens [('Have', '', 2), ('you', '', 2), ('heard', '', 2), ('of', '', 2), ('an', '', 2), ('associate', '', 2), ('professor', '', 2), ('from', '', 2), ('the', 'ORG', 3), ('Politecnico', 'ORG', 1), ('di', 'ORG', 1), ('Milano', 'ORG', 1), ('called', '', 2), ('Mark', 'PERSON', 3), ('Carman', 'PERSON', 1), ('?', '', 2)]\n",
      "Entities [('Politecnico', 'ORG')]\n",
      "Tokens [('No', '', 2), (',', '', 2), ('I', '', 2), ('have', '', 2), (\"n't\", '', 2), (',', '', 2), ('but', '', 2), ('I', '', 2), ('do', '', 2), (\"n't\", '', 2), ('know', '', 2), ('many', '', 2), ('people', '', 2), ('at', '', 2), ('the', '', 2), ('Politecnico', 'ORG', 3), ('.', '', 2), ('What', '', 2), ('does', '', 2), ('he', '', 2), ('work', '', 2), ('on', '', 2), ('?', '', 2)]\n",
      "Saved model to spacy_model\n",
      "Loading from spacy_model\n",
      "Entities [('a couple of years ago', 'DATE'), ('Tokyo', 'GPE')]\n",
      "Tokens [('Mainly', '', 2), ('machine', '', 2), ('learning', '', 2), ('and', '', 2), ('text', '', 2), ('mining', '', 2), ('.', '', 2), ('I', '', 2), ('met', '', 2), ('him', '', 2), ('a', 'DATE', 3), ('couple', 'DATE', 1), ('of', 'DATE', 1), ('years', 'DATE', 1), ('ago', 'DATE', 1), ('at', '', 2), ('SIGIR', '', 2), ('in', '', 2), ('Tokyo', 'GPE', 3), ('.', '', 2)]\n",
      "Entities [('the Politecnico di Milano', 'ORG'), ('Mark Carman', 'PERSON')]\n",
      "Tokens [('Have', '', 2), ('you', '', 2), ('heard', '', 2), ('of', '', 2), ('an', '', 2), ('associate', '', 2), ('professor', '', 2), ('from', '', 2), ('the', 'ORG', 3), ('Politecnico', 'ORG', 1), ('di', 'ORG', 1), ('Milano', 'ORG', 1), ('called', '', 2), ('Mark', 'PERSON', 3), ('Carman', 'PERSON', 1), ('?', '', 2)]\n",
      "Entities [('Politecnico', 'ORG')]\n",
      "Tokens [('No', '', 2), (',', '', 2), ('I', '', 2), ('have', '', 2), (\"n't\", '', 2), (',', '', 2), ('but', '', 2), ('I', '', 2), ('do', '', 2), (\"n't\", '', 2), ('know', '', 2), ('many', '', 2), ('people', '', 2), ('at', '', 2), ('the', '', 2), ('Politecnico', 'ORG', 3), ('.', '', 2), ('What', '', 2), ('does', '', 2), ('he', '', 2), ('work', '', 2), ('on', '', 2), ('?', '', 2)]\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA=my_data  # The method expects the training data to have this name\n",
    "main(model='en_core_web_sm',output_dir='spacy_model',n_iter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MlicBTgepdl-"
   },
   "source": [
    "## Entity Linking in spaCy\n",
    "\n",
    "We don't want to just find entity mentions in a document but link them to a known entity in a knowledge base.\n",
    "- The task of linking the entity mentions to the corresponding entity in the knowledge base is called 'Entity Linking'.\n",
    "- Watch this video to learn more:\n",
    "https://spacy.io/universe/project/video-spacy-irl-entity-linking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "_BKB-yMKpdl-"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "26677e9072a64d16a6f4059e769cae5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ec31dad4b344b2590aff92734f5a720": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49ea17ee73084fbbb8db7c6bc8e4da97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ea397e611e74f42bd078bdac7c4bbd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49ea17ee73084fbbb8db7c6bc8e4da97",
      "max": 52557,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c2a51ebcde1b46b38e36f6ac6b52422f",
      "value": 52557
     }
    },
    "73b14e84e45e4cfc9c251c1b07385a33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c91068862a6742b6955f99801598a785",
       "IPY_MODEL_5ea397e611e74f42bd078bdac7c4bbd1",
       "IPY_MODEL_dc5e6bdaaa804d09873ae781c00a69da"
      ],
      "layout": "IPY_MODEL_c8f7a7d87fee479cbbafc7d03ec44aba"
     }
    },
    "9bc354e617a8453daf0a3ba3782a8498": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2a51ebcde1b46b38e36f6ac6b52422f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c8f7a7d87fee479cbbafc7d03ec44aba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c91068862a6742b6955f99801598a785": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bc354e617a8453daf0a3ba3782a8498",
      "placeholder": "​",
      "style": "IPY_MODEL_26677e9072a64d16a6f4059e769cae5e",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: "
     }
    },
    "dc5e6bdaaa804d09873ae781c00a69da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ec31dad4b344b2590aff92734f5a720",
      "placeholder": "​",
      "style": "IPY_MODEL_f15a6508f63e43079bacafb2cf90855c",
      "value": " 424k/? [00:00&lt;00:00, 29.3MB/s]"
     }
    },
    "f15a6508f63e43079bacafb2cf90855c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
